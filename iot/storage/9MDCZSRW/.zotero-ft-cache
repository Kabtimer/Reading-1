Artiﬁcial Intelligence with Python
Build real-world Artiﬁcial Intelligence applications with Python to intelligently interact with the world around you
Prateek Joshi
BIRMINGHAM - MUMBAI

Artificial Intelligence with Python
Copyright © 2017 Packt Publishing
All rights reserved. No part of this book may be reproduced, stored in a retrieval system, or transmitted in any form or by any means, without the prior written permission of the publisher, except in the case of brief quotations embedded in critical articles or reviews.
Every effort has been made in the preparation of this book to ensure the accuracy of the information presented. However, the information contained in this book is sold without warranty, either express or implied. Neither the author, nor Packt Publishing, and its dealers and distributors will be held liable for any damages caused or alleged to be caused directly or indirectly by this book.
Packt Publishing has endeavored to provide trademark information about all of the companies and products mentioned in this book by the appropriate use of capitals. However, Packt Publishing cannot guarantee the accuracy of this information.
First published: January 2017
Production reference: 1230117
Published by Packt Publishing Ltd. Livery Place 35 Livery Street Birmingham B3 2PB, UK.
ISBN 978-1-78646-439-2
www.packtpub.com

Credits

Author Prateek Joshi

Copy Editors Vikrant Phadkay Safis Editing

Reviewer Richard Marsden

Project Coordinator Nidhi Joshi

Commissioning Editor Veena Pagare

Proofreader Safis Editing

Acquisition Editor Tushar Gupta

Indexer Mariammal Chettiyar

Content Development Editor Aishwarya Pandere

Production Coordinator Shantanu N. Zagade

Technical Editor Karan Thakkar

About the Author
Prateek Joshi is an artificial intelligence researcher, published author of five books, and TEDx speaker. He is the founder of Pluto AI, a venture-funded Silicon Valley startup building an analytics platform for smart water management powered by deep learning. His work in this field has led to patents, tech demos, and research papers at major IEEE conferences. He has been an invited speaker at technology and entrepreneurship conferences including TEDx, AT&T Foundry, Silicon Valley Deep Learning, and Open Silicon Valley. Prateek has also been featured as a guest author in prominent tech magazines.
His tech blog (www.prateekjoshi.com) has received more than 1.2 million page views from 200 over countries and has over 6,600+ followers. He frequently writes on topics such as artificial intelligence, Python programming, and abstract mathematics. He is an avid coder and has won many hackathons utilizing a wide variety of technologies. He graduated from University of Southern California with a master’s degree specializing in artificial intelligence. He has worked at companies such as Nvidia and Microsoft Research. You can learn more about him on his personal website at www.prateekj.com.

About the Reviewer
Richard Marsden has over 20 years of professional software development experience. After starting in the field of geophysical surveying for the oil industry, he has spent the last ten years running the Winwaed Software Technology LLC independent software vendor. Winwaed specializes in geospatial tools and applications including web applications, and operates the http://www.mapping-tools.com website for tools and add-ins for geospatial applications such as Caliper Maptitude and Microsoft MapPoint.
Richard was also a technical reviewer of the following Packt publications: Python Geospatial Development and Python Geospatial Analysis Essentials, both by Erik Westra; Python Geospatial Analysis Cookbook by Michael Diener; Mastering Python Forensics by Drs Michael Spreitzenbarth and Dr Johann Uhrmann; and Effective Python Penetration Testing by Rejah Rehim.

www.PacktPub.com
For support files and downloads related to your book, please visit www.PacktPub.com. Did you know that Packt offers eBook versions of every book published, with PDF and ePub files available? You can upgrade to the eBook version at www.PacktPub.com and as a print book customer, you are entitled to a discount on the eBook copy. Get in touch with us at service@packtpub.com for more details. At www.PacktPub.com, you can also read a collection of free technical articles, sign up for a range of free newsletters and receive exclusive discounts and offers on Packt books and eBooks.
h t t p s ://w w w . p a c k t p u b . c o m /m a p t
Get the most in-demand software skills with Mapt. Mapt gives you full access to all Packt books and video courses, as well as industry-leading tools to help you plan your personal development and advance your career.
Why subscribe?
Fully searchable across every book published by Packt Copy and paste, print, and bookmark content On demand and accessible via a web browser

Customer Feedback
Thank you for purchasing this Packt book. We take our commitment to improving our content and products to meet your needs seriously—that's why your feedback is so valuable. Whatever your feelings about your purchase, please consider leaving a review on this book's Amazon page. Not only will this help us, more importantly it will also help others in the community to make an informed decision about the resources that they invest in to learn.
You can also review for us on a regular basis by joining our reviewers' club. If you're interested in joining, or would like to learn more about the benefits we offer, please contact us: customerreviews@packtpub.com.

Table of Contents

Preface

1

Chapter 1: Introduction to Artificial Intelligence

7

What is Artificial Intelligence?

8

Why do we need to study AI?

8

Applications of AI

12

Branches of AI

14

Defining intelligence using Turing Test

16

Making machines think like humans

18

Building rational agents

20

General Problem Solver

21

Solving a problem with GPS

22

Building an intelligent agent

22

Types of models

24

Installing Python 3

24

Installing on Ubuntu

25

Installing on Mac OS X

25

Installing on Windows

26

Installing packages

26

Loading data

27

Summary

29

Chapter 2: Classification and Regression Using Supervised Learning 30

Supervised versus unsupervised learning

30

What is classification?

31

Preprocessing data

32

Binarization

32

Mean removal

33

Scaling

34

Normalization

35

Label encoding

36

Logistic Regression classifier

37

Naïve Bayes classifier

42

Confusion matrix

46

Support Vector Machines

49

Classifying income data using Support Vector Machines

51

What is Regression?

54

Building a single variable regressor

55

Building a multivariable regressor

58

Estimating housing prices using a Support Vector Regressor

60

Summary

62

Chapter 3: Predictive Analytics with Ensemble Learning

63

What is Ensemble Learning?

63

Building learning models with Ensemble Learning

64

What are Decision Trees?

64

Building a Decision Tree classifier

65

What are Random Forests and Extremely Random Forests?

70

Building Random Forest and Extremely Random Forest classifiers

70

Estimating the confidence measure of the predictions

76

Dealing with class imbalance

80

Finding optimal training parameters using grid search

87

Computing relative feature importance

90

Predicting traffic using Extremely Random Forest regressor

93

Summary

96

Chapter 4: Detecting Patterns with Unsupervised Learning

97

What is unsupervised learning?

97

Clustering data with K-Means algorithm

98

Estimating the number of clusters with Mean Shift algorithm

104

Estimating the quality of clustering with silhouette scores

107

What are Gaussian Mixture Models?

112

Building a classifier based on Gaussian Mixture Models

113

Finding subgroups in stock market using Affinity Propagation model 118

Segmenting the market based on shopping patterns

120

Summary

124

Chapter 5: Building Recommender Systems

125

Creating a training pipeline

125

Extracting the nearest neighbors

128

Building a K-Nearest Neighbors classifier

132

Computing similarity scores

139

Finding similar users using collaborative filtering

143

Building a movie recommendation system

146

Summary

149

Chapter 6: Logic Programming

150

[ ii ]

What is logic programming?

150

Understanding the building blocks of logic programming

153

Solving problems using logic programming

153

Installing Python packages

154

Matching mathematical expressions

154

Validating primes

156

Parsing a family tree

158

Analyzing geography

164

Building a puzzle solver

167

Summary

171

Chapter 7: Heuristic Search Techniques

172

What is heuristic search?

172

Uninformed versus Informed search

173

Constraint Satisfaction Problems

174

Local search techniques

174

Simulated Annealing

175

Constructing a string using greedy search

176

Solving a problem with constraints

180

Solving the region-coloring problem

183

Building an 8-puzzle solver

186

Building a maze solver

191

Summary

196

Chapter 8: Genetic Algorithms

197

Understanding evolutionary and genetic algorithms

197

Fundamental concepts in genetic algorithms

198

Generating a bit pattern with predefined parameters

199

Visualizing the evolution

206

Solving the symbol regression problem

215

Building an intelligent robot controller

220

Summary

227

Chapter 9: Building Games With Artificial Intelligence

228

Using search algorithms in games

229

Combinatorial search

229

Minimax algorithm

230

Alpha-Beta pruning

230

Negamax algorithm

231

Installing easyAI library

231

Building a bot to play Last Coin Standing

232

[ iii ]

Building a bot to play Tic-Tac-Toe

236

Building two bots to play Connect Four™ against each other

239

Building two bots to play Hexapawn against each other

243

Summary

247

Chapter 10: Natural Language Processing

248

Introduction and installation of packages

248

Tokenizing text data

250

Converting words to their base forms using stemming

251

Converting words to their base forms using lemmatization

253

Dividing text data into chunks

255

Extracting the frequency of terms using a Bag of Words model

257

Building a category predictor

260

Constructing a gender identifier

263

Building a sentiment analyzer

266

Topic modeling using Latent Dirichlet Allocation

270

Summary

273

Chapter 11: Probabilistic Reasoning for Sequential Data

274

Understanding sequential data

274

Handling time-series data with Pandas

275

Slicing time-series data

278

Operating on time-series data

280

Extracting statistics from time-series data

283

Generating data using Hidden Markov Models

287

Identifying alphabet sequences with Conditional Random Fields

290

Stock market analysis

295

Summary

298

Chapter 12: Building A Speech Recognizer

299

Working with speech signals

299

Visualizing audio signals

300

Transforming audio signals to the frequency domain

303

Generating audio signals

305

Synthesizing tones to generate music

308

Extracting speech features

310

Recognizing spoken words

314

Summary

320

Chapter 13: Object Detection and Tracking

321

Installing OpenCV

322

[ iv ]

Frame differencing

322

Tracking objects using colorspaces

325

Object tracking using background subtraction

329

Building an interactive object tracker using the CAMShift algorithm 333

Optical flow based tracking

341

Face detection and tracking

348

Using Haar cascades for object detection

348

Using integral images for feature extraction

349

Eye detection and tracking

352

Summary

355

Chapter 14: Artificial Neural Networks

356

Introduction to artificial neural networks

356

Building a neural network

357

Training a neural network

357

Building a Perceptron based classifier

358

Constructing a single layer neural network

362

Constructing a multilayer neural network

366

Building a vector quantizer

371

Analyzing sequential data using recurrent neural networks

374

Visualizing characters in an Optical Character Recognition database 378

Building an Optical Character Recognition engine

381

Summary

384

Chapter 15: Reinforcement Learning

385

Understanding the premise

385

Reinforcement learning versus supervised learning

386

Real world examples of reinforcement learning

387

Building blocks of reinforcement learning

388

Creating an environment

389

Building a learning agent

394

Summary

398

Chapter 16: Deep Learning with Convolutional Neural Networks

399

What are Convolutional Neural Networks?

399

Architecture of CNNs

400

Types of layers in a CNN

401

Building a perceptron-based linear regressor

402

Building an image classifier using a single layer neural network

408

Building an image classifier using a Convolutional Neural Network

410

Summary

416

[v]

Index

417

[ vi ]

Preface
Artificial intelligence is becoming increasingly relevant in the modern world where everything is driven by data and automation. It is used extensively across many fields such as image recognition, robotics, search engines, and self-driving cars. In this book, we will explore various real-world scenarios. We will understand what algorithms to use in a given context and write functional code using this exciting book.
We will start by talking about various realms of artificial intelligence. We’ll then move on to discuss more complex algorithms, such as Extremely Random Forests, Hidden Markov Models, Genetic Algorithms, Artificial Neural Networks, and Convolutional Neural Networks, and so on. This book is for Python programmers looking to use artificial intelligence algorithms to create real-world applications. This book is friendly to Python beginners, but familiarity with Python programming would certainly be helpful so you can play around with the code. It is also useful to experienced Python programmers who are looking to implement artificial intelligence techniques.
You will learn how to make informed decisions about the type of algorithms you need to use and how to implement those algorithms to get the best possible results. If you want to build versatile applications that can make sense of images, text, speech, or some other form of data, this book on artificial intelligence will definitely come to your rescue!
What this book covers
Chapter 1, Introduction to Artificial Intelligence, teaches you various introductory concepts in artificial intelligence. It talks about applications, branches, and modeling of Artificial Intelligence. It walks the reader through the installation of necessary Python packages.
Chapter 2, Classification and Regression Using Supervised Learning, covers various supervised learning techniques for classification and regression. You will learn how to analyze income data and predict housing prices.
Chapter 3, Predictive Analytics with Ensemble Learning, explains predictive modeling techniques using Ensemble Learning, particularly focused on Random Forests. We will learn how to apply these techniques to predict traffic on the roads near sports stadiums.
Chapter 4, Detecting Patterns with Unsupervised Learning, covers unsupervised learning algorithms including K-means and Mean Shift Clustering. We will learn how to apply these algorithms to stock market data and customer segmentation.

Preface
Chapter 5, Building Recommender Systems, illustrates algorithms used to build recommendation engines. You will learn how to apply these algorithms to collaborative filtering and movie recommendations.
Chapter 6, Logic Programming, covers the building blocks of logic programming. We will see various applications, including expression matching, parsing family trees, and solving puzzles.
Chapter 7, Heuristic Search Techniques, shows heuristic search techniques that are used to search the solution space. We will learn about various applications such as simulated annealing, region coloring, and maze solving.
Chapter 8, Genetic Algorithms, covers evolutionary algorithms and genetic programming. We will learn about various concepts such as crossover, mutation, and fitness functions. We will then use these concepts to solve the symbol regression problem and build an intelligent robot controller.
Chapter 9, Building Games with Artificial Intelligence, teaches you how to build games with artificial intelligence. We will learn how to build various games including Tic Tac Toe, Connect Four, and Hexapawn.
Chapter 10, Natural Language Processing, covers techniques used to analyze text data including tokenization, stemming, bag of words, and so on. We will learn how to use these techniques to do sentiment analysis and topic modeling.
Chapter 11, Probabilistic Reasoning for Sequential Data, shows you techniques used to analyze time series and sequential data including Hidden Markov models and Conditional Random Fields. We will learn how to apply these techniques to text sequence analysis and stock market predictions.
Chapter 12, Building A Speech Recognizer, demonstrates algorithms used to analyze speech data. We will learn how to build speech recognition systems.
Chapter 13, Object Detection and Tracking, It covers algorithms related to object detection and tracking in live video. We will learn about various techniques including optical flow, face tracking, and eye tracking.
Chapter 14, Artificial Neural Networks, covers algorithms used to build neural networks. We will learn how to build an Optical Character Recognition system using neural networks.
Chapter 15, Reinforcement Learning, teaches the techniques used to build reinforcement learning systems. We will learn how to build learning agents that can learn from interacting with the environment.
[2]

Preface
Chapter 16, Deep Learning with Convolutional Neural Networks, covers algorithms used to build deep learning systems using Convolutional Neural Networks. We will learn how to use TensorFlow to build neural networks. We will then use it to build an image classifier using convolutional neural networks.
What you need for this book
This book is focused on artificial intelligence in Python as opposed to the Python itself. We have used Python 3 to build various applications. We focus on how to utilize various Python libraries in the best possible way to build real world applications. In that spirit, we have tried to keep all of the code as friendly and readable as possible. We feel that this will enable our readers to easily understand the code and readily use it in different scenarios.
Who this book is for
This book is for Python developers who want to build real-world artificial intelligence applications. This book is friendly to Python beginners, but being familiar with Python would be useful to play around with the code. It will also be useful for experienced Python programmers who are looking to use artificial intelligence techniques in their existing technology stacks.
Conventions
In this book, you will find a number of text styles that distinguish between different kinds of information. Here are some examples of these styles and an explanation of their meaning.
Code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles are shown as follows: "We can include other contexts through the use of the include directive."
A block of code is set as follows:
[default] exten => s,1,Dial(Zap/1|30) exten => s,2,Voicemail(u100) exten => s,102,Voicemail(b100) exten => i,1,Voicemail(s0)
[3]

Preface
When we wish to draw your attention to a particular part of a code block, the relevant lines or items are set in bold:
[default] exten => s,1,Dial(Zap/1|30) exten => s,2,Voicemail(u100) exten => s,102,Voicemail(b100) exten => i,1,Voicemail(s0)
Any command-line input or output is written as follows:
# cp /usr/src/asterisk-addons/configs/cdr_mysql.conf.sample /etc/asterisk/cdr_mysql.conf
New terms and important words are shown in bold. Words that you see on the screen, for example, in menus or dialog boxes, appear in the text like this: "The shortcuts in this book are based on the Mac OS X 10.5+ scheme."
Warnings or important notes appear in a box like this.
Tips and tricks appear like this.
Reader feedback
Feedback from our readers is always welcome. Let us know what you think about this book-what you liked or disliked. Reader feedback is important for us as it helps us develop titles that you will really get the most out of. To send us general feedback, simply e-mail feedback@packtpub.com, and mention the book's title in the subject of your message. If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, see our author guide at www.packtpub.com/authors.
[4]

Preface
Customer support
Now that you are the proud owner of a Packt book, we have a number of things to help you to get the most from your purchase.
Downloading the example code
You can download the example code files for this book from your account at http://www.p acktpub.com. If you purchased this book elsewhere, you can visit http://www.packtpub.c om/supportand register to have the files e-mailed directly to you.
You can download the code files by following these steps:
1. Log in or register to our website using your e-mail address and password. 2. Hover the mouse pointer on the SUPPORT tab at the top. 3. Click on Code Downloads & Errata. 4. Enter the name of the book in the Search box. 5. Select the book for which you're looking to download the code files. 6. Choose from the drop-down menu where you purchased this book from. 7. Click on Code Download.
Once the file is downloaded, please make sure that you unzip or extract the folder using the latest version of:
WinRAR / 7-Zip for Windows Zipeg / iZip / UnRarX for Mac 7-Zip / PeaZip for Linux
The code bundle for the book is also hosted on GitHub at https://github.com/PacktPubl ishing/Artificial-Intelligence-with-Python. We also have other code bundles from our rich catalog of books and videos available at https://github.com/PacktPublishing/. Check them out!
Downloading the color images of this book
We also provide you with a PDF file that has color images of the screenshots/diagrams used in this book. The color images will help you better understand the changes in the output. You can download this file from https://www.packtpub.com/sites/default/files/down l o a d s /A r t i f i c i a l I n t e l l i g e n c e w i t h P y t h o n _ C o l o r I m a g e s . p d f .
[5]

Preface
Errata
Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you find a mistake in one of our books-maybe a mistake in the text or the codewe would be grateful if you could report this to us. By doing so, you can save other readers from frustration and help us improve subsequent versions of this book. If you find any errata, please report them by visiting http://www.packtpub.com/submit-errata, selecting your book, clicking on the Errata Submission Form link, and entering the details of your errata. Once your errata are verified, your submission will be accepted and the errata will be uploaded to our website or added to any list of existing errata under the Errata section of that title. To view the previously submitted errata, go to https://www.packtpub.com/books/conten t/supportand enter the name of the book in the search field. The required information will appear under the Errata section.
Piracy
Piracy of copyrighted material on the Internet is an ongoing problem across all media. At Packt, we take the protection of our copyright and licenses very seriously. If you come across any illegal copies of our works in any form on the Internet, please provide us with the location address or website name immediately so that we can pursue a remedy. Please contact us at copyright@packtpub.com with a link to the suspected pirated material. We appreciate your help in protecting our authors and our ability to bring you valuable content.
Questions
If you have a problem with any aspect of this book, you can contact us at questions@packtpub.com, and we will do our best to address the problem.
[6]

1
Introduction to Artificial
Intelligence
In this chapter, we are going to discuss the concept of Artificial Intelligence (AI) and how it's applied in the real world. We spend a significant portion of our everyday life interacting with smart systems. It can be in the form of searching for something on the internet, Biometric face recognition, or converting spoken words to text. Artificial Intelligence is at the heart of all this and it's becoming an important part of our modern lifestyle. All these system are complex real-world applications and Artificial Intelligence solves these problems with mathematics and algorithms. During the course of this book, we will learn the fundamental principles that are used to build such applications and then implement them as well. Our overarching goal is to enable you to take up new and challenging Artificial Intelligence problems that you might encounter in your everyday life.
By the end of this chapter, you will know:
What is AI and why do we need to study it? Applications of AI Branches of AI Turing test Rational agents

Introduction to Artificial Intelligence
General Problem Solvers Building an intelligent agent Installing Python 3 on various operating systems Installing the necessary Python packages
What is Artificial Intelligence?
Artificial Intelligence (AI) is a way to make machines think and behave intelligently. These machines are controlled by software inside them, so AI has a lot to do with intelligent software programs that control these machines. It is a science of finding theories and methodologies that can help machines understand the world and accordingly react to situations in the same way that humans do. If we look closely at how the field of AI has emerged over the last couple of decades, you will see that different researchers tend to focus on different concepts to define AI. In the modern world, AI is used across many verticals in many different forms. We want the machines to sense, reason, think, and act. We want our machines to be rational too. AI is closely related to the study of human brain. Researchers believe that AI can be accomplished by understanding how the human brain works. By mimicking the way the human brain learns, thinks, and takes action, we can build a machine that can do the same. This can be used as a platform to develop intelligent systems that are capable of learning.
Why do we need to study AI?
AI has the ability to impact every aspect of our lives. The field of AI tries to understand patterns and behaviors of entities. With AI, we want to build smart systems and understand the concept of intelligence as well. The intelligent systems that we construct are very useful in understanding how an intelligent system like our brain goes about constructing another intelligent system.
[8]

Introduction to Artificial Intelligence
Let's take a look at how our brain processes information:
Compared to some other fields such as Mathematics or Physics that have been around for centuries, AI is relatively in its infancy. Over the last couple of decades, AI has produced some spectacular products such as self-driving cars and intelligent robots that can walk. Based on the direction in which we are heading, it's pretty obvious that achieving intelligence will have a great impact on our lives in the coming years.
[9]

Introduction to Artificial Intelligence
We can't help but wonder how the human brain manages to do so much with such effortless ease. We can recognize objects, understand languages, learn new things, and perform many more sophisticated tasks with our brain. How does the human brain do this? When you try to do this with a machine, you will see that it falls way behind! For example, when we try to look for things such as extraterrestrial life or time travel, we don't know if those things exist. The good thing about the holy grail of AI is that we know it exists. Our brain is the holy grail! It is a spectacular example of an intelligent system. All we have to do is to mimic its functionality to create an intelligent system that can do something similar, possibly even more. Let's see how raw data gets converted to wisdom through various levels of processing:
[ 10 ]

Introduction to Artificial Intelligence
One of the main reasons we want to study AI is to automate many things. We live in a world where:
We deal with huge and insurmountable amounts of data. The human brain can't keep track of so much data. Data originates from multiple sources simultaneously. The data is unorganized and chaotic. Knowledge derived from this data has to be updated constantly because the data itself keeps changing. The sensing and actuation has to happen in real time with high precision. Even though the human brain is great at analyzing things around us, it cannot keep up with the preceding conditions. Hence, we need to design and develop intelligent machines that can do this. We need AI systems that can: Handle large amounts of data in an efficient way. With the advent of Cloud Computing, we are now able to store huge amounts of data. Ingest data simultaneously from multiple sources without any lag. Index and organize data in a way that allows us to derive insights. Learn from new data and update constantly using the right learning algorithms. Think and respond to situations based on the conditions in real time. AI techniques are actively being used to make existing machines smarter, so that they can execute faster and more efficiently.
[ 11 ]

Introduction to Artificial Intelligence
Applications of AI
Now that we know how information gets processed, let's see where AI appears in the real world. AI manifests itself in various different forms across multiple fields, so it's important to understand how it's useful in various domains. AI has been used across many industries and it continues to expand rapidly. Some of the most popular areas include:
Computer Vision: These are the systems that deal with visual data such as images and videos. These systems understand the content and extract insights based on the use case. For example, Google uses reverse image search to search for visually similar images across the Web.
[ 12 ]

Introduction to Artificial Intelligence
Natural Language Processing: This field deals with understanding text. We can interact with a machine by typing natural language sentences. Search engines use this extensively to deliver the right search results. Speech Recognition: These systems are capable of hearing and understanding spoken words. For example, there are intelligent personal assistants on our smartphones that can understand what we are saying and give relevant information or perform an action based on that. Expert Systems: These systems use AI techniques to provide advice or make decisions. They usually use databases of expert knowledge areas such as finance, medicine, marketing, and so on to give advice about what to do next. Let's see what an expert system looks like and how it interacts with the user:
Games: AI is used extensively in the gaming industry. It is used to design intelligent agents that can compete with humans. For example, AlphaGo is a computer program that can play the strategy game Go. It is also used in designing many other types of games where we expect the computer to behave intelligently.
[ 13 ]

Introduction to Artificial Intelligence
Robotics: Robotic systems actually combine many concepts in AI. These systems are able to perform many different tasks. Depending on the situation, robots have sensors and actuators that can do different things. These sensors can see things in front of them and measure the temperature, heat, movements, and so on. They have processors on board that compute various things in real time. They are also capable of adapting to the new environments.
Branches of AI
It is important to understand the various fields of study within AI so that we can choose the right framework to solve a given real-world problem. Here's a list of topics that are dominant:
Machine learning and pattern recognition: This is perhaps the most popular form of AI out there. We design and develop software that can learn from data. Based on these learning models, we perform predictions on unknown data. One of the main constraints here is that these programs are limited to the power of the data. If the dataset is small, then the learning models would be limited as well. Let's see what a typical machine learning system looks like:
[ 14 ]

Introduction to Artificial Intelligence
When a system makes an observation, it is trained to compare it with what it has already seen in the form of a pattern. For example, in a face recognition system, the software will try to match the pattern of eyes, nose, lips, eyebrows, and so on in order to find a face in the existing database of users. Logic-based AI: Mathematical logic is used to execute computer programs in logic-based AI. A program written in logic-based AI is basically a set of statements in logical form that express facts and rules about a particular problem domain. This is used extensively in pattern matching, language parsing, semantic analysis, and so on. Search: The Search techniques are used extensively in AI programs. These programs examine a large number of possibilities and then pick the most optimal path. For example, this is used a lot in strategy games such as Chess, networking, resource allocation, scheduling, and so on. Knowledge representation: The facts about the world around us need to be represented in some way for a system to make sense of them. The languages of mathematical logic are frequently used here. If knowledge is represented efficiently, systems can be smarter and more intelligent. Ontology is a closely related field of study that deals with the kinds of objects that exist. It is a formal definition of the properties and relationships of the entities that exist in a particular domain. This is usually done with a particular taxonomy or a hierarchical structure of some kind. The following diagram shows the difference between information and knowledge:
[ 15 ]

Introduction to Artificial Intelligence
Planning: This field deals with optimal planning that gives us maximum returns with minimal costs. These software programs start with facts about the particular situation and a statement of a goal. These programs are also aware of the facts of the world, so that they know what the rules are. From this information, they generate the most optimal plan to achieve the goal. Heuristics: A heuristic is a technique used to solve a given problem that's practical and useful in solving the problem in the short term, but not guaranteed to be optimal. This is more like an educated guess on what approach we should take to solve a problem. In AI, we frequently encounter situations where we cannot check every single possibility to pick the best option. So we need to use heuristics to achieve the goal. They are used extensively in AI in fields such as robotics, search engines, and so on. Genetic programming: Genetic programming is a way to get programs to solve a task, by mating programs and selecting the fittest. The programs are encoded as a set of genes, using an algorithm to get a program that is able to perform the given task really well.
Defining intelligence using Turing Test
The legendary computer scientist and mathematician, Alan Turing, proposed the Turing Test to provide a definition of intelligence. It is a test to see if a computer can learn to mimic human behavior. He defined intelligent behavior as the ability to achieve human-level intelligence during a conversation. This performance should be sufficient to trick an interrogator into thinking that the answers are coming from a human.
To see if a machine can do this, he proposed a test setup: he proposed that a human should interrogate the machine through a text interface. Another constraint is that the human cannot know who's on the other side of the interrogation, which means it can either be a machine or a human. To enable this setup, a human will be interacting with two entities through a text interface. These two entities are called respondents. One of them will be a human and the other one will be the machine.
[ 16 ]

Introduction to Artificial Intelligence
The respondent machine passes the test if the interrogator is unable to tell whether the answers are coming from a machine or a human. The following diagram shows the setup of a Turing Test:
As you can imagine, this is quite a difficult task for the respondent machine. There are a lot of things going on during a conversation. At the very minimum, the machine needs to be well versed with the following things:
Natural Language Processing: The machine needs this to communicate with the interrogator. The machine needs to parse the sentence, extract the context, and give an appropriate answer. Knowledge Representation: The machine needs to store the information provided before the interrogation. It also needs to keep track of the information being provided during the conversation so that it can respond appropriately if it comes up again.
[ 17 ]

Introduction to Artificial Intelligence
Reasoning: It's important for the machine to understand how to interpret the information that gets stored. Humans tend to do this automatically to draw conclusions in real time. Machine Learning: This is needed so that the machine can adapt to new conditions in real time. The machine needs to analyze and detect patterns so that it can draw inferences. You must be wondering why the human is communicating with a text interface. According to Turing, physical simulation of a person is unnecessary for intelligence. That's the reason the Turing Test avoids direct physical interaction between the human and the machine. There is another thing called the Total Turing Test that deals with vision and movement. To pass this test, the machine needs to see objects using computer vision and move around using Robotics.
Making machines think like humans
For decades, we have been trying to get the machine to think like a human. In order to make this happen, we need to understand how humans think in the first place. How do we understand the nature of human thinking? One way to do this would be to note down how we respond to things. But this quickly becomes intractable, because there are too many things to note down. Another way to do this is to conduct an experiment based on a predefined format. We develop a certain number of questions to encompass a wide variety of human topics, and then see how people respond to it. Once we gather enough data, we can create a model to simulate the human process. This model can be used to create software that can think like humans. Of course this is easier said than done! All we care about is the output of the program given a particular input. If the program behaves in a way that matches human behavior, then we can say that humans have a similar thinking mechanism.
[ 18 ]

Introduction to Artificial Intelligence
The following diagram shows different levels of thinking and how our brain prioritizes things:
Within computer science, there is a field of study called Cognitive Modeling that deals with simulating the human thinking process. It tries to understand how humans solve problems. It takes the mental processes that go into this problem solving process and turns it into a software model. This model can then be used to simulate human behavior. Cognitive modeling is used in a variety of AI applications such as deep learning, expert systems, Natural Language Processing, robotics, and so on.
[ 19 ]

Introduction to Artificial Intelligence
Building rational agents
A lot of research in AI is focused on building rational agents. What exactly is a rational agent? Before that, let us define the word rationality. Rationality refers to doing the right thing in a given circumstance. This needs to be performed in such a way that there is maximum benefit to the entity performing the action. An agent is said to act rationally if, given a set of rules, it takes actions to achieve its goals. It just perceives and acts according to the information that's available. This system is used a lot in AI to design robots when they are sent to navigate unknown terrains. How do we define the right thing? The answer is that it depends on the objectives of the agent. The agent is supposed to be intelligent and independent. We want to impart the ability to adapt to new situations. It should understand its environment and then act accordingly to achieve an outcome that is in its best interests. The best interests are dictated by the overall goal it wants to achieve. Let's see how an input gets converted to action:
[ 20 ]

Introduction to Artificial Intelligence
How do we define the performance measure for a rational agent? One might say that it is directly proportional to the degree of success. The agent is set up to achieve a particular task, so the performance measure depends on what percentage of that task is complete. But we must think as to what constitutes rationality in its entirety. If it's just about results, can the agent take any action to get there?
Making the right inferences is definitely a part of being rational, because the agent has to act rationally to achieve its goals. This will help it draw conclusions that can be used successively. What about situations where there are no provably right things to do? There are situations where the agent doesn't know what to do, but it still has to do something. In this situation, we cannot include the concept of inference to define rational behavior.
General Problem Solver
The General Problem Solver (GPS) was an AI program proposed by Herbert Simon, J.C. Shaw, and Allen Newell. It was the first useful computer program that came into existence in the AI world. The goal was to make it work as a universal problem-solving machine. Of course there were many software programs that existed before, but these programs performed specific tasks. GPS was the first program that was intended to solve any general problem. GPS was supposed to solve all the problems using the same base algorithm for every problem.
As you must have realized, this is quite an uphill battle! To program the GPS, the authors created a new language called Information Processing Language (IPL). The basic premise is to express any problem with a set of well-formed formulas. These formulas would be a part of a directed graph with multiple sources and sinks. In a graph, the source refers to the starting node and the sink refers to the ending node. In the case of GPS, the source refers to axioms and the sink refers to the conclusions.
Even though GPS was intended to be a general purpose, it could only solve well-defined problems, such as proving mathematical theorems in geometry and logic. It could also solve word puzzles and play chess. The reason was that these problems could be formalized to a reasonable extent. But in the real world, this quickly becomes intractable because of the number of possible paths you can take. If it tries to brute force a problem by counting the number of walks in a graph, it becomes computationally infeasible.
[ 21 ]

Introduction to Artificial Intelligence
Solving a problem with GPS
Let's see how to structure a given problem to solve it using GPS: 1. The first step is to define the goals. Let's say our goal is to get some milk from the grocery store. 2. The next step is to define the preconditions. These preconditions are in reference to the goals. To get milk from the grocery store, we need to have a mode of transportation and the grocery store should have milk available. 3. After this, we need to define the operators. If my mode of transportation is a car and if the car is low on fuel, then we need to ensure that we can pay the fueling station. We need to ensure that you can pay for the milk at the store.
An operator takes care of the conditions and everything that affects them. It consists of actions, preconditions, and the changes resulting from taking actions. In this case, the action is giving money to the grocery store. Of course, this is contingent upon you having the money in the first place, which is the precondition. By giving them the money, you are changing your money condition, which will result in you getting the milk. GPS will work as long as you can frame the problem like we did just now. The constraint is that it uses the search process to perform its job, which is way too computationally complex and time consuming for any meaningful real-world application.
Building an intelligent agent
There are many ways to impart intelligence to an agent. The most commonly used techniques include machine learning, stored knowledge, rules, and so on. In this section, we will focus on machine learning. In this method, the way we impart intelligence to an agent is through data and training.
[ 22 ]

Introduction to Artificial Intelligence
Let's see how an intelligent agent interacts with the environment:
With machine learning, we want to program our machines to use labeled data to solve a given problem. By going through the data and the associated labels, the machine learns how to extract patterns and relationships. In the preceding example, the intelligent agent depends on the learning model to run the inference engine. Once the sensor perceives the input, it sends it to the feature extraction block. Once the relevant features are extracted, the trained inference engine performs a prediction based on the learning model. This learning model is built using machine learning. The inference engine then takes a decision and sends it to the actuator, which then takes the required action in the real world. There are many applications of machine learning that exist today. It is used in image recognition, robotics, speech recognition, predicting stock market behavior, and so on. In order to understand machine learning and build a complete solution, you will have to be familiar with many techniques from different fields such as pattern recognition, artificial neural networks, data mining, statistics, and so on.
[ 23 ]

Introduction to Artificial Intelligence
Types of models
There are two types of models in the AI world: Analytical models and Learned models. Before we had machines that could compute, people used to rely on analytical models. These models were derived using a mathematical formulation, which is basically a sequence of steps followed to arrive at a final equation. The problem with this approach is that it was based on human judgment. Hence these models were simplistic and inaccurate with just a few parameters. We then entered the world of computers. These computers were good at analyzing data. So, people increasingly started using learned models. These models are obtained through the process of training. During training, the machines look at many examples of inputs and outputs to arrive at the equation. These learned models are usually complex and accurate, with thousands of parameters. This gives rise to a very complex mathematical equation that governs the data. Machine Learning allows us to obtain these learned models that can be used in an inference engine. One of the best things about this is the fact that we don't need to derive the underlying mathematical formula. You don't need to know complex mathematics, because the machine derives the formula based on data. All we need to do is create the list of inputs and the corresponding outputs. The learned model that we get is just the relationship between labeled inputs and the desired outputs.
Installing Python 3
We will be using Python 3 throughout this book. Make sure you have installed the latest version of Python 3 on your machine. Type the following command on your Terminal to check:
$ python3 --version
If you see something like Python 3.x.x (where x.x are version numbers) printed on your terminal, you are good to go. If not, installing it is pretty straightforward.
[ 24 ]

Introduction to Artificial Intelligence
Installing on Ubuntu
Python 3 is already installed by default on Ubuntu 14.xx and above. If not, you can install it using the following command:
$ sudo apt-get install python3
Run the check command like we did earlier:
$ python3 --version
You should see the version number printed on your Terminal.
Installing on Mac OS X
If you are on Mac OS X, it is recommended that you use Homebrew to install Python 3. It is a great package installer for Mac OS X and it is really easy to use. If you don't have Homebrew, you can install it using the following command:
$ ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"
Let's update the package manager:
$ brew update
Let's install Python 3:
$ brew install python3
Run the check command like we did earlier:
$ python3 --version
You should see the version number printed on your Terminal.
[ 25 ]

Introduction to Artificial Intelligence
Installing on Windows
If you use Windows, it is recommended that you use a SciPy-stack compatible distribution of Python 3. Anaconda is pretty popular and easy to use. You can find the installation instructions at: https://www.continuum.io/downloads. If you want to check out other SciPy-stack compatible distributions of Python 3, you can find them at http://www.scipy.org/install.html. The good part about these distributions is that they come with all the necessary packages preinstalled. If you use one of these versions, you don't need to install the packages separately. Once you install it, run the check command like we did earlier:
$ python3 --version
You should see the version number printed on your Terminal.
Installing packages
During the course of this book, we will use various packages such as NumPy, SciPy, scikitlearn, and matplotlib. Make sure you install these packages before you proceed. If you use Ubuntu or Mac OS X, installing these packages is pretty straightforward. All these packages can be installed using a one-line command on the terminal. Here are the relevant links for installation:
NumPy: http://docs.scipy.org/doc/numpy-1.10.1/user/install.html SciPy: http://www.scipy.org/install.html scikit-learn: http://scikit-learn.org/stable/install.html matplotlib: http://matplotlib.org/1.4.2/users/installing.html If you are on Windows, you should have installed a SciPy-stack compatible version of Python 3.
[ 26 ]

Introduction to Artificial Intelligence
Loading data
In order to build a learning model, we need data that's representative of the world. Now that we have installed the necessary Python packages, let's see how to use the packages to interact with data. Go into the Python terminal by typing the following command:
$ python3
Let's import the package containing all the datasets:
>>> from sklearn import datasets
Let's load the house prices dataset:
>>> house_prices = datasets.load_boston()
Print the data:
>>> print(house_prices.data)
You will see an output like this printed on your Terminal:
[ 27 ]

Introduction to Artificial Intelligence
Let's check out the labels: You will see the following printed on your Terminal:
The actual array is larger, so the image represents the first few values in that array. There are also image datasets available in the scikit-learn package. Each image is of shape 8×8. Let's load it:
>>> digits = datasets.load_digits()
Print the fifth image:
>>> print(digits.images[4])
[ 28 ]

Introduction to Artificial Intelligence
You will see the following on your Terminal:
As you can see, it has eight rows and eight columns.
Summary
In this chapter, we learned what AI is all about and why we need to study it. We discussed various applications and branches of AI. We understood what the Turing test is and how it's conducted. We learned how to make machines think like humans. We discussed the concept of rational agents and how they should be designed. We learned about General Problem Solver (GPS) and how to solve a problem using GPS. We discussed how to develop an intelligent agent using machine learning. We covered different types of models as well. We discussed how to install Python 3 on various operating systems. We learned how to install the necessary packages required to build AI applications. We discussed how to use the packages to load data that's available in scikit-learn. In the next chapter, we will learn about supervised learning and how to build models for classification and regression.
[ 29 ]

2
Classification and Regression Using Supervised Learning
In this chapter, we are going to learn about classification and regression of data using supervised learning techniques. By the end of this chapter, you will know about these topics:
What is the difference between supervised and unsupervised learning? What is classification? How to preprocess data using various methods What is label encoding? How to build a logistic regression classifier What is Naïve Bayes classifier? What is a confusion matrix? What are Support Vector Machines and how to build a classifier based on that? What is linear and polynomial regression? How to build a linear regressor for single variable and multivariable data How to estimate housing prices using Support Vector Regressor
Supervised versus unsupervised learning
One of the most common ways to impart artificial intelligence into a machine is through machine learning. The world of machine learning is broadly divided into supervised and unsupervised learning. There are other divisions too, but we'll discuss those later.

Classification and Regression Using Supervised Learning
Supervised learning refers to the process of building a machine learning model that is based on labeled training data. For example, let's say that we want to build a system to automatically predict the income of a person, based on various parameters such as age, education, location, and so on. To do this, we need to create a database of people with all the necessary details and label it. By doing this, we are telling our algorithm what parameters correspond to what income. Based on this mapping, the algorithm will learn how to calculate the income of a person using the parameters provided to it.
Unsupervised learning refers to the process of building a machine learning model without relying on labeled training data. In some sense, it is the opposite of what we just discussed in the previous paragraph. Since there are no labels available, you need to extract insights based on just the data given to you. For example, let's say that we want to build a system where we have to separate a set of data points into multiple groups. The tricky thing here is that we don't know exactly what the criteria of separation should be. Hence, an unsupervised learning algorithm needs to separate the given dataset into a number of groups in the best way possible.
What is classification?
In this chapter, we will discuss supervised classification techniques. The process of classification is one such technique where we classify data into a given number of classes. During classification, we arrange data into a fixed number of categories so that it can be used most effectively and efficiently.
In machine learning, classification solves the problem of identifying the category to which a new data point belongs. We build the classification model based on the training dataset containing data points and the corresponding labels. For example, let's say that we want to check whether the given image contains a person's face or not. We would build a training dataset containing classes corresponding to these two classes: face and no-face. We then train the model based on the training samples we have. This trained model is then used for inference.
A good classification system makes it easy to find and retrieve data. This is used extensively in face recognition, spam identification, recommendation engines, and so on. The algorithms for data classification will come up with the right criteria to separate the given data into the given number of classes.
[ 31 ]

Classification and Regression Using Supervised Learning
We need to provide a sufficiently large number of samples so that it can generalize those criteria. If there is an insufficient number of samples, then the algorithm will overfit to the training data. This means that it won't perform well on unknown data because it fine-tuned the model too much to fit into the patterns observed in training data. This is actually a very common problem that occurs in the world of machine learning. It's good to consider this factor when you build various machine learning models.
Preprocessing data
We deal with a lot of raw data in the real world. Machine learning algorithms expect data to be formatted in a certain way before they start the training process. In order to prepare the data for ingestion by machine learning algorithms, we have to preprocess it and convert it into the right format. Let's see how to do it.
Create a new Python file and import the following packages:
import numpy as np from sklearn import preprocessing
Let's define some sample data:
input_data = np.array([[5.1, -2.9, 3.3], [-1.2, 7.8, -6.1], [3.9, 0.4, 2.1], [7.3, -9.9, -4.5]])
We will be talking about several different preprocessing techniques. Let's start with binarization:
Binarization Mean removal Scaling Normalization
Let's take a look at each technique, starting with the first.
Binarization
This process is used when we want to convert our numerical values into boolean values. Let's use an inbuilt method to binarize input data using 2.1 as the threshold value.
[ 32 ]

Classification and Regression Using Supervised Learning
Add the following lines to the same Python file:
# Binarize data data_binarized = preprocessing.Binarizer(threshold=2.1).transform(input_data) print("\nBinarized data:\n", data_binarized)
If you run the code, you will see the following output:
Binarized data: [[ 1. 0. 1.] [ 0. 1. 0.] [ 1. 0. 0.] [ 1. 0. 0.]]
As we can see here, all the values above 2.1 become 1. The remaining values become 0.
Mean removal
Removing the mean is a common preprocessing technique used in machine learning. It's usually useful to remove the mean from our feature vector, so that each feature is centered on zero. We do this in order to remove bias from the features in our feature vector. Add the following lines to the same Python file as in the previous section:
# Print mean and standard deviation print("\nBEFORE:") print("Mean =", input_data.mean(axis=0)) print("Std deviation =", input_data.std(axis=0))
The preceding line displays the mean and standard deviation of the input data. Let's remove the mean:
# Remove mean data_scaled = preprocessing.scale(input_data) print("\nAFTER:") print("Mean =", data_scaled.mean(axis=0)) print("Std deviation =", data_scaled.std(axis=0))
[ 33 ]

Classification and Regression Using Supervised Learning
If you run the code, you will see the following printed on your Terminal:
BEFORE: Mean = [ 3.775 -1.15 -1.3 ] Std deviation = [ 3.12039661 6.36651396 4.0620192 ] AFTER: Mean = [ 1.11022302e-16 0.00000000e+00 2.77555756e-17] Std deviation = [ 1. 1. 1.]
As seen from the values obtained, the mean value is very close to 0 and standard deviation is 1.

Scaling
In our feature vector, the value of each feature can vary between many random values. So it becomes important to scale those features so that it is a level playing field for the machine learning algorithm to train on. We don't want any feature to be artificially large or small just because of the nature of the measurements.

Add the following line to the same Python file:

# Min max scaling data_scaler_minmax = preprocessing.MinMaxScaler(feature_range=(0, 1)) data_scaled_minmax = data_scaler_minmax.fit_transform(input_data) print("\nMin max scaled data:\n", data_scaled_minmax)

If you run the code, you will see the following printed on your Terminal:

Min max scaled data:

[[ 0.74117647 0.39548023 1.

]

[ 0.

1.

0.

]

[ 0.6

0.5819209 0.87234043]

[ 1.

0.

0.17021277]]

Each row is scaled so that the maximum value is 1 and all the other values are relative to this value.

[ 34 ]

Classification and Regression Using Supervised Learning

Normalization
We use the process of normalization to modify the values in the feature vector so that we can measure them on a common scale. In machine learning, we use many different forms of normalization. Some of the most common forms of normalization aim to modify the values so that they sum up to 1. L1 normalization, which refers to Least Absolute Deviations, works by making sure that the sum of absolute values is 1 in each row. L2 normalization, which refers to least squares, works by making sure that the sum of squares is 1.

In general, L1 normalization technique is considered more robust than L2 normalization technique. L1 normalization technique is robust because it is resistant to outliers in the data. A lot of times, data tends to contain outliers and we cannot do anything about it. We want to use techniques that can safely and effectively ignore them during the calculations. If we are solving a problem where outliers are important, then maybe L2 normalization becomes a better choice.

Add the following lines to the same Python file:

# Normalize data data_normalized_l1 = preprocessing.normalize(input_data, norm='l1') data_normalized_l2 = preprocessing.normalize(input_data, norm='l2') print("\nL1 normalized data:\n", data_normalized_l1) print("\nL2 normalized data:\n", data_normalized_l2)

If you run the code, you will see the following printed on your Terminal:

L1 normalized data:

[[ 0.45132743 -0.25663717 0.2920354 ]

[-0.0794702 0.51655629 -0.40397351]

[ 0.609375 0.0625

0.328125 ]

[ 0.33640553 -0.4562212 -0.20737327]]

L2 normalized data:

[[ 0.75765788 -0.43082507 0.49024922]

[-0.12030718 0.78199664 -0.61156148]

[ 0.87690281 0.08993875 0.47217844]

[ 0.55734935 -0.75585734 -0.34357152]]

The code for this entire section is given in the preprocessing.py file.

[ 35 ]

Classification and Regression Using Supervised Learning
Label encoding
When we perform classification, we usually deal with a lot of labels. These labels can be in the form of words, numbers, or something else. The machine learning functions in sklearn expect them to be numbers. So if they are already numbers, then we can use them directly to start training. But this is not usually the case.
In the real world, labels are in the form of words, because words are human readable. We label our training data with words so that the mapping can be tracked. To convert word labels into numbers, we need to use a label encoder. Label encoding refers to the process of transforming the word labels into numerical form. This enables the algorithms to operate on our data.
Create a new Python file and import the following packages:
import numpy as np from sklearn import preprocessing
Define some sample labels:
# Sample input labels input_labels = ['red', 'black', 'red', 'green', 'black', 'yellow', 'white']
Create the label encoder object and train it:
# Create label encoder and fit the labels encoder = preprocessing.LabelEncoder() encoder.fit(input_labels)
Print the mapping between words and numbers:
# Print the mapping print("\nLabel mapping:") for i, item in enumerate(encoder.classes_):
print(item, '-->', i)
Let's encode a set of randomly ordered labels to see how it performs:
# Encode a set of labels using the encoder test_labels = ['green', 'red', 'black'] encoded_values = encoder.transform(test_labels) print("\nLabels =", test_labels) print("Encoded values =", list(encoded_values))
[ 36 ]

Classification and Regression Using Supervised Learning
Let's decode a random set of numbers:
# Decode a set of values using the encoder encoded_values = [3, 0, 4, 1] decoded_list = encoder.inverse_transform(encoded_values) print("\nEncoded values =", encoded_values) print("Decoded labels =", list(decoded_list))
If you run the code, you will see the following output:
You can check the mapping to see that the encoding and decoding steps are correct. The code for this section is given in the label_encoder.py file.
Logistic Regression classifier
Logistic regression is a technique that is used to explain the relationship between input variables and output variables. The input variables are assumed to be independent and the output variable is referred to as the dependent variable. The dependent variable can take only a fixed set of values. These values correspond to the classes of the classification problem. Our goal is to identify the relationship between the independent variables and the dependent variables by estimating the probabilities using a logistic function. This logistic function is a sigmoid curve that's used to build the function with various parameters. It is very closely related to generalized linear model analysis, where we try to fit a line to a bunch of points to minimize the error. Instead of using linear regression, we use logistic regression. Logistic regression by itself is actually not a classification technique, but we use it in this way so as to facilitate classification. It is used very commonly in machine learning because of its simplicity. Let's see how to build a classifier using logistic regression. Make sure you have Tkinter package installed on your system before you proceed. If you don't, you can find it at: https://docs.python.org/2/library/tkinter.html.
[ 37 ]

Classification and Regression Using Supervised Learning
Create a new Python file and import the following packages. We will be importing a function from the file utilities.py. We will be looking into that function very soon. But for now, let's import it:
import numpy as np from sklearn import linear_model import matplotlib.pyplot as plt
from utilities import visualize_classifier
Define sample input data with two-dimensional vectors and corresponding labels:
# Define sample input data X = np.array([[3.1, 7.2], [4, 6.7], [2.9, 8], [5.1, 4.5], [6, 5], [5.6, 5], [3.3, 0.4], [3.9, 0.9], [2.8, 1], [0.5, 3.4], [1, 4], [0.6, 4.9]]) y = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3])
We will train the classifier using this labeled data. Now create the logistic regression classifier object:
# Create the logistic regression classifier classifier = linear_model.LogisticRegression(solver='liblinear', C=1)
Train the classifier using the data that we defined earlier:
# Train the classifier classifier.fit(X, y)
Visualize the performance of the classifier by looking at the boundaries of the classes:
# Visualize the performance of the classifier visualize_classifier(classifier, X, y)
We need to define this function before we can use it. We will be using this multiple times in this chapter, so it's better to define it in a separate file and import the function. This function is given in the utilities.py file provided to you. Create a new Python file and import the following packages:
import numpy as np import matplotlib.pyplot as plt
[ 38 ]

Classification and Regression Using Supervised Learning
Create the function definition by taking the classifier object, input data, and labels as input parameters:
def visualize_classifier(classifier, X, y): # Define the minimum and maximum values for X and Y # that will be used in the mesh grid min_x, max_x = X[:, 0].min() - 1.0, X[:, 0].max() + 1.0 min_y, max_y = X[:, 1].min() - 1.0, X[:, 1].max() + 1.0
We also defined the minimum and maximum values of X and Y directions that will be used in our mesh grid. This grid is basically a set of values that is used to evaluate the function, so that we can visualize the boundaries of the classes. Define the step size for the grid and create it using the minimum and maximum values:
# Define the step size to use in plotting the mesh grid mesh_step_size = 0.01
# Define the mesh grid of X and Y values x_vals, y_vals = np.meshgrid(np.arange(min_x, max_x, mesh_step_size), np.arange(min_y, max_y, mesh_step_size))
Run the classifier on all the points on the grid:
# Run the classifier on the mesh grid output = classifier.predict(np.c_[x_vals.ravel(), y_vals.ravel()])
# Reshape the output array output = output.reshape(x_vals.shape)
Create the figure, pick a color scheme, and overlay all the points:
# Create a plot plt.figure()
# Choose a color scheme for the plot plt.pcolormesh(x_vals, y_vals, output, cmap=plt.cm.gray)
# Overlay the training points on the plot plt.scatter(X[:, 0], X[:, 1], c=y, s=75, edgecolors='black', linewidth=1, cmap=plt.cm.Paired)
[ 39 ]

Classification and Regression Using Supervised Learning
Specify the boundaries of the plots using the minimum and maximum values, add the tick marks, and display the figure:
# Specify the boundaries of the plot plt.xlim(x_vals.min(), x_vals.max()) plt.ylim(y_vals.min(), y_vals.max()) # Specify the ticks on the X and Y axes plt.xticks((np.arange(int(X[:, 0].min() - 1), int(X[:, 0].max() + 1), 1.0))) plt.yticks((np.arange(int(X[:, 1].min() - 1), int(X[:, 1].max() + 1), 1.0))) plt.show()
If you run the code, you will see the following screenshot:
[ 40 ]

Classification and Regression Using Supervised Learning
If you change the value of C to 100 in the following line, you will see that the boundaries become more accurate:
classifier = linear_model.LogisticRegression(solver='liblinear', C=100)
The reason is that C imposes a certain penalty on misclassification, so the algorithm customizes more to the training data. You should be careful with this parameter, because if you increase it by a lot, it will overfit to the training data and it won't generalize well. If you run the code with C set to 100, you will see the following screenshot:
If you compare with the earlier figure, you will see that the boundaries are now better. The code for this section is given in the logistic_regression.py file.
[ 41 ]

Classification and Regression Using Supervised Learning
Naïve Bayes classifier
Naïve Bayes is a technique used to build classifiers using Bayes theorem. Bayes theorem describes the probability of an event occurring based on different conditions that are related to this event. We build a Naïve Bayes classifier by assigning class labels to problem instances. These problem instances are represented as vectors of feature values. The assumption here is that the value of any given feature is independent of the value of any other feature. This is called the independence assumption, which is the naïve part of a Naïve Bayes classifier.
Given the class variable, we can just see how a given feature affects, it regardless of its affect on other features. For example, an animal may be considered a cheetah if it is spotted, has four legs, has a tail, and runs at about 70 MPH. A Naïve Bayes classifier considers that each of these features contributes independently to the outcome. The outcome refers to the probability that this animal is a cheetah. We don't concern ourselves with the correlations that may exist between skin patterns, number of legs, presence of a tail, and movement speed. Let's see how to build a Naïve Bayes classifier.
Create a new Python file and import the following packages:
import numpy as np import matplotlib.pyplot as plt from sklearn.Naïve_bayes import GaussianNB from sklearn import cross_validation
from utilities import visualize_classifier
We will be using the file data_multivar_nb.txt as the source of data. This file contains comma separated values in each line:
# Input file containing data input_file = 'data_multivar_nb.txt'
Let's load the data from this file:
# Load data from input file data = np.loadtxt(input_file, delimiter=',') X, y = data[:, :-1], data[:, -1]
Create an instance of the Naïve Bayes classifier. We will be using the Gaussian Naïve Bayes classifier here. In this type of classifier, we assume that the values associated in each class follow a Gaussian distribution:
# Create Naïve Bayes classifier classifier = GaussianNB()
[ 42 ]

Classification and Regression Using Supervised Learning
Train the classifier using the training data:
# Train the classifier classifier.fit(X, y)
Run the classifier on the training data and predict the output:
# Predict the values for training data y_pred = classifier.predict(X)
Let's compute the accuracy of the classifier by comparing the predicted values with the true labels, and then visualize the performance:
# Compute accuracy accuracy = 100.0 * (y == y_pred).sum() / X.shape[0] print("Accuracy of Naïve Bayes classifier =", round(accuracy, 2), "%")
# Visualize the performance of the classifier visualize_classifier(classifier, X, y)
The preceding method to compute the accuracy of the classifier is not very robust. We need to perform cross validation, so that we don't use the same training data when we are testing it. Split the data into training and testing subsets. As specified by the test_size parameter in the line below, we will allocate 80% for training and the remaining 20% for testing. We'll then train a Naïve Bayes classifier on this data:
# Split data into training and test data X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2, random_state=3) classifier_new = GaussianNB() classifier_new.fit(X_train, y_train) y_test_pred = classifier_new.predict(X_test)
Compute the accuracy of the classifier and visualize the performance:
# compute accuracy of the classifier accuracy = 100.0 * (y_test == y_test_pred).sum() / X_test.shape[0] print("Accuracy of the new classifier =", round(accuracy, 2), "%")
# Visualize the performance of the classifier visualize_classifier(classifier_new, X_test, y_test)
[ 43 ]

Classification and Regression Using Supervised Learning
Let's use the inbuilt functions to calculate the accuracy, precision, and recall values based on threefold cross validation:
num_folds = 3 accuracy_values = cross_validation.cross_val_score(classifier,
X, y, scoring='accuracy', cv=num_folds) print("Accuracy: " + str(round(100*accuracy_values.mean(), 2)) + "%") precision_values = cross_validation.cross_val_score(classifier,
X, y, scoring='precision_weighted', cv=num_folds) print("Precision: " + str(round(100*precision_values.mean(), 2)) + "%") recall_values = cross_validation.cross_val_score(classifier,
X, y, scoring='recall_weighted', cv=num_folds) print("Recall: " + str(round(100*recall_values.mean(), 2)) + "%") f1_values = cross_validation.cross_val_score(classifier,
X, y, scoring='f1_weighted', cv=num_folds) print("F1: " + str(round(100*f1_values.mean(), 2)) + "%")
If you run the code, you will see this for the first training run:
[ 44 ]

Classification and Regression Using Supervised Learning
The preceding screenshot shows the boundaries obtained from the classifier. We can see that they separate the 4 clusters well and create regions with boundaries based on the distribution of the input datapoints. You will see in the following screenshot the second training run with cross validation:
[ 45 ]

Classification and Regression Using Supervised Learning
You will see the following printed on your Terminal:
Accuracy of Naïve Bayes classifier = 99.75 % Accuracy of the new classifier = 100.0 % Accuracy: 99.75% Precision: 99.76% Recall: 99.75% F1: 99.75%
The code for this section is given in the file naive_bayes.py.
Confusion matrix
A Confusion matrix is a figure or a table that is used to describe the performance of a classifier. It is usually extracted from a test dataset for which the ground truth is known. We compare each class with every other class and see how many samples are misclassified. During the construction of this table, we actually come across several key metrics that are very important in the field of machine learning. Let's consider a binary classification case where the output is either 0 or 1:
True positives: These are the samples for which we predicted 1 as the output and the ground truth is 1 too. True negatives: These are the samples for which we predicted 0 as the output and the ground truth is 0 too. False positives: These are the samples for which we predicted 1 as the output but the ground truth is 0. This is also known as a Type I error. False negatives: These are the samples for which we predicted 0 as the output but the ground truth is 1. This is also known as a Type II error.
Depending on the problem at hand, we may have to optimize our algorithm to reduce the false positive or the false negative rate. For example, in a biometric identification system, it is very important to avoid false positives, because the wrong people might get access to sensitive information. Let's see how to create a confusion matrix.
Create a new Python file and import the following packages:
import numpy as np import matplotlib.pyplot as plt from sklearn.metrics import confusion_matrix from sklearn.metrics import classification_report
[ 46 ]

Classification and Regression Using Supervised Learning
Define some samples labels for the ground truth and the predicted output:
# Define sample labels true_labels = [2, 0, 0, 2, 4, 4, 1, 0, 3, 3, 3] pred_labels = [2, 1, 0, 2, 4, 3, 1, 0, 1, 3, 3]
Create the confusion matrix using the labels we just defined:
# Create confusion matrix confusion_mat = confusion_matrix(true_labels, pred_labels)
Visualize the confusion matrix:
# Visualize confusion matrix plt.imshow(confusion_mat, interpolation='nearest', cmap=plt.cm.gray) plt.title('Confusion matrix') plt.colorbar() ticks = np.arange(5) plt.xticks(ticks, ticks) plt.yticks(ticks, ticks) plt.ylabel('True labels') plt.xlabel('Predicted labels') plt.show()
In the above visualization code, the ticks variable refers to the number of distinct classes. In our case, we have five distinct labels. Let's print the classification report:
# Classification report targets = ['Class-0', 'Class-1', 'Class-2', 'Class-3', 'Class-4'] print('\n', classification_report(true_labels, pred_labels, target_names=targets))
[ 47 ]

Classification and Regression Using Supervised Learning
The classification report prints the performance for each class. If you run the code, you will see the following screenshot:
[ 48 ]

Classification and Regression Using Supervised Learning
White indicates higher values, whereas black indicates lower values as seen on the color map slider. In an ideal scenario, the diagonal squares will be all white and everything else will be black. This indicates 100% accuracy. You will see the following printed on your Terminal:
The code for this section is given in the file confusion_matrix.py.
Support Vector Machines
A Support Vector Machine (SVM) is a classifier that is defined using a separating hyperplane between the classes. This hyperplane is the N-dimensional version of a line. Given labeled training data and a binary classification problem, the SVM finds the optimal hyperplane that separates the training data into two classes. This can easily be extended to the problem with N classes. Let's consider a two-dimensional case with two classes of points. Given that it's 2D, we only have to deal with points and lines in a 2D plane. This is easier to visualize than vectors and hyperplanes in a high-dimensional space. Of course, this is a simplified version of the SVM problem, but it is important to understand it and visualize it before we can apply it to highdimensional data.
[ 49 ]

Classification and Regression Using Supervised Learning
Consider the following figure:
There are two classes of points and we want to find the optimal hyperplane to separate the two classes. But how do we define optimal? In this picture, the solid line represents the best hyperplane. You can draw many different lines to separate the two classes of points, but this line is the best separator, because it maximizes the distance of each point from the separating line. The points on the dotted lines are called Support Vectors. The perpendicular distance between the two dotted lines is called maximum margin.
[ 50 ]

Classification and Regression Using Supervised Learning
Classifying income data using Support Vector Machines
We will build a Support Vector Machine classifier to predict the income bracket of a given person based on 14 attributes. Our goal is to see where the income is higher or lower than $50,000 per year. Hence this is a binary classification problem. We will be using the census income dataset available at https://archive.ics.uci.edu/ml/datasets/Census+Income. One thing to note in this dataset is that each datapoint is a mixture of words and numbers. We cannot use the data in its raw format, because the algorithms don't know how to deal with words. We cannot convert everything using label encoder because numerical data is valuable. Hence we need to use a combination of label encoders and raw numerical data to build an effective classifier.
Create a new Python file and import the following packages:
import numpy as np import matplotlib.pyplot as plt from sklearn import preprocessing from sklearn.svm import LinearSVC from sklearn.multiclass import OneVsOneClassifier from sklearn import cross_validation
We will be using the file income_data.txt to load the data. This file contains the income details:
# Input file containing data input_file = 'income_data.txt'
In order to load the data from the file, we need to preprocess it so that we can prepare it for classification. We will use at most 25,000 data points for each class:
# Read the data X = [] y = [] count_class1 = 0 count_class2 = 0 max_datapoints = 25000
[ 51 ]

Classification and Regression Using Supervised Learning
Open the file and start reading the lines:
with open(input_file, 'r') as f: for line in f.readlines(): if count_class1 >= max_datapoints and count_class2 >=
max_datapoints: break
if '?' in line: continue
Each line is comma separated, so we need to split it accordingly. The last element in each line represents the label. Depending on that label, we will assign it to a class:
data = line[:-1].split(', ')
if data[-1] == '<=50K' and count_class1 < max_datapoints: X.append(data) count_class1 += 1
if data[-1] == '>50K' and count_class2 < max_datapoints: X.append(data) count_class2 += 1
Convert the list into a numpy array so that we can give it as an input to the sklearn function:
# Convert to numpy array X = np.array(X)
If any attribute is a string, then we need to encode it. If it is a number, we can keep it as it is. Note that we will end up with multiple label encoders and we need to keep track of all of them:
# Convert string data to numerical data label_encoder = [] X_encoded = np.empty(X.shape) for i,item in enumerate(X[0]):
if item.isdigit(): X_encoded[:, i] = X[:, i]
else: label_encoder.append(preprocessing.LabelEncoder()) X_encoded[:, i] = label_encoder[-1].fit_transform(X[:, i])
X = X_encoded[:, :-1].astype(int) y = X_encoded[:, -1].astype(int)
[ 52 ]

Classification and Regression Using Supervised Learning
Create the SVM classifier with a linear kernel:
# Create SVM classifier classifier = OneVsOneClassifier(LinearSVC(random_state=0))
Train the classifier:
# Train the classifier classifier.fit(X, y)
Perform cross validation using an 80/20 split for training and testing, and then predict the output for training data:
# Cross validation X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.2, random_state=5) classifier = OneVsOneClassifier(LinearSVC(random_state=0)) classifier.fit(X_train, y_train) y_test_pred = classifier.predict(X_test)
Compute the F1 score for the classifier:
# Compute the F1 score of the SVM classifier f1 = cross_validation.cross_val_score(classifier, X, y, scoring='f1_weighted', cv=3) print("F1 score: " + str(round(100*f1.mean(), 2)) + "%")
Now that the classifier is ready, let's see how to take a random input data point and predict the output. Let's define one such data point:
# Predict output for a test datapoint input_data = ['37', 'Private', '215646', 'HS-grad', '9', 'Never-married', 'Handlers-cleaners', 'Not-in-family', 'White', 'Male', '0', '0', '40', 'United-States']
Before we can perform prediction, we need to encode this data point using the label encoders we created earlier:
# Encode test datapoint input_data_encoded = [-1] * len(input_data) count = 0 for i, item in enumerate(input_data):
if item.isdigit(): input_data_encoded[i] = int(input_data[i])
else: input_data_encoded[i] =
int(label_encoder[count].transform(input_data[i])) count += 1
[ 53 ]

Classification and Regression Using Supervised Learning
input_data_encoded = np.array(input_data_encoded)
We are now ready to predict the output using the classifier:
# Run classifier on encoded datapoint and print output predicted_class = classifier.predict(input_data_encoded) print(label_encoder[-1].inverse_transform(predicted_class)[0])
If you run the code, it will take a few seconds to train the classifier. Once it's done, you will see the following printed on your Terminal:
F1 score: 66.82%
You will also see the output for the test data point:
<=50K
If you check the values in that data point, you will see that it closely corresponds to the data points in the less than 50K class. You can change the performance of the classifier (F1 score, precision, or recall) by using various different kernels and trying out multiple combinations of the parameters.
The code for this section is given in the file income_classifier.py.
What is Regression?
Regression is the process of estimating the relationship between input and output variables. One thing to note is that the output variables are continuous-valued real numbers. Hence there are an infinite number of possibilities. This is in contrast with classification, where the number of output classes is fixed. The classes belong to a finite set of possibilities.
In regression, it is assumed that the output variables depend on the input variables, so we want to see how they are related. Consequently, the input variables are called independent variables, also known as predictors, and output variables are called dependent variables, also known as criterion variables. It is not necessary that the input variables are independent of each other. There are a lot of situations where there are correlations between input variables.
Regression analysis helps us in understanding how the value of the output variable changes when we vary some input variables while keeping other input variables fixed. In linear regression, we assume that the relationship between input and output is linear. This puts a constraint on our modeling procedure, but it's fast and efficient.
[ 54 ]

Classification and Regression Using Supervised Learning
Sometimes, linear regression is not sufficient to explain the relationship between input and output. Hence we use polynomial regression, where we use a polynomial to explain the relationship between input and output. This is more computationally complex, but gives higher accuracy. Depending on the problem at hand, we use different forms of regression to extract the relationship. Regression is frequently used for prediction of prices, economics, variations, and so on.
Building a single variable regressor
Let's see how to build a single variable regression model. Create a new Python file and import the following packages:
import pickle
import numpy as np from sklearn import linear_model import sklearn.metrics as sm import matplotlib.pyplot as plt
We will use the file data_singlevar_regr.txt provided to you. This is our source of data:
# Input file containing data input_file = 'data_singlevar_regr.txt'
It's a comma-separated file, so we can easily load it using a one-line function call:
# Read data data = np.loadtxt(input_file, delimiter=',') X, y = data[:, :-1], data[:, -1]
Split it into training and testing:
# Train and test split num_training = int(0.8 * len(X)) num_test = len(X) - num_training
# Training data X_train, y_train = X[:num_training], y[:num_training]
# Test data X_test, y_test = X[num_training:], y[num_training:]
[ 55 ]

Classification and Regression Using Supervised Learning
Create a linear regressor object and train it using the training data:
# Create linear regressor object regressor = linear_model.LinearRegression()
# Train the model using the training sets regressor.fit(X_train, y_train)
Predict the output for the testing dataset using the training model:
# Predict the output y_test_pred = regressor.predict(X_test)
Plot the output:
# Plot outputs plt.scatter(X_test, y_test, color='green') plt.plot(X_test, y_test_pred, color='black', linewidth=4) plt.xticks(()) plt.yticks(()) plt.show()
Compute the performance metrics for the regressor by comparing the ground truth, which refers to the actual outputs, with the predicted outputs:
# Compute performance metrics print("Linear regressor performance:") print("Mean absolute error =", round(sm.mean_absolute_error(y_test, y_test_pred), 2)) print("Mean squared error =", round(sm.mean_squared_error(y_test, y_test_pred), 2)) print("Median absolute error =", round(sm.median_absolute_error(y_test, y_test_pred), 2)) print("Explain variance score =", round(sm.explained_variance_score(y_test, y_test_pred), 2)) print("R2 score =", round(sm.r2_score(y_test, y_test_pred), 2))
Once the model has been created, we can save it into a file so that we can use it later. Python provides a nice module called pickle that enables us to do this:
# Model persistence output_model_file = 'model.pkl'
# Save the model with open(output_model_file, 'wb') as f:
pickle.dump(regressor, f)
[ 56 ]

Classification and Regression Using Supervised Learning
Let's load the model from the file on the disk and perform prediction:
# Load the model with open(output_model_file, 'rb') as f:
regressor_model = pickle.load(f) # Perform prediction on test data y_test_pred_new = regressor_model.predict(X_test) print("\nNew mean absolute error =", round(sm.mean_absolute_error(y_test, y_test_pred_new), 2))
If you run the code, you will see the following screenshot:
[ 57 ]

Classification and Regression Using Supervised Learning
You will see the following printed on your Terminal:
Linear regressor performance: Mean absolute error = 0.59 Mean squared error = 0.49 Median absolute error = 0.51 Explain variance score = 0.86 R2 score = 0.86 New mean absolute error = 0.59
The code for this section is given in the file regressor_singlevar.py.
Building a multivariable regressor
In the previous section, we discussed how to build a regression model for a single variable. In this section, we will deal with multidimensional data. Create a new Python file and import the following packages:
import numpy as np from sklearn import linear_model import sklearn.metrics as sm from sklearn.preprocessing import PolynomialFeatures
We will use the file data_multivar_regr.txt provided to you.
# Input file containing data input_file = 'data_multivar_regr.txt'
This is a comma-separated file, so we can load it easily with a one-line function call:
# Load the data from the input file data = np.loadtxt(input_file, delimiter=',') X, y = data[:, :-1], data[:, -1]
Split the data into training and testing:
# Split data into training and testing num_training = int(0.8 * len(X)) num_test = len(X) - num_training
# Training data X_train, y_train = X[:num_training], y[:num_training]
# Test data X_test, y_test = X[num_training:], y[num_training:]
[ 58 ]

Classification and Regression Using Supervised Learning
Create and train the linear regressor model:
# Create the linear regressor model linear_regressor = linear_model.LinearRegression()
# Train the model using the training sets linear_regressor.fit(X_train, y_train)
Predict the output for the test dataset:
# Predict the output y_test_pred = linear_regressor.predict(X_test)
Print the performance metrics:
# Measure performance print("Linear Regressor performance:") print("Mean absolute error =", round(sm.mean_absolute_error(y_test, y_test_pred), 2)) print("Mean squared error =", round(sm.mean_squared_error(y_test, y_test_pred), 2)) print("Median absolute error =", round(sm.median_absolute_error(y_test, y_test_pred), 2)) print("Explained variance score =", round(sm.explained_variance_score(y_test, y_test_pred), 2)) print("R2 score =", round(sm.r2_score(y_test, y_test_pred), 2))
Create a polynomial regressor of degree 10. Train the regressor on the training dataset. Let's take a sample data point and see how to perform prediction. The first step is to transform it into a polynomial:
# Polynomial regression polynomial = PolynomialFeatures(degree=10) X_train_transformed = polynomial.fit_transform(X_train) datapoint = [[7.75, 6.35, 5.56]] poly_datapoint = polynomial.fit_transform(datapoint)
If you look closely, this data point is very close to the data point on line 11 in our data file, which is [7.66, 6.29, 5.66]. So, a good regressor should predict an output that's close to 41.35. Create a linear regressor object and perform the polynomial fit. Perform the prediction using both linear and polynomial regressors to see the difference:
poly_linear_model = linear_model.LinearRegression() poly_linear_model.fit(X_train_transformed, y_train) print("\nLinear regression:\n", linear_regressor.predict(datapoint)) print("\nPolynomial regression:\n", poly_linear_model.predict(poly_datapoint))
[ 59 ]

Classification and Regression Using Supervised Learning
If you run the code, you will see the following printed on your Terminal:
Linear Regressor performance: Mean absolute error = 3.58 Mean squared error = 20.31 Median absolute error = 2.99 Explained variance score = 0.86 R2 score = 0.86
You will see the following as well:
Linear regression: [ 36.05286276]
Polynomial regression: [ 41.46961676]
As you can see, the polynomial regressor is closer to 41.35. The code for this section is given in the file regressor_multivar.py.
Estimating housing prices using a Support Vector Regressor
Let's see how to use the SVM concept to build a regressor to estimate the housing prices. We will use the dataset available in sklearn where each data point is define, by 13 attributes. Our goal is to estimate the housing prices based on these attributes.
Create a new Python file and import the following packages:
import numpy as np from sklearn import datasets from sklearn.svm import SVR from sklearn.metrics import mean_squared_error, explained_variance_score from sklearn.utils import shuffle
Load the housing dataset:
# Load housing data data = datasets.load_boston()
Let's shuffle the data so that we don't bias our analysis:
# Shuffle the data X, y = shuffle(data.data, data.target, random_state=7)
[ 60 ]

Classification and Regression Using Supervised Learning
Split the dataset into training and testing in an 80/20 format:
# Split the data into training and testing datasets num_training = int(0.8 * len(X)) X_train, y_train = X[:num_training], y[:num_training] X_test, y_test = X[num_training:], y[num_training:]
Create and train the Support Vector Regressor using a linear kernel. The C parameter represents the penalty for training error. If you increase the value of C, the model will finetune it more to fit the training data. But this might lead to overfitting and cause it to lose its generality. The epsilon parameter specifies a threshold; there is no penalty for training error if the predicted value is within this distance from the actual value:
# Create Support Vector Regression model sv_regressor = SVR(kernel='linear', C=1.0, epsilon=0.1)
# Train Support Vector Regressor sv_regressor.fit(X_train, y_train)
Evaluate the performance of the regressor and print the metrics:
# Evaluate performance of Support Vector Regressor y_test_pred = sv_regressor.predict(X_test) mse = mean_squared_error(y_test, y_test_pred) evs = explained_variance_score(y_test, y_test_pred) print("\n#### Performance ####") print("Mean squared error =", round(mse, 2)) print("Explained variance score =", round(evs, 2))
Let's take a test data point and perform prediction:
# Test the regressor on test datapoint test_data = [3.7, 0, 18.4, 1, 0.87, 5.95, 91, 2.5052, 26, 666, 20.2, 351.34, 15.27] print("\nPredicted price:", sv_regressor.predict([test_data])[0])
If you run the code, you will see the following printed on the Terminal:
#### Performance #### Mean squared error = 15.41 Explained variance score = 0.82 Predicted price: 18.5217801073
The code for this section is given in the file house_prices.py.
[ 61 ]

Classification and Regression Using Supervised Learning
Summary
In this chapter, we learned the difference between supervised and unsupervised learning. We discussed the data classification problem and how to solve it. We understood how to preprocess data using various methods. We also learned about label encoding and how to build a label encoder. We discussed logistic regression and built a logistic regression classifier. We understood what Naïve Bayes classifier is and learned how to build it. We also learned how to build a confusion matrix. We discussed Support Vector Machines and understood how to build a classifier based on that. We learned about regression and understood how to use linear and polynomial regression for single and multivariable data. We then used Support Vector Regressor to estimate the housing prices using input attributes. In the next chapter, we will learn about predictive analytics and how to build a predictive engine using ensemble learning.
[ 62 ]

3
Predictive Analytics with Ensemble Learning
In this chapter, we are going to learn about Ensemble Learning and how to use it for predictive analytics. By the end of this chapter, you will know these topics:
Building learning models with Ensemble Learning What are Decision Trees and how to build a Decision Trees classifier What are Random Forests and Extremely Random Forests, and how to build classifiers based on them Estimating the confidence measure of the predictions Dealing with class imbalance Finding optimal training parameters using grid search Computing relative feature importance Predicting traffic using Extremely Random Forests regressor
What is Ensemble Learning?
Ensemble Learning refers to the process of building multiple models and then combining them in a way that can produce better results than individual models. These individual models can be classifiers, regressors, or anything else that models data in some way. Ensemble learning is used extensively across multiple fields including data classification, predictive modeling, anomaly detection, and so on.

Predictive Analytics with Ensemble Learning
Why do we need ensemble learning in the first place? In order to understand this, let's take a real-life example. You want to buy a new TV, but you don't know what the latest models are. Your goal is to get the best value for your money, but you don't have enough knowledge on this topic to make an informed decision. When you have to make a decision about something like this, you go around and try to get the opinions of multiple experts in the domain. This will help you make the best decision. More often than not, instead of just relying on a single opinion, you tend to make a final decision by combining the individual decisions of those experts. The reason we do that is because we want to minimize the possibility of a wrong or suboptimal decision.
Building learning models with Ensemble Learning
When we select a model, the most commonly used procedure is to choose the one with the smallest error on the training dataset. The problem with this approach is that it will not always work. The model might get biased or overfit the training data. Even when we compute the model using cross validation, it can perform poorly on unknown data.
One of the main reasons ensemble learning is so effective is because it reduces the overall risk of making a poor model selection. This enables it to train in a diverse manner and then perform well on unknown data. When we build a model using ensemble learning, the individual models need to exhibit some diversity. This would allow them to capture various nuances in our data; hence the overall model becomes more accurate.
The diversity is achieved by using different training parameters for each individual model. This allows individual models to generate different decision boundaries for training data. This means that each model will use different rules to make an inference, which is a powerful way of validating the final result. If there is agreement among the models, then we know that the output is correct.
What are Decision Trees?
A Decision Tree is a structure that allows us to split the dataset into branches and then make simple decisions at each level. This will allow us to arrive at the final decision by walking down the tree. Decision Trees are produced by training algorithms, which identify how we can split the data in the best possible way.
[ 64 ]

Predictive Analytics with Ensemble Learning
Any decision process starts at the root node at the top of the tree. Each node in the tree is basically a decision rule. Algorithms construct these rules based on the relationship between the input data and the target labels in the training data. The values in the input data are utilized to estimate the value for the output.
Now that we understand basic concept of Decision Trees, the next thing is to understand how the trees are automatically constructed. We need algorithms that can construct the optimal tree based on our data. In order to understand it, we need to understand the concept of entropy. In this context, entropy refers to information entropy and not thermodynamic entropy. Entropy is basically a measure of uncertainty. One of the main goals of a decision tree is to reduce uncertainty as we move from the root node towards the leaf nodes. When we see an unknown data point, we are completely uncertain about the output. By the time we reach the leaf node, we are certain about the output. This means that we need to construct the decision tree in a way that will reduce the uncertainty at each level. This implies that we need to reduce the entropy as we progress down the tree.
You can learn more about this at: https://prateekvjoshi.com
/2016/03/22/h o w - a r e - d e c i s i o n - t r e e s - c o n s t r u c t e d - i n - m a c h i n e - l e a r
ning.
Building a Decision Tree classifier
Let's see how to build a classifier using Decision Trees in Python. Create a new Python file and import the following packages:
import numpy as np import matplotlib.pyplot as plt from sklearn.metrics import classification_report from sklearn import cross_validation from sklearn.tree import DecisionTreeClassifier
from utilities import visualize_classifier
We will be using the data in the data_decision_trees.txt file that's provided to you. In this file, each line contains comma-separated values. The first two values correspond to the input data and the last value corresponds to the target label. Let's load the data from that file:
# Load input data input_file = 'data_decision_trees.txt' data = np.loadtxt(input_file, delimiter=',') X, y = data[:, :-1], data[:, -1]
[ 65 ]

Predictive Analytics with Ensemble Learning
Separate the input data into two separate classes based on the labels:
# Separate input data into two classes based on labels class_0 = np.array(X[y==0]) class_1 = np.array(X[y==1])
Let's visualize the input data using a scatter plot:
# Visualize input data plt.figure() plt.scatter(class_0[:, 0], class_0[:, 1], s=75, facecolors='black',
edgecolors='black', linewidth=1, marker='x') plt.scatter(class_1[:, 0], class_1[:, 1], s=75, facecolors='white',
edgecolors='black', linewidth=1, marker='o') plt.title('Input data')
We need to split the data into training and testing datasets:
# Split data into training and testing datasets X_train, X_test, y_train, y_test = cross_validation.train_test_split(
X, y, test_size=0.25, random_state=5)
Create, build, and visualize a decision tree classifier based on the training dataset. The random_state parameter refers to the seed used by the random number generator required for the initialization of the decision tree classification algorithm. The max_depth parameter refers to the maximum depth of the tree that we want to construct:
# Decision Trees classifier params = {'random_state': 0, 'max_depth': 4} classifier = DecisionTreeClassifier(**params) classifier.fit(X_train, y_train) visualize_classifier(classifier, X_train, y_train, 'Training dataset')
Compute the output of the classifier on the test dataset and visualize it:
y_test_pred = classifier.predict(X_test) visualize_classifier(classifier, X_test, y_test, 'Test dataset')
Evaluate the performance of the classifier by printing the classification report:
# Evaluate classifier performance class_names = ['Class-0', 'Class-1'] print("\n" + "#"*40) print("\nClassifier performance on training dataset\n") print(classification_report(y_train, classifier.predict(X_train), target_names=class_names)) print("#"*40 + "\n")
[ 66 ]

Predictive Analytics with Ensemble Learning print("#"*40) print("\nClassifier performance on test dataset\n") print(classification_report(y_test, y_test_pred, target_names=class_names)) print("#"*40 + "\n") plt.show()
The full code is given in the decision_trees.py file. If you run the code, you will see a few figures. The first screenshot is the visualization of input data:
[ 67 ]

Predictive Analytics with Ensemble Learning
The second screenshot shows the classifier boundaries on the test dataset:
[ 68 ]

Predictive Analytics with Ensemble Learning
You will see the following printed on your Terminal:
The performance of a classifier is characterized by precision, recall, and f1-scores. Precision refers to the accuracy of the classification and recall refers to the number of items that were retrieved as a percentage of the overall number of items that were supposed to be retrieved. A good classifier will have high precision and high recall, but it is usually a tradeoff between the two. Hence we have f1-score to characterize that. F1 score is the harmonic mean of precision and recall, which gives it a good balance between precision and recall values.
[ 69 ]

Predictive Analytics with Ensemble Learning
What are Random Forests and Extremely Random Forests?
A Random Forest is a particular instance of ensemble learning where individual models are constructed using Decision Trees. This ensemble of Decision Trees is then used to predict the output value. We use a random subset of training data to construct each Decision Tree. This will ensure diversity among various decision trees. In the first section, we discussed that one of the most important things in ensemble learning is to ensure that there's diversity among individual models.
One of the best things about Random Forests is that they do not overfit. As we know, overfitting is a problem that we encounter frequently in machine learning. By constructing a diverse set of Decision Trees using various random subsets, we ensure that the model does not overfit the training data. During the construction of the tree, the nodes are split successively and the best thresholds are chosen to reduce the entropy at each level. This split doesn't consider all the features in the input dataset. Instead, it chooses the best split among the random subset of the features that is under consideration. Adding this randomness tends to increase the bias of the random forest, but the variance decreases because of averaging. Hence, we end up with a robust model.
Extremely Random Forests take randomness to the next level. Along with taking a random subset of features, the thresholds are chosen at random too. These randomly generated thresholds are chosen as the splitting rules, which reduce the variance of the model even further. Hence the decision boundaries obtained using Extremely Random Forests tend to be smoother than the ones obtained using Random Forests.
Building Random Forest and Extremely Random Forest classifiers
Let's see how to build a classifier based on Random Forests and Extremely Random Forests. The way to construct both classifiers is very similar, so we will use an input flag to specify which classifier needs to be built.
[ 70 ]

Predictive Analytics with Ensemble Learning
Create a new Python file and import the following packages:
import argparse
import numpy as np import matplotlib.pyplot as plt from sklearn.metrics import classification_report from sklearn import cross_validation from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier from sklearn import cross_validation from sklearn.metrics import classification_report
from utilities import visualize_classifier
Define an argument parser for Python so that we can take the classifier type as an input parameter. Depending on this parameter, we can construct a Random Forest classifier or an Extremely Random forest classifier:
# Argument parser def build_arg_parser():
parser = argparse.ArgumentParser(description='Classify data using \ Ensemble Learning techniques')
parser.add_argument('--classifier-type', dest='classifier_type', required=True, choices=['rf', 'erf'], help="Type of
classifier \to use; can be either 'rf' or 'erf'")
return parser
Define the main function and parse the input arguments:
if __name__=='__main__': # Parse the input arguments args = build_arg_parser().parse_args() classifier_type = args.classifier_type
We will be using the data from the data_random_forests.txt file that is provided to you. Each line in this file contains comma-separated values. The first two values correspond to the input data and the last value corresponds to the target label. We have three distinct classes in this dataset. Let's load the data from that file:
# Load input data input_file = 'data_random_forests.txt' data = np.loadtxt(input_file, delimiter=',') X, y = data[:, :-1], data[:, -1]
[ 71 ]

Predictive Analytics with Ensemble Learning
Separate the input data into three classes:
# Separate input data into three classes based on labels class_0 = np.array(X[y==0]) class_1 = np.array(X[y==1]) class_2 = np.array(X[y==2])
Let's visualize the input data:
# Visualize input data plt.figure() plt.scatter(class_0[:, 0], class_0[:, 1], s=75, facecolors='white',
edgecolors='black', linewidth=1, marker='s') plt.scatter(class_1[:, 0], class_1[:, 1], s=75, facecolors='white',
edgecolors='black', linewidth=1, marker='o') plt.scatter(class_2[:, 0], class_2[:, 1], s=75, facecolors='white',
edgecolors='black', linewidth=1, marker='^') plt.title('Input data')
Split the data into training and testing datasets:
# Split data into training and testing datasets X_train, X_test, y_train, y_test = cross_validation.train_test_split(
X, y, test_size=0.25, random_state=5)
Define the parameters to be used when we construct the classifier. The n_estimators parameter refers to the number of trees that will be constructed. The max_depth parameter refers to the maximum number of levels in each tree. The random_state parameter refers to the seed value of the random number generator needed to initialize the random forest classifier algorithm:
# Ensemble Learning classifier params = {'n_estimators': 100, 'max_depth': 4, 'random_state': 0}
Depending on the input parameter, we either construct a random forest classifier or an extremely random forest classifier:
if classifier_type == 'rf': classifier = RandomForestClassifier(**params)
else: classifier = ExtraTreesClassifier(**params)
Train and visualize the classifier:
classifier.fit(X_train, y_train) visualize_classifier(classifier, X_train, y_train, 'Training dataset')
[ 72 ]

Predictive Analytics with Ensemble Learning
Compute the output based on the test dataset and visualize it:
y_test_pred = classifier.predict(X_test) visualize_classifier(classifier, X_test, y_test, 'Test dataset')
Evaluate the performance of the classifier by printing the classification report:
# Evaluate classifier performance class_names = ['Class-0', 'Class-1', 'Class-2'] print("\n" + "#"*40) print("\nClassifier performance on training dataset\n") print(classification_report(y_train, classifier.predict(X_train), target_names=class_names)) print("#"*40 + "\n") print("#"*40) print("\nClassifier performance on test dataset\n") print(classification_report(y_test, y_test_pred, target_names=class_names)) print("#"*40 + "\n")
The full code is given in the random_forests.py file. Let's run the code with the Random Forest classifier using the rf flag in the input argument. Run the following command on your Terminal:
$ python3 random_forests.py --classifier-type rf
You will see a few figures pop up. The first screenshot is the input data:
[ 73 ]

Predictive Analytics with Ensemble Learning
In the preceding screenshot, the three classes are being represented by squares, circles, and triangles. We see that there is a lot of overlap between classes, but that should be fine for now. The second screenshot shows the classifier boundaries:
Now let's run the code with the Extremely Random Forest classifier by using the erf flag in the input argument. Run the following command on your Terminal:
$ python3 random_forests.py --classifier-type erf [ 74 ]

Predictive Analytics with Ensemble Learning
You will see a few figures pop up. We already know what the input data looks like. The second screenshot shows the classifier boundaries:
[ 75 ]

Predictive Analytics with Ensemble Learning
If you compare the preceding screenshot with the boundaries obtained from Random Forest classifier, you will see that these boundaries are smoother. The reason is that Extremely Random Forests have more freedom during the training process to come up with good Decision Trees, hence they usually produce better boundaries.
Estimating the confidence measure of the predictions
If you observe the outputs obtained on the terminal, you will see that the probabilities are printed for each data point. These probabilities are used to measure the confidence values for each class. Estimating the confidence values is an important task in machine learning. In the same python file, add the following line to define an array of test data points:
# Compute confidence test_datapoints = np.array([[5, 5], [3, 6], [6, 4], [7, 2], [4, 4], [5, 2]])
The classifier object has an inbuilt method to compute the confidence measure. Let's classify each point and compute the confidence values:
print("\nConfidence measure:") for datapoint in test_datapoints:
probabilities = classifier.predict_proba([datapoint])[0] predicted_class = 'Class-' + str(np.argmax(probabilities)) print('\nDatapoint:', datapoint) print('Predicted class:', predicted_class)
Visualize the test data points based on classifier boundaries:
# Visualize the datapoints visualize_classifier(classifier, test_datapoints,
[0]*len(test_datapoints), 'Test datapoints') plt.show()
[ 76 ]

Predictive Analytics with Ensemble Learning
If you run the code with the rf flag, you will get the following output:
[ 77 ]

Predictive Analytics with Ensemble Learning
You will get the following output on your Terminal:
[ 78 ]

Predictive Analytics with Ensemble Learning
For each data point, it computes the probability of that point belonging to our three classes. We pick the one with the highest confidence. If you run the code with the erf flag, you will get the following output:
[ 79 ]

Predictive Analytics with Ensemble Learning
You will get the following output on your Terminal:
As we can see, the outputs are consistent with our observations.
Dealing with class imbalance
A classifier is only as good as the data that's used for training. One of the most common problems we face in the real world is the quality of data. For a classifier to perform well, it needs to see equal number of points for each class. But when we collect data in the real world, it's not always possible to ensure that each class has the exact same number of data points. If one class has 10 times the number of data points of the other class, then the classifier tends to get biased towards the first class. Hence we need to make sure that we account for this imbalance algorithmically. Let's see how to do that.
[ 80 ]

Predictive Analytics with Ensemble Learning
Create a new Python file and import the following packages:
import sys
import numpy as np import matplotlib.pyplot as plt from sklearn.ensemble import ExtraTreesClassifier from sklearn import cross_validation from sklearn.metrics import classification_report
from utilities import visualize_classifier
We will use the data in the file data_imbalance.txt for our analysis. Let's load the data. Each line in this file contains comma-separated values. The first two values correspond to the input data and the last value corresponds to the target label. We have two classes in this dataset. Let's load the data from that file:
# Load input data input_file = 'data_imbalance.txt' data = np.loadtxt(input_file, delimiter=',') X, y = data[:, :-1], data[:, -1]
Separate the input data into two classes:
# Separate input data into two classes based on labels class_0 = np.array(X[y==0]) class_1 = np.array(X[y==1])
Visualize the input data using scatter plot:
# Visualize input data plt.figure() plt.scatter(class_0[:, 0], class_0[:, 1], s=75, facecolors='black',
edgecolors='black', linewidth=1, marker='x') plt.scatter(class_1[:, 0], class_1[:, 1], s=75, facecolors='white',
edgecolors='black', linewidth=1, marker='o') plt.title('Input data')
Split the data into training and testing datasets:
# Split data into training and testing datasets X_train, X_test, y_train, y_test = cross_validation.train_test_split(
X, y, test_size=0.25, random_state=5)
[ 81 ]

Predictive Analytics with Ensemble Learning
Next, we define the parameters for the Extremely Random Forest classifier. Note that there is an input parameter called balance that controls whether or not we want to algorithmically account for class imbalance. If so, then we need to add another parameter called class_weight that tells the classifier that it should balance the weight, so that it's proportional to the number of data points in each class:
# Extremely Random Forests classifier params = {'n_estimators': 100, 'max_depth': 4, 'random_state': 0} if len(sys.argv) > 1:
if sys.argv[1] == 'balance': params = {'n_estimators': 100, 'max_depth': 4, 'random_state':
0, 'class_weight': 'balanced'} else: raise TypeError("Invalid input argument; should be 'balance'")
Build, train, and visualize the classifier using training data:
classifier = ExtraTreesClassifier(**params) classifier.fit(X_train, y_train) visualize_classifier(classifier, X_train, y_train, 'Training dataset')
Predict the output for test dataset and visualize the output:
y_test_pred = classifier.predict(X_test) visualize_classifier(classifier, X_test, y_test, 'Test dataset')
Compute the performance of the classifier and print the classification report:
# Evaluate classifier performance class_names = ['Class-0', 'Class-1'] print("\n" + "#"*40) print("\nClassifier performance on training dataset\n") print(classification_report(y_train, classifier.predict(X_train), target_names=class_names)) print("#"*40 + "\n")
print("#"*40) print("\nClassifier performance on test dataset\n") print(classification_report(y_test, y_test_pred, target_names=class_names)) print("#"*40 + "\n")
plt.show()
[ 82 ]

Predictive Analytics with Ensemble Learning
The full code is given in the file class_imbalance.py. If you run the code, you will see a few screenshots. The first screenshot shows the input data:
[ 83 ]

Predictive Analytics with Ensemble Learning
The second screenshot shows the classifier boundary for the test dataset:
[ 84 ]

Predictive Analytics with Ensemble Learning
The preceding screenshot indicates that the boundary was not able to capture the actual boundary between the two classes. The black patch near the top represents the boundary. You should see the following output on your Terminal:
You see a warning because the values are 0 in the first row, which leads to a divide-by-zero error (ZeroDivisionError exception) when we compute the f1-score. Run the code on the terminal using the ignore flag so that you do not see the divide-by-zero warning:
$ python3 --W ignore class_imbalance.py
Now if you want to account for class imbalance, run it with the balance flag:
$ python3 class_imbalance.py balance
[ 85 ]

