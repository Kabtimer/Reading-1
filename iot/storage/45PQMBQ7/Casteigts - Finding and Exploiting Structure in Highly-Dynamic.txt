Finding and Exploiting Structure in Highly-Dynamic Networks
Arnaud Casteigts Rescom Summer School 2019 (Anglet)
June 24, 2019
1/25

Networks?

• Set of nodes V (a.k.a. entities, vertices) • Set of links E among them (a.k.a. relations, edges)

→ A network (or graph) G = (V , E )

Complex networks (data analysis) → detect patterns → explain and reproduce phenomena

Communication networks
→ design interactions among entities → study what can be done from within
→ distributed algorithms...

2/25

Distributed Algorithms
Collaboration of distinct entities to perform a common task. No centralization available. No global knowledge. (Think globally, act locally)
3/25

Examples of problems
Broadcast

Propagating a piece of information from one node to all others.
→

Election

→

Distinguishing exactly one node among all.

Spanning tree

Selecting a cycle-free set of edges that interconnects all nodes.
→

Counting
→
Consensus, naming, routing, exploration, ...

Determining how many participants there are. 9

4/25

Abstracting Communications
Atomic interaction

T

N

Ex:

T

T

NT

(Population protocols (Angluin et al., 2004); Graph relabeling systems (Litovsky et al., 1999))

T

NT

NT

NT

Note: Scheduling is not part of the algorithm!

NT → Can be adversarial, randomized, etc.

Scope of the models

Relations between them (Chalopin, 2006)

5/25

Dynamic Networks
6/25

Dynamic networks?
In fact, highly dynamic networks.
Ex:
How changes are perceived? - Faults and Failures? - Nature of the system. Change is normal. - Possibly partitioned network, etc.
Example of scenario
(say, exploration by mobile robots)
7/25

Dynamic Graphs
Also called time-varying graphs, evolving graphs, temporal graphs, etc. As a sequence Sequence of static graphs G = G0, G1, ... [+table of dates]

G0

G1

With a presence function G = (V , E , T , ρ),
with ρ being a presence function ρ : E × T → {0, 1}

G2

G3

a

[0]

c [2, 3]

e

[2, 3]

[1, 2]

[0, 1]

[0, 2]

b

[0]

d

→ These models (and others) are essentially equivalent if T ⊆ N

(not when T ⊆ R, e.g.

)

→ Further extensions possible (latency function, node-presence function, ...)

8/25

Basic graph concepts

a

e

c

b

d

G0

a

e

c

b

d

G1

a

e

c

b

d

G2

a

e

c

b

d

G3

→ Paths become temporal (journey) Ex: ((ac, t1), (cd, t2), (de, t3)) with ti+1 ≥ ti and ρ(ei , ti ) = 1 Also known as Schedule-conforming path, Time-respecting path, Temporal path,
and Journey (Bui-Xuan et al., 2003).
→ Strict journeys vs. non-strict journeys. (More relevant in discrete time.)
→ Temporal connectivity. Not symmetrical! (e.g. a e, but e a)
→ Snapshots, footprint, etc.

9/25

Necessary and suﬃcient conditions in dynamic networks
10/25

Informal example
Ex: Broadcast algorithm

G0

G1

G2

G3

Lucky version. Yeah !! But things could have gone diﬀerently. Too late! Failure! Or even worse.. Too fast! Too fast! Failure! =⇒ Additional assumptions needed to guarantee something.

Assumption: Every present edge is “selected” at least once (but we don’t know in what order...)

→ Now, is the success guaranteed? Why not?

Because ¬(src st ∗)

→ Is the success possible? Of course, but why?

Because (src ∗)

Notions of necessary condition (e.g. src conditions relate only to the topology.

∗) or suﬃcient condition (e.g. src st ∗) for a given algorithm. These
More formally...

11/25

Interaction over dynamic graphs

Interactions over a Dynamic Graph G = {G0, G1, ..., Gk }
...

G0

G1

Gk

time

Interactions I1

Interactions I2

Change 1

Change 2

Interactions Ik . . . Change k − 1

An execution is an alternated sequence of interactions and topological events:

X = Ik ◦ Changek−1 ◦ .. ◦ Change2 ◦ I2 ◦ Change1 ◦ I1(G0)

Non deterministic !

→ X : set of all possible executions (for a given algorithm and graph G).
What makes a graph property P a necessary or suﬃcient condition for success on G? → Necessary condition: ¬P(G) =⇒ ∀X ∈ X , failure(X). → Suﬃcient condition: P(G) =⇒ ∀X ∈ X , success(X).

12/25

Back to the broadcast example
Necessary condition → PN : there exists a journey from the source to all other nodes (noted src ∗).
Suﬃcient condition → PS : there exists a strict journey from the source to all other nodes (noted src st ∗).

Classes of dynamic graphs
→ C1: PN is satisﬁed by at least one node (noted 1 ∗). → C2: PN is satisﬁed by all nodes (∗ ∗). → C3: PS is satisﬁed by at least one node (1 st ∗). → C4: PS is satistied by all nodes (∗ st ∗).

a

e

3

c

1, 2

0, 1

0, 1, 2, 3

0, 2, 3

b

d

∈ C2 ∩ C3

13/25

Counting algorithm (non-uniform)

Counting with a distinguished counter

Initial states: 1 for the counter, N for all other nodes.

i

N

Algorithm:

i +1

F

→ Hopefully, after some time, the counter is labelled n.
Necessary or suﬃcient conditions

But when?

PN : there exists an edge, at some time, between the counter and every other node. PS = PN .

Classes of dynamic graphs
→ C5: at least one node veriﬁes P, (noted 1–∗). → C6: all the nodes verify P, (noted ∗–∗).

14/25

Counting algorithm (uniform)

Uniform counting (every body is initially a counter)

Initial states: 1 (all nodes).

i =0 Algorithm:

j =0

i +j

0

→ Hopefully, after some time, one node is labelled n.
Conditions and classes of graphs

But when?

Necessary condition CN : at least one node can be reached by all (∗ 1). → C7: graphs having this property.
Suﬃcient condition CS : all pairs of nodes must share an edge at least once over time (∗–∗). → C6 (already seen before).

15/25

Classifying dynamic networks

1−∗ C5

− =⇒ Jstrict

1 st ∗ C3

Jstrict =⇒ J

1∗ C1

∀ =⇒ ∃

∀ =⇒ ∃

− =⇒ J

∀ =⇒ ∃

C6 ∗−∗

− =⇒ Jstrict

C4 ∗ st ∗

Jstrict =⇒ J

C2 ∗∗

∀ =⇒ ∃

C7 ∗1

16/25

Classifying dynamic networks

1−∗ C5

1 st ∗ C3

1∗ C1

C6 ∗−∗

C4 ∗ st ∗

C2 ∗∗

PN (countingv1) PS (countingv1) PS (countingv2)

PN (countingv2)

→ Comparison of distributed algorithms on a formal basis

C7 ∗1

17/25

Further classes of dynamic networks Network algorithms
Exploit

infinite lifetime KR

EP

EB

ER

α-T CB

T CB

T CR

C∩

C∗

CR

PR

K (∗–∗)

finite lifetime

E 1∀ (1–∗)

J 1∀
(1 ∗)

TC
?

TC
(∗ ∗)
?

J ∀1
(∗ 1)

Test
Data analysis

18/25

Classes of dynamic networks

Network algorithms
Exploit

infinite lifetime

Population protocols

KR

Fastest broadcast

Foremost broadcast

EP

EB

ER

Shortest broadcast

Ring exploration

α-T CB

T CB

T CR

C∩

C∗

CR

PR

Counting
K (∗–∗)

finite lifetime

Broadcast

E 1∀ (1–∗)

J 1∀
(1 ∗)

TC

TC
(∗ ∗)

J ∀1
(∗ 1)

Broadcast + acknowledgment

Leader election

Speed up for some problems

Bounded broadcast

Retry broadcast

Retry routing

19/25

Zoom: Optimal broadcast in DTNs?

What optimality ?

b [3, 4)

c

[1, 2)

foremost

[5, 6)

a

[4, 5) e [9, 10)

shortest

d

[7, 8)

fastest

[7, 8)

f [7, 8) g

(Bui-Xuan, Jarry, Ferreira, 2003)
Which way is optimal from a to d? -min hop? (shortest) -earliest arrival? (foremost) -fastest traversal? (fastest)

→ Computing shortest, foremost and fastest journeys in dynamic networks

What about the distributed version?
→ Can we broadcast a message to all the nodes in a foremost, shortest, or fastest way? (with termination detection at the emitter and without knowing the schedule)

Fastest

Shortest

Foremost

Nothing

EP

EB

ER

(periodic) (bounded-recurrent) (recurrent)

Arbitrary

Assumption on the edges

(C., Flocchini, Mans, Santoro, 2015)

20/25

Classes of dynamic networks

infinite lifetime EP

KR

EB

ER

K (∗–∗)

α-T CB

T CB

T CR

TC

C∩

C∗

CR

PR

finite lifetime

E 1∀ (1–∗)

J 1∀
(1 ∗)

TC
(∗ ∗)

J ∀1
(∗ 1)

21/25

Zoom: Exploiting structure within T CR

T CR := All nodes can reach each other through journeys inﬁnitely often (Formally, T CR := ∀t, G[t,+∞) ∈ T C)

≡ A connected spanning subset of the edges must be recurrent

(Braud Santoni et al., 2016)

For example,

−→

Can we exploit this property even if we don’t know which subset of edges is recurrent?

→ Yes, e.g. for covering problems like MinimalDominatingSet, in some cases a solution can be
found relative to the footprint and remain eﬀective in all possible eventual footprints provided the graph is in T CR. Such a solution is then called robust (C., Dubois, Petit, Robson, 2018)

Example:

Robust MDS

Non robust MDS

∃MDS ∃MIS ∀MIS
∀MDS

Not locally computable
Locally computable

Local algorithm for ∀MIS

22/25

Classes of dynamic networks Network algorithms
Exploit

infinite lifetime KR

EP

EB

ER

α-T CB

T CB

T CR

C∩

C∗

CR

PR

K (∗–∗)

finite lifetime

E 1∀ (1–∗)

J 1∀
(1 ∗)

TC
?

TC
(∗ ∗)
?

J ∀1
(∗ 1)

Test
Centralized algorithms

Induce
Movement synthesis

23/25

Algorithmic movement synthesis
1) Collective movements which induce temporal structure
→ Synthesizing collective movements (a.k.a. mobility models) that satisfy temporal properties on the resulting communication graph (combined with a target mission).
← Ex: this network ∈ ER
(Credit video: Jason Schoeters)
2) Integrating physical constraints in a tractable way
Discrete acceleration models Vector Racer
(paper and pencil game)

→ Impact on problems, e.g. TSP

Acceleration does impact the visit order!

24/25

Thank you!
The content of this talk is compiled in Chapters 2 and 3 of A. Casteigts. Finding Structure in Dynamic Networks,
(Monograph available at https://arxiv.org/abs/1807.07801)
25/25

