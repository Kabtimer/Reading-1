2019 International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)

Q-Learning Based Energy Harvesting for Heterogeneous Statistical QoS Provisioning Over
Multihop Big-Data Relay Networks
Xi Zhang, Jingqing Wang, and Qixuan Zhu
Networking and Information Systems Laboratory Department of Electrical and Computer Engineering, Texas A&M University, College Station, TX 77843, USA
E-mail: {xizhang@ece.tamu.edu, wang12078@tamu.edu, qixuan@tamu.edu,}

Abstract‚ÄîWith the increasing demand for the data-intensive wireless multimedia services over the time-varying wireless channels, the big-data based wireless networks demand the 5G candidate framework to process such massive amount of multimedia data without causing extra burden to the backhaul links in supporting the heterogeneous statistical delay-bounded quality-of-service (QoS) provisionings. Due to the beneÔ¨Åts of energy harvesting (EH) technologies, wireless devices are able to support the dataintensive wireless multimedia services by harvesting energy from the environment. Energy harvesting has emerged as the promising technology to solve the energy supply problem while bringing new challenges due to the stochastic nature of the harvested energy in supporting the heterogeneous statistical quality-of-service (QoS) provisionings. However, due to the unknown dynamics of the harvested energy as well as the channel state information (CSI), it is challenging to design the efÔ¨Åcient routing protocol for selecting the optimal routing and power allocation policies under the statistical delay-bounded QoS constraints. To overcome the aforementioned problems, in this paper we propose the Q-learning based optimal routing and power allocation policies through learning from the history of the energy harvesting process while satisfying the heterogeneous statistical delay-bounded QoS constraints over multihop big-data relay networks. In particular, under the heterogeneous statistical delay-bounded QoS requirements, we formulate the endto-end effective-capacity optimization problem for the batteryfree energy harvesting based big-data multihop relay networks. Then, we apply the Markov decision process and Q-learning methods for deriving the optimal multihop routing algorithms over big-data multihop relay networks. Also conducted is a set of simulations which evaluate the system performances and show that our proposed Q-learning based multihop routing scheme outperforms the other existing schemes under the heterogeneous statistical delay-bounded QoS constraints over multihop big-data relay networks.
Index Terms‚ÄîQ-learning, energy harvesting, heterogeneous statistical delay-bounded quality of service (QoS), effective capacity, multihop big-data relay networks.
I. INTRODUCTION
I N order to support the explosively growth of the multimedia data-intensive wireless services and applications, the energy
This work was supported in part by the U.S. National Science Foundation under Grants ECCS-1408601 and CNS-1205726, and the U.S. Air Force under Grant FA9453-15-C-0423.

supply problem has received a great deal of research attention from both academia and industry. Consequently, in order to efÔ¨Åciently manage the energy consumption and prolong the lifetime of the wireless devices, researchers have proposed various 5G candidate techniques to support the current demand of the real-time multimedia big-data transmissions for guaranteeing the statistical delay-bounded quality-of-service (QoS) [1] [2] provisionings.
To relieve the energy consumption of the network operators over big-data relay networks, a promising solution has been proposed by applying energy harvesting (EH) devices at base stations and utilize clean and renewable energy (such as solar, thermal, RF radiation etc.) as alternative energy resources. Energy harvesting scheme, which enables the wireless devices to harvest energy from the environment, has been proposed as one of the 5G promising candidate techniques to tackle such energy supply problem. In this case, each wireless device is equipped with one or more energy harvesters, as well as an energy buffer, storing the harvested energy for future use. However, due to dynamic nature of the energy sources, it is challenging to adapt the transmit power of the wireless devices while guaranteeing the statistical delay-bounded QoS requirements, in order to maximize the system capacity. Furthermore, the resources may be wasted and the service will be suspended in the absence of the prior knowledge of the system statistics, accordingly, how to learn from the historical behaviors and efÔ¨Åciently allocate the available energy is a signiÔ¨Åcant concern for network operation and optimization problems.
Toward this end, various machine-learning based optimal routing protocols have been proposed to learn from the historical behaviors by using game-theoretic approach, differentially private online learning, Q-learning method, and so on. According to the machine learning theory, there is a network controller who knows about the amount of trafÔ¨Åcs associated with BSs in the current network state, updates the network state according to a controlled discrete-time Markov decision process (DTMDP), and selects the optimal trafÔ¨Åc ofÔ¨Çoading strategy that can maximize the total reward while satisfying the statistical delaybounded QoS requirements. The works of [3] formulated the joint optimization problem by combining different perspectives

978-1-7281-2980-8/19/$31.00 ¬©2019 IEEE

807

DOI 10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00147

from Markov approximation and non-cooperative game theory. The authors apply the log-linear learning algorithm to Ô¨Ånd the equilibrium of a non-cooperative game. However, when considering the real-time multimedia data transmissions for the coordination among the competing interests of a large number of mobile users, how to efÔ¨Åciently design the machine-learning based multihop routing algorithms for the EH based data transmissions under the statistical delay-bounded QoS constraints still remains as a challenging and open problem.
To effectively overcome the aforementioned problems, in this paper we propose the Q-learning based multihop routing scheme for designing the optimal routing and power allocation policies through learning from the history of the EH process while satisfying the heterogeneous statistical delay-bounded QoS constraints over multihop big-data relay networks. In particular, we establish the wireless communication model and EH model over multihop big-data relay networks. Under the heterogeneous statistical delay-bounded QoS provisionings, we formulate the endto-end effective-capacity optimization problem for the batteryfree EH based multihop relay scheme. Then, we develop the Markov decision process and Q-learning based multihop routing and power allocation algorithms. We also conduct a set of simulations which evaluate the system performances and show that our proposed Q-learning based routing scheme outperforms the other existing schemes under the heterogeneous statistical delay-bounded QoS constraints over multihop big-data relay networks.
The rest of this paper is organized as follows. Section II establishes the system models for wireless communications and EH. Section III formulates the end-to-end effective capacity optimization problem under the heterogeneous statistical delaybounded QoS constraints. Section IV proposes the Markov decision process based multihop routing algorithm. Section V proposes the Q-learning based multihop routing algorithm. Section VI evaluates and compares the performances of our proposed schemes with the other existing schemes. The paper concludes with Section VII.
II. THE SYSTEM MODELS
Consider an energy harvesting (EH) based big-data multihop relay network where the source node transmits its data to the destination node via multiple decode-and-forward (DF) relays, as shown in Fig. 1. Assume that there are Ì†µÌ∞æ users and one base station (BS) that can transmit energy to all the users. Assume that both data and energy arrive in packets at each time slot. DeÔ¨Åne Ì†µÌ±ámax as the maximum delay that can be tolerated by at the destination mobile user.

A. The Wireless Communication System Model
The Nakagami-m fading model, where Ì†µÌ±ö is the shape factor of the Nakagami-m model, is applied in our proposed system. In the special case, Ì†µÌ±ö = 1 represents Rayleigh fading, and Ì†µÌ±ö = ‚àû corresponds to the Gaussian channel. The channel‚Äôs impulse response function, denoted by ‚ÑéÌ†µÌ±ò(Ì†µÌ±°), from mobile user Ì†µÌ±ò to mobile user (Ì†µÌ±ò + 1) at time slot Ì†µÌ±° can be expressed as

‚ÑéÌ†µÌ±ò(Ì†µÌ±°) = Ì†µÌªºÌ†µÌ±òÌ†µÌªø (Ì†µÌ±° ‚àí Ì†µÌºâÌ†µÌ±ò) exp (‚àíÌ†µÌ∫•Ì†µÌºôÌ†µÌ±ò) ,

(1)

:LUHOHVV'DWD/LQN (QHUJ\+DUYHVWLQJ/LQN 6HOHFWHG5HOD\LQJ1RGH

%DVH6WDWLRQ

...
6RXUFH1RGH

(QHUJ\ +DUYHVWHU
4R6»ô &RQVWUDLQWV
¬ó 4XHXLQJ3URFHVVQl
9LGHR3URFHVVLQJ
'HVWLQDWLRQ1RGH

Fig. 1. The system architecture for the energy harvesting based big-data multihop relay network.

‚àö where Ì†µÌ∫• = ‚àí1; Ì†µÌºâÌ†µÌ±ò is the path delay for mobile user Ì†µÌ±ò; Ì†µÌªø (‚ãÖ) is the unit impulse function; Ì†µÌªºÌ†µÌ±ò is a random variable representing the path envelope for mobile user Ì†µÌ±ò‚Äôs channel

and follows the Nakagami-m distribution; and Ì†µÌºôÌ†µÌ±ò is a random variable representing the phase-shift for mobile user Ì†µÌ±ò. Note
that all random variables Ì†µÌºôÌ†µÌ±ò, ‚àÄÌ†µÌ±ò, are independent and identically distributed (i.i.d) which uniformly distributed between [0, 2Ì†µÌºã),

and all random variables Ì†µÌªºÌ†µÌ±ò, ‚àÄÌ†µÌ±ò, are i.i.d. Correspondingly, the received signal, denoted by Ì†µÌ±¶Ì†µÌ±ò(Ì†µÌ±°), from
mobile user Ì†µÌ±ò to mobile user (Ì†µÌ±ò + 1) at time slot Ì†µÌ±° can be

expressed as in the following equation:

‚àö

‚àë Ì†µÌ∞æ ‚àö

Ì†µÌ±¶Ì†µÌ±ò(Ì†µÌ±°) = Ì†µÌ≤´Ì†µÌ±ò(Ì†µÌ±°)‚ÑéÌ†µÌ±ò(Ì†µÌ±°)Ì†µÌ±†Ì†µÌ±ò(Ì†µÌ±°) +

Ì†µÌ≤´Ì†µÌ±ó (Ì†µÌ±°)‚ÑéÌ†µÌ±ó (Ì†µÌ±°)Ì†µÌ±†Ì†µÌ±ó (Ì†µÌ±°) + Ì†µÌ±õÌ†µÌ±ò (Ì†µÌ±°),

Ì†µÌ±ó=1,Ì†µÌ±ó‚àï=Ì†µÌ±ò
(2)

where Ì†µÌ±†Ì†µÌ±ò(Ì†µÌ±°) and Ì†µÌ±†Ì†µÌ±ó(Ì†µÌ±°) denote the source signals sent from mobile user Ì†µÌ±ò and mobile user Ì†µÌ±ó at time slot Ì†µÌ±°, respectively; Ì†µÌ≤´Ì†µÌ±ò(Ì†µÌ±°) and Ì†µÌ≤´Ì†µÌ±ó(Ì†µÌ±°) are the transmit power at mobile user Ì†µÌ±ò and mobile user Ì†µÌ±ó, respectively; ‚ÑéÌ†µÌ±ò(Ì†µÌ±°) and ‚ÑéÌ†µÌ±ó(Ì†µÌ±°) denote the channel‚Äôs impulse response from mobile user Ì†µÌ±ò to mobile user (Ì†µÌ±ò +1) and mobile user Ì†µÌ±ó to mobile user (Ì†µÌ±ò + 1) at time slot Ì†µÌ±°, respectively; and Ì†µÌ±õÌ†µÌ±ò(Ì†µÌ±°) represents the additive white Gaussian noise (AWGN) with zero mean and variance Ì†µÌºé2.
Consider the multihop relay network, where the required Ô¨Åle
is transmitted through multiple relay nodes to the destination.
DeÔ¨Åne multihop routing indicator variable at time slot Ì†µÌ±°, denoted by{Ì†µÌ±•Ì†µÌ±ò(Ì†µÌ±°), subject to the following constraints:
Ì†µÌ±•Ì†µÌ±ò(Ì†µÌ±°) = 1, mobile user Ì†µÌ±ò is selected for next hop; (3) Ì†µÌ±•Ì†µÌ±ò(Ì†µÌ±°) = 0, otherwise.

B. The Energy Harvesting System Model
We apply the radio-frequency (RF) based EH technique in light of its Ô¨Çexible and sustainable characteristics compared with the conventional solar and wind EH techniques. Assume that each user is equipped with one single antenna and operates in half-duplex mode such that it can only transmit or receive at one time. In this way, the users work under the ‚Äúharvest-thentransmit‚Äù protocol [4], i.e., there are two phases in a frame duration Ì†µÌ±áÌ†µÌ±ì :

808

1) Phase 1: Energy Harvesting: During the energy harvesting phase, the RF energy harvesting source will transmit energy to user Ì†µÌ±ò. The duration of Phase 1 is Ì†µÌºèÌ†µÌ±òÌ†µÌ±áÌ†µÌ±ì where 0 < Ì†µÌºèÌ†µÌ±ò < 1.
2) Phase 2: Wireless Data Transmission: For the wireless data transmission phase, user Ì†µÌ±ò will transmit data using the energy harvested in Phase 1 in the remaining time duration (1 ‚àí Ì†µÌºèÌ†µÌ±ò)Ì†µÌ±áÌ†µÌ±ì .
For the proposed EH model, we can ignore the noise energy since it is too small as compared with the overall harvested energy. We assume that all mobile users are equipped with energy harvester that can harvest energy from RF signals. Accordingly, the received power, denoted by Ì†µÌ∞∏Ì†µÌ±ò, at user Ì†µÌ±ò can be formulated as follows [5]:

Ì†µÌ∞∏Ì†µÌ±ò = Ì†µÌºÖÌ†µÌºèÌ†µÌ±òÌ†µÌ≤´Ì†µÌ±°Ì†µÌ±îÌ†µÌ∞∏,Ì†µÌ±ò,

(4)

where Ì†µÌºÖ is the EH efÔ¨Åciency decided by the energy harvester, Ì†µÌ≤´Ì†µÌ±° denotes the transmit power at the energy harvester, and Ì†µÌ±îÌ†µÌ∞∏,Ì†µÌ±ò represents the channel‚Äôs impulse response from the power transmitter to user Ì†µÌ±ò.
Assume that all users are battery-free, i.e., the users are not equipped with any constant energy supplies, but they can harvest energy from the RF signals. Thus, the users‚Äô operations completely depend on the amount of energy harvested from the RF signals. Correspondingly, the transmit power need to satisfy the following constraint:

Ì†µÌ¥ºÌ†µÌªæÌ†µÌ±ò [(1 ‚àí Ì†µÌºèÌ†µÌ±ò)Ì†µÌ≤´Ì†µÌ±ò] ‚â§ Ì†µÌºÖÌ†µÌºèÌ†µÌ±òÌ†µÌ±áÌ†µÌ±ì Ì†µÌ≤´Ì†µÌ±°Ì†µÌ±îÌ†µÌ∞∏,Ì†µÌ±ò.

(5)

III. MAXIMIZING EFFECTIVE CAPACITY UNDER HETEROGENEOUS STATISTICAL DELAY-BOUNDED QOS
PROVISIONINGS
In this section, we consider the battery-free scenario for our proposed EH scheme. By jointly optimizing the EH time and the transmit power, we formulate the effective-capacity maximization problem for our proposed EH scheme under the heterogeneous statistical delay-bounded QoS constraints over multihop big-data relay networks.

A. Preliminary for Effective Capacity Under Homogeneous Statistical Delay-Bounded QoS Constraints

The statistical QoS guarantees [6] has been extensively studied for analyzing the queuing behavior for time-varying arrival and service processes. Based on large deviation principle (LDP), under sufÔ¨Åcient conditions, the queue length process Ì†µÌ±Ñ(Ì†µÌ±°) with the average arrival rate Ì†µÀúÌºÜ and average service rate Ì†µÀúÌºá converges in distribution to a random variable Ì†µÌ±Ñ(‚àû) such that [7]

‚àí lim
Ì†µÌ±ÑÌ†µÌ±°‚Ñé ‚Üí‚àû

log (Pr {Ì†µÌ±Ñ(‚àû) Ì†µÌ±ÑÌ†µÌ±°‚Ñé

>

Ì†µÌ±ÑÌ†µÌ±°‚Ñé})

=

Ì†µÌºÉ.

(6)

where Ì†µÌºÉ > 0 is deÔ¨Åned as the QoS exponent and plays

a critically important role for statistical delay-bounded QoS

provisionings and Ì†µÌ±ÑÌ†µÌ±°‚Ñé denotes the queue-length bound. The effective capacity [8] is deÔ¨Åned as the maximum constant

arrival rate for a given service process subject to the statistical

delay-bounded QoS constraints. We can derive the effective

capacity, denoted by Ì†µÌ∞∂Ì†µÌ±ò(Ì†µÌºÉÌ†µÌ±ò, Ì†µÌ±°), for the communication between

the mobile user Ì†µÌ±ò and the mobile user (Ì†µÌ±ò + 1) at time slot Ì†µÌ±° as

follows [8]:

Ì†µÌ∞∂Ì†µÌ±ò(Ì†µÌºÉÌ†µÌ±ò, Ì†µÌ±°)

=

‚àí

1 Ì†µÌºÉÌ†µÌ±ò

([

])

log Ì†µÌ¥ºÌ†µÌªæÌ†µÌ±ò Ì†µÌ±í‚àíÌ†µÌºÉÌ†µÌ±òÌ†µÌ±ÖÌ†µÌ±ò(Ì†µÌ±°)

(7)

where Ì†µÌ¥ºÌ†µÌªæÌ†µÌ±ò (‚ãÖ) is the expectation operation with respect to the random variable ŒìÌ†µÌ±ò. ŒìÌ†µÌ±ò is the mobile user Ì†µÌ±ò‚Äôs signal-to-noiseplus-interference ratio (SINR) whose value is Ì†µÌªæÌ†µÌ±ò and Ì†µÌºÉÌ†µÌ±ò is the QoS exponent for the mobile user Ì†µÌ±ò.

Furthermore, we need to derive the power allocation policy,

denoted by Ì†µÌΩÇÌ†µÌ±ò ‚âú Ì†µÌΩÇÌ†µÌ±ò(Ì†µÌºÉÌ†µÌ±ò, Ì†µÌªæÌ†µÌ±ò), which is a function of both the SINR Ì†µÌªæÌ†µÌ±ò and the QoS exponent Ì†µÌºÉÌ†µÌ±ò [9]. Assume that all mobile

users are heterogeneous, which implies that they are assigned

different power allocations according to different channel state

information. DeÔ¨Åne the mean transmit power of mobile user Ì†µÌ±ò

as Ì†µÌ≤´Ì†µÌ±ò. Applying the power allocation policy, the instantaneous transmit power of the user becomes Ì†µÌ≤´Ì†µÌ±ò(Ì†µÌΩÇÌ†µÌ±ò) = Ì†µÌΩÇÌ†µÌ±òÌ†µÌ≤´Ì†µÌ±ò. As a

result, the power allocation policy need to satisfy the mean

power constraint given as follows:

‚à´‚àû

Ì†µÌ≤´Ì†µÌ±ò(Ì†µÌΩÇÌ†µÌ±ò)Ì†µÌ±ùŒìÌ†µÌ±ò (Ì†µÌªæÌ†µÌ±ò)Ì†µÌ±ëÌ†µÌªæÌ†µÌ±ò = Ì†µÌ≤´Ì†µÌ±ò,

‚àÄÌ†µÌ±ò,

(8)

0

where Ì†µÌ±ùŒìÌ†µÌ±ò (Ì†µÌªæÌ†µÌ±ò) denotes the probability density function (pdf) of the random variable ŒìÌ†µÌ±ò over a Nakagami-Ì†µÌ±ö fading channel

given by

Ì†µÌ±ùŒìÌ†µÌ±ò (Ì†µÌªæÌ†µÌ±ò)

=

Ì†µÌªæÌ†µÌ†µÌ±òÌ±ö‚àí1 Œì(Ì†µÌ±ö)

( Ì†µÌ±ö )Ì†µÌ±ö Ì†µÌªæÌ†µÌ±ò

(

)

exp

‚àí

Ì†µÌ±öÌ†µÌªæÌ†µÌ±ò Ì†µÌªæÌ†µÌ±ò

,

(9)

where Ì†µÌªæÌ†µÌ±ò denotes the average SINR for mobile user Ì†µÌ±ò and Œì(‚ãÖ) is the gamma function.

B. Joint Optimization of Power and Time Allocation Under Heterogeneous Statistical Delay-Bounded QoS Guarantees
Considering our proposed EH based multihop relaying model, it is unrealistic to assume that all the different hops have the homogeneous statistical QoS provisionings. Accordingly, the diverse delay-bounded QoS provisionings for different hops need to be considered, which represents the new heterogeneous statistical QoS provisioning framework and imposes many new challenges. DeÔ¨Åne Ì†µÌºΩ = [Ì†µÌºÉ1, Ì†µÌºÉ2, . . . , Ì†µÌºÉÌ†µÌ∞æ ] as the QoS exponent vector, Ì†µÌΩâ = [Ì†µÌºè1, Ì†µÌºè2, . . . , Ì†µÌºèÌ†µÌ∞æ ] as the time scheduling vector, and Ììü ‚âú [Ì†µÌ≤´1, . . . , Ì†µÌ≤´Ì†µÌ∞æ ] as the power allocation vector for all Ì†µÌ∞æ users.
We can derive the data transmission rate Ì†µÌ±ÖÌ†µÌ±ò(Ì†µÌ±°) in Eq. (7) for mobile user Ì†µÌ±ò at time slot Ì†µÌ±° as follows:

Ì†µÌ±ÖÌ†µÌ±ò(Ì†µÌ±°) = Ì†µÌ±•Ì†µÌ±ò(Ì†µÌ±°)Ì†µÌ±áÌ†µÌ±ì Ì†µÌ∞µ log2 (1 + Ì†µÌªæÌ†µÌ±ò) ,

(10)

where Ì†µÌ∞µ denotes the bandwidth for the users. We assume that all

users are assigned with the same bandwidth Ì†µÌ∞µ. Using Eq. (10),

we can further derive the single-hop effective capacity Ì†µÌ∞∂Ì†µÌ±ò(Ì†µÌºÉÌ†µÌ±ò, Ì†µÌ±°) in Eq. (7) between user Ì†µÌ±ò and user (Ì†µÌ±ò + 1) at time slot Ì†µÌ±° as

follows:

Ì†µÌ∞∂Ì†µÌ±ò(Ì†µÌºÉÌ†µÌ±ò, Ì†µÌ±°)

=

‚àí

1 Ì†µÌºÉÌ†µÌ±ò

log

(Ì†µÌ¥ºÌ†µÌªæÌ†µÌ±ò

[exp

{‚àíÌ†µÌºÉÌ†µÌ±ò Ì†µÌ±•Ì†µÌ±ò (Ì†µÌ±°)Ì†µÌºèÌ†µÌ±ò Ì†µÌ±áÌ†µÌ±ì

√óÌ†µÌ∞µ log2 (1 + Ì†µÌ≤´Ì†µÌ±òÌ†µÌªæÌ†µÌ±ò)}]) . (11)

809

Since the system capacity of multihop transmissions is dominated by the bottlenecked link, the end-to-end effective capacity of the multihop relay networks can be derived as follows:

Ì†µÌ∞∂ (Ì†µÌºÉ,

Ì†µÌ±°)

‚âú

min
1‚â§Ì†µÌ±ò‚â§Ì†µÌ∞æ

{Ì†µÌ∞∂Ì†µÌ±ò (Ì†µÌºÉÌ†µÌ±ò ,

Ì†µÌ±°)}

.

(12)

Then, using Eqs. (11) and (12), we construct an optimization

problem P1 for maximizing the end-to-end effective capacity

under the heterogeneous statistical delay-bounded QoS provi-

sionings can be formulated as follows:

{

{

([ {

P1 : Ì†µÌ∞∂opt(Ì†µÌºÉ, Ì†µÌ±°) ‚âú arg max
{Ììü,Ì†µÌΩâ }

min
1‚â§Ì†µÌ±ò‚â§Ì†µÌ∞æ

‚àí

1 Ì†µÌºÉÌ†µÌ±ò

log

Ì†µÌ¥ºÌ†µÌªæÌ†µÌ±ò

exp

‚àíÌ†µÌºÉÌ†µÌ±ò

}])}}

√ó(1‚àíÌ†µÌºèÌ†µÌ±ò)Ì†µÌ±•Ì†µÌ±ò(Ì†µÌ±°)Ì†µÌ±áÌ†µÌ±ì Ì†µÌ∞µ log2 (1+Ì†µÌ≤´Ì†µÌ±òÌ†µÌªæÌ†µÌ±ò)

,

(13)

s.t. Ì†µÌ∞∂1 : Ì†µÌ¥ºÌ†µÌªæÌ†µÌ±ò [(1 ‚àí Ì†µÌºèÌ†µÌ±ò)Ì†µÌ≤´Ì†µÌ±ò] ‚â§ Ì†µÌºÖÌ†µÌºèÌ†µÌ±òÌ†µÌ±áÌ†µÌ±ì Ì†µÌ≤´Ì†µÌ±°Ì†µÌ±îÌ†µÌ∞∏,Ì†µÌ±ò; Ì†µÌ∞∂2 : 0 < Ì†µÌºèÌ†µÌ±ò < 1, ‚àÄÌ†µÌ±ò; Ì†µÌ∞∂3 : Ì†µÌ≤´Ì†µÌ±ò ‚â• 0, ‚àÄÌ†µÌ±ò; Ì†µÌ∞∂4 : Ì†µÌ±•Ì†µÌ±ò(Ì†µÌ±°) ‚àà {0, 1}, ‚àÄÌ†µÌ±ò,
where Ì†µÌ∞∂opt(Ì†µÌºÉ, Ì†µÌ±°) is the maximized end-to-end effective capacity obtained from the optimization problem P1. According to Eq. (13), we can observe that the above mixed-integer optimization problem is NP-hard [10] and hence is challenging to solve. Correspondingly, in the next section, the Markov decision process is considered to solve the optimization problem P1.

IV. MARKOV DECISION PROCESS BASED MULTIHOP ROUTING ALGORITHM

A. Optimal Multihop Routing Protocol

Our goal is to Ô¨Ånd the optimal multihop routing protocol

Ì†µÌΩÖ(Ì†µÌ≤ô(Ì†µÌ±°)) ‚âú [Ì†µÌΩÖ(Ì†µÌ±•1(Ì†µÌ±°)), . . . , Ì†µÌΩÖ(Ì†µÌ±•Ì†µÌ∞æ (Ì†µÌ±°))] in order to maximize the

reward function. Accordingly, we deÔ¨Åne the reward function,

denoted by ‚Ñõ(Ì†µÌΩÖ(Ì†µÌ≤ô(Ì†µÌ±°))), as follows:

{[

]}

‚àë

‚Ñõ(Ì†µÌΩÖ(Ì†µÌ≤ô(Ì†µÌ±°))) = max Ì†µÌ¥º Ì†µÌºÇÌ†µÌ±°‚àí1Ì†µÌºá(Ì†µÌΩÖ(Ì†µÌ≤ô(Ì†µÌ±° ‚àí 1))) , (14)

Ì†µÌΩÖ(Ì†µÌ≤ô(Ì†µÌ±°))

Ì†µÌ±°

where Ì†µÌºÇÌ†µÌ±°‚àí1 ‚àà [0, 1) represents the discount factor, Ì†µÌºá(Ì†µÌΩÖ(Ì†µÌ≤ô(Ì†µÌ±° ‚àí

1))) is the utility function deÔ¨Åned as the maximum end-to-end

effective capacity at time slot (Ì†µÌ±°‚àí1) given the total transmission

energy Ì†µÌΩÖ(Ì†µÌ≤ô(Ì†µÌ±° ‚àí 1)), i.e.,

{

{

([ {

Ì†µÌºá(Ì†µÌΩÖ(Ì†µÌ≤ô(Ì†µÌ±°))) ‚âú arg max
{Ììü,Ì†µÌΩâ }

min
1‚â§Ì†µÌ±ò‚â§Ì†µÌ∞æ

‚àí 1 log Ì†µÌºÉÌ†µÌ±ò

Ì†µÌ¥ºÌ†µÌªæÌ†µÌ±ò

exp

‚àíÌ†µÌºÉÌ†µÌ±ò

}])}}

√ó(1‚àíÌ†µÌºèÌ†µÌ±ò)Ì†µÌ±•Ì†µÌ±ò(Ì†µÌ±°)Ì†µÌ±áÌ†µÌ±ì Ì†µÌ∞µ log2 (1+Ì†µÌ≤´Ì†µÌ±òÌ†µÌªæÌ†µÌ±ò)

,

(15)

subject to the constraints Ì†µÌ∞∂1-Ì†µÌ∞∂4 of problem P1 in Eq. (13). Since the mobile users only know their own energy storage state and EH state, the utility function Ì†µÌºá(Ì†µÌΩÖ(Ì†µÌ≤ô(Ì†µÌ±°))) is a stochastic function, where the statistic nature is introduced by the

energy storage state, EH state, and CSI from other mobile users. Assume that each user knows the minimum amount of energy for transmitting the arriving data packet at time slot Ì†µÌ±°. The optimization problem in Eq. (15) can be considered as a discrete-time Markov decision process (DTMDP), consisting of Ì†µÌ∞æ independent Markov chains.
To solve the above-mentioned optimization problem, Ô¨Årst, we deÔ¨Åne the following four elements:

‚àô Agents: Ì†µÌ∞æ mobile users. ‚àô State: The system state at time slot Ì†µÌ±° is characterized
by the aggregation of channel state information (CSI),
and energy state information (ESI), which are denoted by Ì†µÌ±∫(Ì†µÌ±°) = (Ì†µÌ±Ø(Ì†µÌ±°), Ì†µÌ±¨(Ì†µÌ±°)), where Ì†µÌ±Ø(Ì†µÌ±°) = {‚ÑéÌ†µÌ±ò(Ì†µÌ±°)}Ì†µÌ†µÌ±òÌ∞æ=1, and Ì†µÌ±¨(Ì†µÌ±°) = {Ì†µÌ∞∏Ì†µÌ±ò(Ì†µÌ±°)}Ì†µÌ†µÌ±òÌ∞æ=1, respectively. ‚àô Action: At each time slot Ì†µÌ±°, a multihop routing action Ì†µÌ≤ô(Ì†µÌ±°) = {Ì†µÌ±•Ì†µÌ±ò(Ì†µÌ±°) ‚àà {0, 1}}Ì†µÌ†µÌ±òÌ∞æ=1 is taken from the set of actions in the action space Ì†µÌ≤ú based on the current state Ì†µÌ±∫(Ì†µÌ±°). Note that the transmission power allocation action and the routing action are correlated.
‚àô Reward: Reward is deÔ¨Åned as the end-to-end effective
capacity, speciÔ¨Åed by Eq. (14).

Given the EH policy Ì†µÌΩÖ(Ì†µÌ≤ô(Ì†µÌ±°)) and the network state Ì†µÌ±∫(Ì†µÌ±°), the

future network state at time slot (Ì†µÌ±°+ 1) can be derived using the

state transition probability. Since state transitions depend only

on the current state and the current action at each mobile user,

our proposed model follows the discrete-time Markov decision

process. Accordingly, we deÔ¨Åne the action function as in the

following equation:

[

‚àë

Ì†µÌ±ÑÌ†µÌºã(Ì†µÌ±†Ì†µÌ±ò(Ì†µÌ±°), Ì†µÌ±•Ì†µÌ±ò(Ì†µÌ±°)) ‚âú

Ì†µÌ±ùÌ†µÌ±•Ì†µÌ±ò(Ì†µÌ±°)(Ì†µÌ±†Ì†µÌ±ó (Ì†µÌ±°), Ì†µÌ±†Ì†µÌ±ò(Ì†µÌ±°)) Ì†µÌºá(Ì†µÌΩÖ(Ì†µÌ≤ô(Ì†µÌ±°)))

Ì†µÌ±†Ì†µÌ±ó (Ì†µÌ±°)‚ààÌ†µÌ≤Æ(Ì†µÌ±°)

]

+ Ì†µÌ±â Ì†µÌºã(Ì†µÌ±†Ì†µÌ±ò(Ì†µÌ±°)) , (16)

where Ì†µÌ±ùÌ†µÌ±•Ì†µÌ±ò(Ì†µÌ±°)(Ì†µÌ±†Ì†µÌ±ó(Ì†µÌ±°), Ì†µÌ±†Ì†µÌ±ò(Ì†µÌ±°)) denotes the transition probability from network state Ì†µÌ±†Ì†µÌ±ó(Ì†µÌ±°) to network state Ì†µÌ±†Ì†µÌ±ò(Ì†µÌ±°) when action Ì†µÌ±•Ì†µÌ±ò(Ì†µÌ±°) is taken at time slot Ì†µÌ±°. Then, the DTMDP based effectivecapacity optimization problem can be solved by applying the
dynamic programming [11]. DeÔ¨Åne the Bellman‚Äôs equation [12]
as follows:

Ì†µÌ±â Ì†µÌºã(Ì†µÌ±†Ì†µÌ±ò(Ì†µÌ±°)) ‚âú max Ì†µÌ±ÑÌ†µÌºã(Ì†µÌ±†Ì†µÌ±ò(Ì†µÌ±°), Ì†µÌ±•Ì†µÌ±ò(Ì†µÌ±°)).

(17)

Ì†µÌ±•Ì†µÌ±ò (Ì†µÌ±°)‚ààÌ†µÌ≤≥

DeÔ¨Åne Ì†µÌ≤¢ as the group of the selected relay nodes for the EH based multihop relay networks. The DTMDP based routing
algorithm is proposed in Algorithm 1. The optimal value of the equation Ì†µÌ≤±(Ì†µÌ±†Ì†µÌ±ò(Ì†µÌ±°)) can be calculated by working backwards from Ì†µÌ±ámax to 1.

B. Optimal Joint Power and Time Allocation Under Heterogeneous Statistical Delay-Bounded QoS Provisionings
Using Algorithm 1, we can derive the optimal joint power and time allocation policy under the heterogeneous statistical delaybounded QoS constraint. However, the optimization problem P1 is a non-convex problem. In order to derive a feasible solution,

810

Algorithm 1 DTMDP Based Multihop Routing Algorithm Over EH Based Multihop Relay Networks

Input: Ì†µÌ±áÌ†µÌ±ì , Ì†µÌ±ámax, Ì†µÌ∞µ, Ì†µÌ∞æ, Ì†µÌ≤´1, Ì†µÌ≤´2, . . . ,[Ì†µÌ≤´Ì†µÌ∞æ

]

Initialization: [Ì†µÌ≤´1, Ì†µÌ≤´2, . . . , Ì†µÌ≤´Ì†µÌ∞æ ] = Ì†µÌ≤´1, Ì†µÌ≤´2, . . . , Ì†µÌ≤´Ì†µÌ∞æ

Step 1:

Set Ì†µÌ±° = Ì†µÌ±ámax while Ì†µÌ±° ‚â• 1 do

for Ì†µÌ±ó = 1 : Ì†µÌ∞æ do Calculate Ì†µÌ±ÑÌ†µÌºã(Ì†µÌ±†Ì†µÌ±ò(Ì†µÌ±°), Ì†µÌ±•Ì†µÌ±ò(Ì†µÌ±°)) by using Eq. (16). Calculate Ì†µÌ±â Ì†µÌºã(Ì†µÌ±†Ì†µÌ±ò(Ì†µÌ±°)).
end for

Set Ì†µÌ±° ‚Üê Ì†µÌ±° ‚àí 1

end while

Step 2:

Set Ì†µÌ±° = 1

while Ì†µÌ±° ‚â§ Ì†µÌ±ámax do for Ì†µÌ±ó = 1 : Ì†µÌ∞æ do

Observe the current state Ì†µÌ±†Ì†µÌ±ò(Ì†µÌ±°) and select the corresponding routing action Ì†µÌ±•Ì†µÌ±ò(Ì†µÌ±°) with the maximum value of Ì†µÌ±â Ì†µÌºã(Ì†µÌ±†Ì†µÌ±ò(Ì†µÌ±°)). if Ì†µÌ±•Ì†µÌ±ò(Ì†µÌ±°) = 1 then
Ì†µÌ±ò ‚Üí Ì†µÌ≤¢

end if

end for

Set Ì†µÌ±° ‚Üê Ì†µÌ±° + 1

end while

we deÔ¨Åne a new variable Ì†µÌ±íÌ†µÌ±ò ‚âú Ì†µÌºèÌ†µÌ±òÌ†µÌ≤´Ì†µÌ±ò. Accordingly, we can convert P1 into the following optimization problem P2:

{

{

([ {

P2 : Ì†µÌ∞∂opt(Ì†µÌºÉ, Ì†µÌ±°) = arg max
{Ì†µÌ≤Ü,Ì†µÌΩâ }

min
1‚â§Ì†µÌ±ò‚â§Ì†µÌ∞æ

‚àí

1 Ì†µÌºÉÌ†µÌ±ò

log

Ì†µÌ¥ºÌ†µÌªæÌ†µÌ±ò

exp

‚àíÌ†µÌºÉÌ†µÌ±ò

(

)}])}}

√ó (1‚àíÌ†µÌºèÌ†µÌ±ò)Ì†µÌ±áÌ†µÌ±ì Ì†µÌ∞µ log2

1+

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

Ì†µÌªæÌ†µÌ±ò

,

(18)

subject to the constraints Ì†µÌ∞∂1-Ì†µÌ∞∂4 of problem P1 in Eq. (13). Lemma 1: P2 is a jointly convex optimization problem with
respect to Ì†µÌΩâ and Ì†µÌ≤Ü.
Proof: Due to the lack of space, we omit the proof of Lemma 1.

According to Lemma 1, the non-convex optimization problem
P1 is converted to a convex problem P2 with respect to time and power allocations. Then, we can further convert P2 in Eq. (18) into an equivalent problem P3 as follows:

{

{[ {

P3 : Ì†µÌ∞∂opt(Ì†µÌºÉ, Ì†µÌ±°) = arg min
{Ì†µÌ≤Ü,Ì†µÌΩâ }

max
1‚â§Ì†µÌ±ò‚â§Ì†µÌ∞æ

Ì†µÌ¥ºÌ†µÌªæÌ†µÌ±ò exp

‚àíÌ†µÌºÉÌ†µÌ±ò

(

)}]}}

√ó (1‚àíÌ†µÌºèÌ†µÌ±ò)Ì†µÌ±áÌ†µÌ±ì Ì†µÌ∞µ log2

1

+

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

Ì†µÌªæÌ†µÌ±ò

,

(19)

subject to the constraints Ì†µÌ∞∂1-Ì†µÌ∞∂4 of problem P1 in Eq. (13).

For simplicity, we deÔ¨Åne a new function as follows:

[{

(

)}]

Ì†µÀúÌ∞∂Ì†µÌ±ò(Ì†µÌºèÌ†µÌ±ò, Ì†µÌ±íÌ†µÌ±ò) ‚âú Ì†µÌ¥ºÌ†µÌªæÌ†µÌ±ò

exp

‚àíÌ†µÌºÉÌ†µÌ±ò(1‚àíÌ†µÌºèÌ†µÌ±ò)Ì†µÌ±áÌ†µÌ±ì Ì†µÌ∞µ log2

1+

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

Ì†µÌªæÌ†µÌ±ò

,

(20)

and a new variable Ì†µÀúÌ∞∂ such that Ì†µÀúÌ∞∂Ì†µÌ±ò(Ì†µÌºèÌ†µÌ±ò, Ì†µÌ±íÌ†µÌ±ò) ‚â§ Ì†µÀúÌ∞∂. Then, we can

further reformulate the optimization problem P3 as follows:

{}

P4 : Ì†µÌ∞∂opt(Ì†µÌºÉ, Ì†µÌ±°) = arg min Ì†µÀúÌ∞∂ ,

(21)

{Ì†µÌ≤Ü,Ì†µÌΩâ }

s.t. Ì†µÌ∞∂0 : Ì†µÀúÌ∞∂Ì†µÌ±ò(Ì†µÌºèÌ†µÌ±ò, Ì†µÌ±íÌ†µÌ±ò) ‚â§ Ì†µÀúÌ∞∂;

Ì†µÌ∞∂1, Ì†µÌ∞∂2, and Ì†µÌ∞∂3.

(22)

Then, we can derive the partial Lagrangian function of P4 with respect to the constraint Ì†µÌ∞∂0 given in Eq. (22) as follows:

‚àë Ì†µÌ∞æ (

)

‚Ñí(Ì†µÌΩÄ, Ì†µÌ≤Ü, Ì†µÌΩâ ) = ‚àí Ì†µÌºÜÌ†µÌ±ò Ì†µÀúÌ∞∂Ì†µÌ±ò(Ì†µÌºèÌ†µÌ±ò, Ì†µÌ±íÌ†µÌ±ò) ‚àí Ì†µÀúÌ∞∂ ,

(23)

Ì†µÌ±ò=1

where Ì†µÌΩÄ = [Ì†µÌºÜ1, . . . , Ì†µÌºÜÌ†µÌ∞æ ] with Ì†µÌºÜÌ†µÌ±ò representing the non-negative Lagrangian multiplier associated with the constraint Ì†µÌ∞∂0. Let ‚Ñ± denote the feasible set of (Ì†µÌΩâ , Ì†µÌ≤Ü) given in the constraints Ì†µÌ∞∂1, Ì†µÌ∞∂2, and Ì†µÌ∞∂3. We can determine the Lagrange dual problem P4 as follows:

Ì†µÌ≤ü(Ì†µÌΩÄ) = arg min ‚Ñí(Ì†µÌΩÄ, Ì†µÌ≤Ü, Ì†µÌΩâ ),

(24)

{Ì†µÌ≤Ü,Ì†µÌΩâ }‚àà‚Ñ±

We can ignore the term Ì†µÌºÜÌ†µÌ±òÌ†µÀúÌ∞∂ in Eq. (23) since it does not affect the optimization with respect to set (Ì†µÌΩâ , Ì†µÌ≤Ü). Therefore, we
can rewrite the Lagrange dual problem as follows:

P5 : arg max ‚àë Ì†µÌ∞æ Ì†µÌºÜÌ†µÌ±òÌ†µÀúÌ∞∂Ì†µÌ±ò(Ì†µÌºèÌ†µÌ±ò, Ì†µÌ±íÌ†µÌ±ò),

(25)

{Ì†µÌ≤Ü,Ì†µÌΩâ }‚àà‚Ñ±

Ì†µÌ±ò=1

subject to the constraints Ì†µÌ∞∂1-Ì†µÌ∞∂4 of problem P1 in Eq. (13). Using the decomposition technique [13], we can relax the

coupling constraints by dual decomposition and formulate the

partial Lagrangian function of optimization problem P5 as

follows:

‚ÑíÀú(Ì†µÌ≤Ü, Ì†µÌΩâ , Ì†µÌΩÅ) = ‚àë Ì†µÌ∞æ Ì†µÌºÜÌ†µÌ±òÌ†µÀúÌ∞∂Ì†µÌ±ò(Ì†µÌºèÌ†µÌ±ò, Ì†µÌ±íÌ†µÌ±ò)
Ì†µÌ±ò=1

+

{

Ì†µÌºáÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

Ì†µÌ¥ºÌ†µÌªæÌ†µÌ±ò

[( 1 Ì†µÌºèÌ†µÌ±ò

‚àí

)] 1 Ì†µÌ±íÌ†µÌ±ò
}

‚àí Ì†µÌºÖÌ†µÌºèÌ†µÌ±òÌ†µÌ±áÌ†µÌ±ì Ì†µÌ≤´Ì†µÌ±°Ì†µÌ±îÌ†µÌ∞∏,Ì†µÌ±ò

=

‚àèÌ†µÌ∞æ
Ì†µÌ±ò=1

Ì†µÌºÜÌ†µÌ±ò Ì†µÌ¥ºÌ†µÌªæÌ†µÌ±ò {

[( 1+
[(

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

Ì†µÌªæÌ†µÌ±ò

)‚àí(1‚àíÌ†µÌºèÌ†µÌ±ò )]

)Ì†µÌªΩÌ†µÌ±ò

]

}

+

Ì†µÌºáÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

Ì†µÌ¥ºÌ†µÌªæÌ†µÌ±ò

1 Ì†µÌºèÌ†µÌ±ò

‚àí1

Ì†µÌ±íÌ†µÌ±ò ‚àí Ì†µÌºÖÌ†µÌ±áÌ†µÌ±ì Ì†µÌ≤´Ì†µÌ±°Ì†µÌ±îÌ†µÌ∞∏,Ì†µÌ±ò

,

(26)

where Ì†µÌºáÌ†µÌ±ò is the non-negative Lagrangian multiplier associated with constraints Ì†µÌ∞∂1-Ì†µÌ∞∂4 of problem P1 in Eq. (13), Ì†µÌΩÅ = [Ì†µÌºá1, . . . , Ì†µÌºáÌ†µÌ∞æ ] represents the vector of Lagrangian multipliers, and Ì†µÌªΩÌ†µÌ±ò ‚âú Ì†µÌºÉÌ†µÌ±òÌ†µÌ±áÌ†µÌ±ì Ì†µÌ∞µ/ log 2 is deÔ¨Åned as the normalized QoS exponent at user Ì†µÌ±ò. Due to the convexity of optimization
problem P5, the duality gap between P5 and its dual problem

811

is zero. Correspondingly, we can formulate the Lagrangian dual function as follows:

Ì†µÌ≤ü(Ì†µÌΩÅ) = arg max ‚ÑíÀú(Ì†µÌ≤Ü, Ì†µÌΩâ , Ì†µÌΩÅ),

(27)

{Ì†µÌ≤Ü,Ì†µÌΩâ }

Therefore, the Lagrange dual problem P6 is given as follows:

P6

:

arg min Ì†µÌ≤ü(Ì†µÌΩÅ),
Ì†µÌΩÅ

(28)

s.t. Ì†µÌΩÅ ‚â• 0.

(29)

Theorem 1: The optimal joint power and time allocation that

maximizes the end-to-end effective capacity for our proposed

EH based multihop scheme in high SINR regime can be derived

as

fol‚éßlows: Ô£¥Ô£¥Ô£¥‚é®Ì†µÌºèÌ†µoÌ±òpt

=

Ì†µÌ≤≤(‚àí ( log Ì†µÌ±íoÌ†µÌ±òptÌ†µÌªæÌ†µÌ±ò)) ( ) ‚àí log Ì†µÌ±íoÌ†µÌ±òptÌ†µÌªæÌ†µÌ±ò

;

opt

Ì†µÌºèÌ†µoÌ±òpt Ì†µÌªΩÌ†µÌ±ò

Ô£¥Ô£¥Ô£¥‚é©Ì†µÌ±í = Ì†µÌ±ò

Ì†µÀúÌºÜÌ†µÌ±ò

‚àèÌ†µÌ∞æ (
Ì†µÌ±ò=1

Ì†µÌºèÌ†µoÌ±òptÌ†µÌªΩÌ†µÌ±ò Ì†µÌªæÌ†µÌ±ò Ì†µÌºÜoÌ†µÌ±òpt Ì†µÌºáÌ†µÌ±ò

)

(1‚àíÌ†µÌºèÌ†µoÌ±òpt )Ì†µÌªΩÌ†µÌ±ò 1+(1‚àíÌ†µÌºèÌ†µoÌ±òpt )Ì†µÌ∞æ Ì†µÌªΩÌ†µÌ±ò

‚àí

1 Ì†µÌªæÌ†µÌ±ò

,

(30)

where Ì†µÌ≤≤(‚ãÖ) denotes the Lambert W function [14] and Ì†µÌºÜoÌ†µÌ±òpt is the optimal Lagrange multiplier and can be numerically obtained by

substituting Eq. (30) back into constraint Ì†µÌ∞∂1 for problem P1 given by Eq. (13).

Proof: Applying the Karush-Kuhn-Tucker (KKT) condition, we can take the derivative of ‚ÑíÀú(Ì†µÌ≤Ü, Ì†µÌΩâ , Ì†µÌΩÅ) with respect to Ì†µÌ±íÌ†µÌ±ò

and Ì†µÌºèÌ†µÌ±ò (1 ‚â§ Ì†µÌ±ò ‚â§ Ì†µÌ∞æ) and set the results to zero as follows:

‚àÇ‚ÑíÀú(Ì†µÌ≤Ü, Ì†µÌΩâ , Ì†µÌΩÅ) ‚àÇÌ†µÌ±íÌ†µÌ±ò

=‚àí

(1

‚àí

Ì†µÌºèÌ†µÌ±ò

)Ì†µÌªΩÌ†µÌ±ò

Ì†µÌªæÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

( 1+

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

Ì†µÌªæÌ†µÌ±ò

)‚àí1

√ó

‚àèÌ†µÌ∞æ Ì†µÌºÜÌ†µÌ±ò
Ì†µÌ±ò=1

( 1

+

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

)‚àí(1‚àíÌ†µÌºèÌ†µÌ±ò )Ì†µÌªΩÌ†µÌ±ò Ì†µÌªæÌ†µÌ±ò

Ì†µÌ±ùŒìÌ†µÌ±ò (Ì†µÌªæÌ†µÌ±ò)

+

Ì†µÌºáÌ†µÌ±ò

(1 ‚àí Ì†µÌºèÌ†µÌ±ò (Ì†µÌºèÌ†µÌ±ò )2

)

Ì†µÌ±ùŒìÌ†µÌ±ò

(Ì†µÌªæÌ†µÌ±ò

)

=

0.

(31)

and
‚àÇ‚ÑíÀú(Ì†µÌ≤Ü, Ì†µÌΩâ , Ì†µÌΩÅ) ‚àÇÌ†µÌºèÌ†µÌ±ò

‚éõ = ‚éùÌ†µÌªΩÌ†µÌ±ò

(

)

log

1

+

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

Ì†µÌªæÌ†µÌ±ò

+

‚éû

((1 ‚àí Ì†µÌºèÌ†µÌ±ò)Ì†µÌªΩ)Ì†µÌ±òÌ†µÌ±íÌ†µÌ±òÌ†µÌªæÌ†µÌ±ò ‚é†

1+

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

Ì†µÌªæÌ†µÌ±ò

(Ì†µÌºèÌ†µÌ±ò )2

√ó

‚àèÌ†µÌ∞æ ( Ì†µÌºÜÌ†µÌ±ò 1
Ì†µÌ±ò=1 (

+

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

)‚àí(1‚àíÌ†µÌºèÌ†µÌ±ò )Ì†µÌªΩÌ†µÌ±ò Ì†µÌªæÌ†µÌ±ò
)

Ì†µÌ±ùŒìÌ†µÌ±ò (Ì†µÌªæÌ†µÌ±ò)

+ Ì†µÌºáÌ†µÌ±òÌ†µÌ±íÌ†µÌ±ò

‚àí2 (Ì†µÌºèÌ†µÌ±ò )3

+

1 (Ì†µÌºèÌ†µÌ±ò )2

Ì†µÌ±ùŒìÌ†µÌ±ò (Ì†µÌªæÌ†µÌ±ò) = 0, (32)

where Ì†µÌ±ùŒìÌ†µÌ±ò (Ì†µÌªæÌ†µÌ±ò) is deÔ¨Åned in Eq. (9). According to Eq. (31), we

have

( 1+

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

Ì†µÌªæÌ†µÌ±ò

)‚àí1

=

Ì†µÌºáÌ†µÌ±ò ‚àèÌ†µÌ∞æ ( Ì†µÌºèÌ†µÌ±òÌ†µÌªΩÌ†µÌ±òÌ†µÌªæÌ†µÌ±ò Ì†µÌºÜÌ†µÌ±ò 1 +
Ì†µÌ±ò=1

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

)‚àí(1‚àíÌ†µÌºèÌ†µÌ±ò )Ì†µÌªΩÌ†µÌ±ò Ì†µÌªæÌ†µÌ±ò

.

(33)

Multiplying Ì†µÌ∞æ equations in Eq. (33), we can derive the relation-

ship time

between the optimal power allocation Ì†µÌºèÌ†µoÌ±òpt as follows:

allocation

Ì†µÌ±íoÌ†µÌ±òpt

and

the

optimal

opt

Ì†µÌºè Ì†µÌªΩ opt

Ì†µÌ±ò Ì†µÌ±ò

Ì†µÌ±í = Ì†µÀúÌºÜ ‚àè ( ) Ì†µÌ±ò

Ì†µÌ∞æ
Ì†µÌ±ò Ì†µÌ±ò=1

Ì†µÌºèÌ†µoÌ±òptÌ†µÌªΩÌ†µÌ±ò Ì†µÌªæÌ†µÌ±ò Ì†µÌºÜoÌ†µÌ±òpt Ì†µÌºáÌ†µÌ±ò

(1‚àíÌ†µÌºèÌ†µoÌ±òpt )Ì†µÌªΩÌ†µÌ±ò 1+(1‚àíÌ†µÌºèÌ†µoÌ±òpt )Ì†µÌ∞æ Ì†µÌªΩÌ†µÌ±ò

‚àí

1 Ì†µÌªæÌ†µÌ±ò

,

(34)

where Ì†µÌºÜoÌ†µÌ±òpt is the optimal Lagrange multiplier and can be numerically obtained by substituting Eq. (34) back into constraint

Ì†µÌ∞∂1 for problem P1 given by Eq. (13). Then, combing Eq. (31) and Eq. (32), we have

(

)

log

1

+

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

Ì†µÌªæÌ†µÌ±ò

=

Ì†µÌ±íÌ†µÌ±ò Ì†µÌªæÌ†µÌ±ò (Ì†µÌºèÌ†µÌ±ò )2

( 1

+

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

)‚àí1 Ì†µÌªæÌ†µÌ±ò

.

(35)

In high SINR regime, we have 1 + Ì†µÌ±íÌ†µÌ±òÌ†µÌªæÌ†µÌ±ò/Ì†µÌºèÌ†µÌ±ò ‚â´ 1. Correspondingly, we can approximately rewrite Eq. (35) as follows:

()

log

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

Ì†µÌªæÌ†µÌ±ò

=

Ì†µÌ±íÌ†µÌ±ò Ì†µÌªæÌ†µÌ±ò (Ì†µÌºèÌ†µÌ±ò )2

(

Ì†µÌ±íÌ†µÌ±ò Ì†µÌºèÌ†µÌ±ò

Ì†µÌªæÌ†µÌ±ò

)‚àí1

.

(36)

Then, we apply the Lambert W function [14] to solve Eq. (35)

for Ì†µÌ±ò = 1, 2, . . . , Ì†µÌ∞æ. Then, we can derive the optimal time

allocation that maximizes the end-to-end effective capacity for

our proposed EH based multihop scheme as follows:

Ì†µÌºèÌ†µoÌ±òpt = Ì†µÌ≤≤ ‚àí(‚àílolgog(Ì†µ(Ì±íoÌ†µÌ†µÌ±òpÌ±íoÌ†µtÌ±òÌ†µpÌªætÌ†µÌ†µÌ±òÌªæ)Ì†µÌ±ò)) ,

(37)

where Ì†µÌ≤≤(‚ãÖ) denotes the Lambert W function. By substituting Eq. (37) into Eq. (34), we can derive the optimal power allocation policy for our proposed EH based scheme as in Eq. (30). Therefore, we complete the proof of Theorem 1.

V. Q-LEARNING BASED MULTIHOP ROUTING ALGORITHM UNDER HETEROGENEOUS STATISTICAL DELAY-BOUNDED
QOS PROVISIONINGS
In the previous section, we derive the optimal joint power and time allocation policy by applying the DTMDP based algorithm. However, in order to use DTMDP based algorithm, we assume that the transition probability can be calculated in advance for deriving the optimal multihop routing policy in Algorithm 1 over EH based multihop relay networks. In practical scenarios, it is usually infeasible to derive an exact model of the transition probability for our proposed EH based multihop relay scheme because of the large state space and the uncertainty of the energy state information (ESI), CSI, and the mobile users‚Äô mobility [15]. As a result, we propose to apply the reinforcement learning method which allows the mobile users to try different actions in different network states within inÔ¨Ånite number of times until it can gradually adapt to the dynamically changing environment according to the received feedbacks. In this section, we propose the Q-learning based multihop routing algorithm in order to solve the optimization problem P1 with unknown transition probability. In particular, we apply the Qlearning based multihop routing algorithm at the source node to choose a route with the lowest maximum end-to-end effective capacity. Q-learning method can gradually learn an optimal decision policy without knowing the transition probabilities.
The goal of the Q-learning based multihop routing algorithm is to learn to select the best action given state Ì†µÌ±∫(Ì†µÌ±°) for users such that the best reward (maximum end-to-end effective capacity) can be achieved. Given state Ì†µÌ±∫(Ì†µÌ±°) at time slot Ì†µÌ±°, a Ô¨Ånite number of possible actions can be selected to perform at the users.

812

Algorithm 2 Q-Learning Based Multihop Routing Algorithm

Input: Ì†µÌ±áÌ†µÌ±ì , Ì†µÌ∞µ, Ì†µÌ∞æ, Ì†µÌ≤´1, Ì†µÌ≤´2, . . . , Ì†µÌ≤´Ì†µÌ∞æ [

]

Initialization: [Ì†µÌ≤´1, Ì†µÌ≤´2, . . . , Ì†µÌ≤´Ì†µÌ∞æ ] = Ì†µÌ≤´1, Ì†µÌ≤´2, . . . , Ì†µÌ≤´Ì†µÌ∞æ

for each state Ì†µÌ±∫ and action Ì†µÌ≤Ç do

Ì†µÌ±Ñ (Ì†µÌ±∫, Ì†µÌ≤Ç) = 0

end for

Learning:

if Ì†µÌ±üÌ†µÌ±éÌ†µÌ±õÌ†µÌ±ë(‚ãÖ) < Ì†µÌºñ then

randomly select a routing action

else

Observe the current state Ì†µÌ±∫(Ì†µÌ±°) and select an action Ì†µÌ≤Ç(Ì†µÌ±°)

with maximum Q value.

end if

Observe the transition state Ì†µÌ±∫(Ì†µÌ±°) ‚Üí Ì†µÌ±∫(Ì†µÌ±° + 1) and calculate

the immediate reward.

Update the Q value function using Eq. (39).

Set Ì†µÌ±° ‚Üê (Ì†µÌ±° + 1).

Correspondingly, user Ì†µÌ±ò need to guarantee that the transmit

power satisÔ¨Åes the following constraint: {

Ì†µÌ≤´Ì†µÌ±ò(Ì†µÌ±°) ‚â§ Ì†µÌ∞µÌ†µÌ±ò(Ì†µÌ±°);

(38)

Ì†µÌ∞µÌ†µÌ±ò(Ì†µÌ±° + 1) = Ì†µÌ∞µÌ†µÌ±ò(Ì†µÌ±°) ‚àí min {Ì†µÌ≤´Ì†µÌ±ò(Ì†µÌ±°), Ì†µÌ∞µÌ†µÌ±ò(Ì†µÌ±°)} + Ì†µÌ∞∏Ì†µÌ±ò(Ì†µÌ±°).

With the unknown users‚Äô mobility, it is obvious that transition

probability is no longer needed in Q-learning algorithm. Accord-

ingly, using the Q-learning algorithm, the network controller need to calculate Q-function Ì†µÌ±Ñ (Ì†µÌ±∫(Ì†µÌ±°), Ì†µÌ≤Ç(Ì†µÌ±°)) at each time slot Ì†µÌ±° in order to learn which action is optimal for the corre-

sponding state. The Q value updating depends on the states {Ì†µÌ±∫(Ì†µÌ±° + 1), Ì†µÌ±∫(Ì†µÌ±°)} and actions Ì†µÌ≤Ç(Ì†µÌ±°), and thus the corresponding

reward can be derived as follows: [ ‚àë Ì†µÌ∞æ
Ì†µÌ±Ñ (Ì†µÌ±∫(Ì†µÌ±°), Ì†µÌ≤Ç(Ì†µÌ±°)) ‚Üê(1 ‚àí Ì†µÀÜÌªº)Ì†µÌ±Ñ (Ì†µÌ±∫(Ì†µÌ±°), Ì†µÌ≤Ç(Ì†µÌ±°)) + Ì†µÀÜÌªº Ì†µÌ∞∂Ì†µÌ±ò(Ì†µÌºÉÌ†µÌ±ò, Ì†µÌ±°)

‚àë(

)] Ì†µÌ±ò=1

+ Ì†µÌºÅ max Ì†µÌ±Ñ Ì†µÀúÌ±∫, Ì†µÌ≤Ç ,

(39)

Ì†µÌ≤Ç‚ààÌ†µÌ±®

Ì†µÀúÌ±∫‚ààÌ†µÌ≤Æ

where 0 < Ì†µÀÜÌªº ‚â§ 1 denotes the learning rate, Ì†µÌºÅ is the discount factor, w(here)Ì†µÀúÌ±∫ denotes the next state at time slot (Ì†µÌ±° + 1), and max Ì†µÌ±Ñ Ì†µÀúÌ±∫, Ì†µÌ≤Ç represents the estimation of the optimal future
Ì†µÌ≤Ç‚ààÌ†µÌ±®
Q value based on the best selected actions. In addition, the Ì†µÌºÄ-greedy policy is applied at the network controller in each

time slot for the action selection, in which the action with the

maximum value of the effective capacity is chosen with a high possibility (1 ‚àí Ì†µÌºÄ), and the rest actions are selected randomly with a small probability Ì†µÌºÄ. Accordingly, the Q-learning based

multihop routing algorithm for our proposed EH scheme is

described in Algorithm 1. According to Algorithm 1, using Ì†µÌºñ-greedy policy, the pro-

posed Q-learning based multihop routing algorithm converges with probability one as Ì†µÌ±° ‚Üí ‚àû if the learning rate Ì†µÀÜÌªº satisÔ¨Åes

the following conditions:

{

}

‚àë

‚àë

0 ‚â§ Ì†µÀÜÌªº < 1; Ì†µÀÜÌªº = ‚àû; Ì†µÀÜÌªº2 < ‚àû .

(40)

Ì†µÌ±°

Ì†µÌ±°

Normalized End-to-End Effective Capacity

1

K = 10

K=8

0.8

K=6

0.6

0.4

0.2

0

0

0.5

1

1.5

2

2.5

3

Path Loss Exponent

Fig. 2. The normalized end-to-end effective capacity v.s. path loss exponent Ì†µÀúÌªº over multihop big-data relay networks.

Normalized End-to-End Effecteive Capacity

1

= 0.8

= 0.6

0.8

= 0.4

0.6

0.4

0.2

0 15 16 17 18 19 20 21 22 23 24 25
Transmit Power (dB)

Fig. 3. The normalized end-to-end effective capacity v.s. transmit power at the energy harvester over multihop big-data relay networks.

For brevity, the convergence of the proposed Q-learning algorithm can be found in [16] when the learning rate satisÔ¨Åes the conditions in Eq. (40).
VI. PERFORMANCE EVALUATIONS
We use simulations to validate and evaluate our proposed schemes. Throughout our simulations, we set the bandwidth Ì†µÌ∞µ = 5 MHz for all mobile users, the time frame Ì†µÌ±áÌ†µÌ±ì = 2 s, and the average transmit power Ì†µÌ≤´Ì†µÌ±ò = 1 Watt for mobile user Ì†µÌ±ò.
DeÔ¨Åne the normalized effective capacity as the effective capacity divided by Ì†µÌ∞µ and Ì†µÌ±áÌ†µÌ±ì , which then has the unit of bits/sec/Hz. Consider the three-hop EH based multihop scheme, Fig. 2 and Fig. 3 plot the normalized end-to-end effective capacity v.s. path loss exponent Ì†µÀúÌªº and transmit power at the energy harvester, respectively. As shown in Fig. 2, the normalized end-to-end effective capacity decreases as the quality of wireless channel becomes worse. We can observe from Fig. 2 that the normalized end-to-end effective capacity increases with the increase of the number of users. Also, Fig. 3 shows that our proposed scheme performs better with more harvested energy.
Figure 4 depicts the normalized end-to-end effective capacity with different number of hops for our proposed EH based big-

813

Normalized End-to-End Effecteive Capacity

1

0.8

Upper bound

0.6

0.4
Lower bound 0.2
0

5

10 15 20 25 30 35

Number of hops

Fig. 4. The upper bound and lower bound for the normalized end-to-end effective capacity with different number of hops.

1

Normalized End-to-End Effective Capacity

0.8

0.6

0.4

0.2 0

0

0

500 1000 1500 2000 2500 3000

Number of Iterations

Fig. 5. The upper bound and lower bound for the normalized end-to-end effective capacity with different number of hops.

data multihop relay networks. Fig. 4 shows that the loose QoS exponent (Ì†µÌºÉ ‚Üí 0) and the stringent QoS exponent (Ì†µÌºÉ ‚Üí ‚àû) set the upper bound and lower bound for the normalized effective capacity, respectively. Also as shown in Fig. 4, the normalized end-to-end effective capacity increases as the number of hops increases, which implies that our proposed multihop EH scheme can outperform the traditional single-hop schemes in terms of the normalized end-to-end effective capacity.
Set the number of users Ì†µÌ∞æ = 8 and the energy harvesting efÔ¨Åciency Ì†µÌºÖ = 0.6. Using Algorithm 1, Fig. 5 plots the upper bound and lower bound of the normalized end-to-end effective capacity for our proposed Q-learning based multihop routing algorithm with different number of mobile user over big-data multihop relay networks. We can observe from Fig. 5 that the normalized end-to-end effective capacity increases as the number of iterations increases, and Ô¨Ånally achieves the optimal multihop routing strategy.
VII. CONCLUSIONS
We have designed the Q-learning based algorithm for optimizing power and routing policies through learning from the history of the EH process while satisfying the heterogeneous

statistical delay-bounded QoS constraints over multihop big-
data relay networks. In particular, we have established and
analyzed the wireless communication model as well as the
EH model. Under the heterogeneous statistical delay-bounded
QoS requirements, we have formulated the end-to-end effective-
capacity optimization problem for the battery-free EH based
multihop relay networks. Then, we have developed DTMDP
and Q-learning based multihop routing algorithms. We have
also conducted a set of simulations which show that our pro-
posed Q-learning based EH scheme outperforms other existing
schemes under the heterogeneous statistical delay-bounded QoS
constraints over multihop big-data relay networks.
REFERENCES
[1] H. Su and X. Zhang, ‚ÄúCross-layer based opportunistic MAC protocols for QoS provisionings over cognitive radio wireless networks,‚Äù IEEE Journal on Selected Areas in Comm., vol. 26, no. 1, pp. 118‚Äì129, Jan. 2008.
[2] J. Wang and X. Zhang, ‚ÄúHeterogeneous QoS-driven resource adaptation over full-duplex relay networks,‚Äù in IEEE GLOBECOM 2016.
[3] T. Z. Oo, N. H. Tran, W. Saad, D. Niyato, Z. Han, and C. S. Hong, ‚ÄúOfÔ¨Çoading in HetNet: A coordination of interference mitigation, user association, and resource allocation,‚Äù IEEE Transactions on Mobile Computing, vol. 16, no. 8, pp. 2276‚Äì2291, Aug. 2017.
[4] Q. Wu, M. Tao, D. W. K. Ng, W. Chen, and R. Schober, ‚ÄúEnergy-efÔ¨Åcient resource allocation for wireless powered communication networks,‚Äù IEEE Trans. on Wireless Comm., vol. 15, no. 3, pp. 2312‚Äì2327, Mar. 2016.
[5] S. Akbar, Y. Deng, A. Nallanathan, M. Elkashlan, and A.-H. Aghvami, ‚ÄúSimultaneous wireless information and power transfer in K-tier heterogeneous cellular networks,‚Äù IEEE Trans. on Wireless Comm., vol. 15, no. 8, pp. 5804‚Äì5818, Aug. 2016.
[6] C.-S. Chang, ‚ÄúStability, queue length, and delay of deterministic and stochastic queueing networks,‚Äù IEEE Transactions on Auto. Control, vol. 39, no. 5, pp. 913‚Äì931, May 1994.
[7] X. Zhang, W. Cheng, and H. Zhang, ‚ÄúHeterogeneous statistical QoS provisioning over 5G mobile wireless networks,‚Äù IEEE Network Magazine, vol. 28, no. 6, pp. 46‚Äì53, Nov. 2014.
[8] W. Cheng, X. Zhang, and H. Zhang, ‚ÄúHeterogeneous statistical QoS provisioning for downlink transmissions over mobile wireless cellular networks,‚Äù in IEEE GLOBECOM 2014, pp. 4757‚Äì4763.
[9] J. Tang and X. Zhang, ‚ÄúQuality-of-service driven power and rate adaptation over wireless links,‚Äù IEEE Trans. on Wireless Comm., vol. 6, no. 8, pp. 3058‚Äì3068, Aug. 2007.
[10] T. J. Van and L. A. Wolsey, ‚ÄúSolving mixed integer programming problems using automatic reformulation,‚Äù IEEE Transactions on Wireless Communications, vol. 35, no. 1, pp. 45‚Äì57, Aug. 2007.
[11] R. Bellman, ‚ÄúDynamic programming,‚Äù in Princeton University Press, 1957.
[12] M. L. Littman, T. L. Dean, and L. P. Kaelbling, ‚ÄúOn the complexity of solving Markov decision problems,‚Äù in Proceedings of the Eleventh Conference on Uncertainty in ArtiÔ¨Åcial Intelligence, 1995, pp. 394‚Äì402.
[13] C. Xu, M. Zheng, W. Liang, H. Yu, and Y.-C. Liang, ‚ÄúEnd-to-end throughput maximization for underlay multi-hop cognitive radio networks with RF energy harvesting,‚Äù IEEE Transactions on Wireless Comm., vol. 6, no. 6, pp. 3561‚Äì3572, June 2017.
[14] R. M. Corless, G. H. Gonnet, D. E. G. Hare, D. J. Jeffrey, and D. E. Knuth, ‚ÄúOn the lambert w function,‚Äù Advances in Computational Mathematics, vol. 5, pp. 329‚Äì359, 1996.
[15] X. Chen, J. Wu, Y. Cai, H. Zhang, and T. Chen, ‚ÄúEnergy-efÔ¨Åciency oriented trafÔ¨Åc ofÔ¨Çoading in wireless networks: A brief survey and a learning approach for heterogeneous cellular networks,‚Äù IEEE Journal on Selected Areas in Communications, vol. 33, no. 4, pp. 3520‚Äì3535, April 2015.
[16] C. J. C. H. Watkins and P. Dayan, ‚ÄúQ-learning,‚Äù Machine Learning, vol. 8, no. 3, pp. 279‚Äì292, 1992.

814

