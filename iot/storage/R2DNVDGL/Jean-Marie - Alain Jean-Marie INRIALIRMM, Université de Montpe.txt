Queueing Systems
Queueing Systems
Alain Jean-Marie INRIA/LIRMM, Université de Montpellier, CNRS
Alain.Jean-Marie@inria.fr
RESCOM Summer School 2019 June 2019

Queueing Systems
About the class
This class: Lesson 4: Queueing Systems (2h, now) Case Study 3: Queuing Systems (1h, after the break)
Companion classes: Lesson 5 and Case Study 4: Markov Decision Processes by E. Hyon (2h + 1h, tomorrow)
Common Lab: Lab 3: Queueing Systems and Markov Decision Processes (2h, Friday)
Related talk: Opening 1: Models of Hidden Markov Chains for Trace Analysis on the Internet by S. Vatton (1h30, tomorrow)

Queueing Systems
Preparation of the lab
Topic of the lab: programming the basic discrete-time queue with impatience using the library marmoreCore (C++ programming) programming the same queue with a control of the service using the library marmoteMDP ﬁnding the optimal control policy.
Preparation: two possibilities using a virtual machine with virtualbox download VM + instructions from
http://www-desir.lip6.fr/~hyon/Marmote/MachineVirtuelle/Rescom2019_ TP.html
copy it from USB drive, ask the technician! using the library (linux only)
tarball + instructions from https://marmotecore.gforge.inria.fr/dokuwiki/

Queueing Systems
General Plan
Part 1: Basic features of queueing systems Part 2: Metrics associated with queuing Part 3: Modeling queueing systems with Markov chains Part 4: Numerical solution and simulation

Queueing Systems Part 1: Basics of Queueing
Part 1: Basics of Queueing

Queueing Systems Part 1: Basics of Queueing
Basics of Queueing: Plan
Table of contents customers, buﬀers, servers, arrival process, service time buﬀer capacity, blocking, rejection, impatience, balking, reneging customer classes, scheduling policy Kendall’s notation networks of queues, routing, blocking

Queueing Systems Part 1: Basics of Queueing Single Queues
Why study queues?
Queues are everywhere...
... and in particular, a lot in networks.

Queueing Systems Part 1: Basics of Queueing Single Queues
A queue
A queue is an abstraction for several actors sharing a resource. Queue / Queueing System waiting room server

arrivals a1, a2, . . .

wait

service

σ1, σ2, . . .

departure

The usual representation of a queueing system

Queueing Systems Part 1: Basics of Queueing Single Queues
Components of a queue
The elements that form a queue are: one or several servers → manage the access to the resource(s) one waiting room (possibly) several classes of customers an arrival process per class a process of service times per class → the total duration a customer will need the resource a service discipline a departure process

Queueing Systems Part 1: Basics of Queueing Single Queues
The dynamics of queues
Queues are systems that evolve over time. Fundamental quantities:
N(t) number of customers present in the queue W (t) quantity of work (workload, backlog) to be done for these
customers all this, at time t.

Queueing Systems Part 1: Basics of Queueing Single Queues
Dynamics of a queue

Consider customers with the following characteristics:
Number 1 2 3 4 5 Arrival 0 2 6 8 15 Service 4 8 4 4 2

Evolution of N(t), the number of customers: if FIFO service,

4 N (t)

3

2

1

0

t

0 2 4 6 8 10 12 14 16 18 20 22

1

2

3

4

5

Queueing Systems Part 1: Basics of Queueing Single Queues
Dynamics of the workload

Evolution of W (t), the workload:

W(t) 12

10

8

6

4

2

0

t

0 2 4 6 8 10 12 14 16 18 20 22

Jumps upwards at times 0, 2, 6, 8, 15 with steps 4, 8, 4, 4, 2.

Queueing Systems Part 1: Basics of Queueing Single Queues

Compared evolution of N(t) and W (t):

a1 a2

a3 a4

a5

W(t) 12 10 8 6 4 2 t 0 0 2 4 6 8 10 12 14 16 18 20 22
N(t) 4 3 2 1 t 0 0 2 4 6 8 10 12 14 16 18 20 22

1 d1

2

3

4

5

d2

d3

d4 d5

Queueing Systems Part 1: Basics of Queueing Single Queues
Idle periods, busy periods
In general, the typical evolution of W (t) is of the form:
W (t)

IP

BP

IP

BP

IP BP IP

BP

It alternates busy periods and idle periods.

Queueing Systems Part 1: Basics of Queueing Single Queues
Arrival process

The sequence of arrival times a1, a2, . . . , an, . . . forms the arrival process.
It is often characterized by the sequence of inter-arrival times: τn = an+1 − an. For instance, for the Poisson process, the sequence {τn; n ∈ N} is i.i.d. with distribution:

P{τn ≤ x} = 1 − e−λx ,

where λ > 0 is a parameter: the rate of the process. If the process has i.i.d. inter-arrivals τ , then

λ

=

1 Eτ

.

In discrete time, the process can be characterized by the sequence {An; n ∈ N} where An is the number of arrivals in “slot” n.
A grouped arrival is called a batch.

Queueing Systems Part 1: Basics of Queueing Single Queues
Services
The service requirement of a customer is a random variable: σn for the n-th customer.
Typical distributions in queueing theory are: the exponential distribution:
P{σn ≤ x} = 1 − e−µx ,
for some µ > 0. The average service time is then Eσ = 1/µ. the Erlang distribution (sum of exponential distributions) the Hypergeometric distribution (mixtures of exponentials) the deterministic distribution many others.

Queueing Systems Part 1: Basics of Queueing Single Queues
Number of servers
The queue may have one or several servers. single-server queue: the standard situation multi-server queue: one single queue for all servers NOT to be confused with several single-server queues in parallel servers may be heterogeneous in speed inﬁnite-server queue no waiting think of a population of independent individuals

Queueing Systems Part 1: Basics of Queueing Single Queues
Service discipline
The way waiting customers enter service is speciﬁed by the service discipline (or service policy, scheduling policy). Some usual service disciplines:
FCFS (First-Come-First-Served): service in the order of arrival FIFO (First-In-First-Out): the common name for FCFS LIFO (Last-In-First-Out): the stack PS (Processor Sharing): customers get simultaneously some share of the resource Some variants, especially when several classes:
egalitarian PS weighted PS Head-of-the-Line PS
Priorities: each class of customers has a priority level. Those with the highest priority are served ﬁrst. FIFO among customers with same priority.

Queueing Systems Part 1: Basics of Queueing Single Queues
Service discipline (ctd.)
Other service discipines, whith some sort of priority Based on the service duration SPT (Shortest Processing Time), SRPT (Shortest Remaining Processing Time), LPT, etc. Based on a deadline (real-time policies): EDF (Earliest Deadline First), aka EDD (Earliest Due Date) and many more LLF (Least Laxity First), etc.

Queueing Systems Part 1: Basics of Queueing Single Queues
Service discipline: preemption
In certain service disciplines such as: priority-based LIFO, SPT, SRPT, . . .
a customer that arrives may have a higher priority than the customer currently in service.
non-préemption nothing happens until the end of current service preemption the service is interrupted; when interrupting tasks are over: resume service will continue from where it has stopped restart service will start over kill! service will never start again!

Queueing Systems Part 1: Basics of Queueing Single Queues
Complications with service
Idle servers are costly so: servers may take vacations once repeated as long as nobody to serve servers may poll several waiting rooms according to several policies visiting queues: cyclic, greedy, random, ... serving queues: limited, exhaustive, gated, ...

Queueing Systems Part 1: Basics of Queueing Single Queues
Queueing capacity and admission/rejection policy
The size of the buﬀer may be ﬁnite of inﬁnite. When ﬁnite: system capacity (including servers) or buﬀer capacity (without servers). “queue capacity” is ambiguous, usually refers to system capacity. In case of ﬁnite capacity, what happens to a customer which arrives when the queue is full?
rejection of the newcomer eviction of the last in queue (push-out): the queue behaves as a stack eviction of a customer of lesser priority eviction at random ...
In case of batch arrivals: rejection of the whole batch rejection of customers which ﬁt in queue

Queueing Systems Part 1: Basics of Queueing Single Queues
Other mechanisms
Impatience: customers do not like waiting behavior at the queue balking: not entering the queue if too much waiting is expected reneging: leaving the waiting room (or service) if too much waiting behavior after balking/reneging permanent departure resubmission after some “orbit”
Redundant jobs: submit the same service request to diﬀerent queues cancel on start, cancel on completion
Jockeying...

Queueing Systems Part 1: Basics of Queueing Kendall’s notation
Necessity of a notation
Queues are not simple in/out linear systems... The quality of service in a queue may depend on
the distribution of the arrival process → not only its average throughput the distribution of the service times, → not only its average, variance. the number of servers, the size of the waiting room, the service discipline... =⇒ necessity to specify clearly the parameters of a queue.

Queueing Systems Part 1: Basics of Queueing Kendall’s notation
Example: dependence on the service discipline

Illustration of this idea: with the data previously introduced.

Compared evolution of N(t) for diﬀerent service discipline + statistics

LIFO-NPR

PS FIFO

N (t) 4
3

SPT-PR LIFO-NPR

Policy FIFO LIFO-PR

Avg Var 8,6 7,8 10,8 61,8

2

1

0

t

0 2 4 6 8 10 12 14 16 18 20 22

LIFO-NPR 8,2 21,8

SPT-PR 7,2 42,6

PS

11,3 26,1

=⇒ Necessity to specify clearly the queueing model.

Queueing Systems Part 1: Basics of Queueing Kendall’s notation
Kendall’s notation
This notation allows to identify certain queues among the variety of possibilities. A queueing model is denoted by:
A/S/P/K/D
A the inter-arrival distribution S the service time distribution P the number of servers K the system capacity (by default: ∞) D the discipline of service (by default: FIFO)

Queueing Systems Part 1: Basics of Queueing Kendall’s notation
Code for Kendall’s notation
Usual codes for distributions: D : deterministic/Dirac M : exponential distribution (Markov), Poisson process E : Erlang distribution H : Hyperexponential distribution G : general distribution GI : general distribution, i.i.d. sequence
PH : phase-type distribution MMPP : Markov-modulated Poisson process BMAP : Batch Markov Arrival process
...

Queueing Systems Part 1: Basics of Queueing Kendall’s notation
Common examples of queues in Kendall’s notation
The most useful queues: M/M/1 (abbreviation of M/M/1/∞/FIFO) M/M/1/K (equivalent to M/M/1/K/FIFO) M/GI/1 M/M/K/K GI/M/1 M/GI/∞

Queueing Systems Part 1: Basics of Queueing Networks of Queues
Networks of Queues

Most interesting systems have several resources → several queues.
Each queue is an input/ouput system for customers: possibility to interconnect them.

arrivals

Queue

departures
service completions

rejection / balking eviction impatience

Specifying customer movement: two main ways probabilistic routing, possibly with change of class deterministic routing depending on the class

Queueing Systems Part 1: Basics of Queueing Networks of Queues
Jackson Networks
Jackson Networks are networks of queues with probabilistic routing. Speciﬁcation of a Jackson Network:
N “nodes” which are single-server queues with a duration of service ∼ Exp, one single class of customers the service rates at each node (µ1, . . . , µN ) a vector of arrival rates λ0 = (λ0,1, . . . , λ0,N ) for Poisson processes of customers at each node a square matrix N × N of routing probabilities R:
ri,j = P{a customer which exits node i goes to j} .

Queueing Systems Part 1: Basics of Queueing Networks of Queues
Example of Jackson Network

The “central server” model:
λ01
µ2 µ3 µ4

r10 µ1
r12
r13
r14

Queueing Systems Part 1: Basics of Queueing Networks of Queues
Kelly Networks
Speciﬁcation of a Kelly Network customers belong to diﬀerent classes to each cass corresponds a route in the network: rk = (rk1, . . . , rknk ) . customers arrive at route rk according to a Poisson process with rate λk customers/s the service duration in node j is ∼ Exp(µj )

Queueing Systems Part 1: Basics of Queueing Networks of Queues
Example of a Kelly network

Example with 5 nodes (queues) and 4 routes.

2

3

1

4

5

Routes
(1,2,3) (1,2,5) (1,4) (1,4,5)

This route topology is feed-forward: no loops.

Queueing Systems Part 1: Basics of Queueing Other queueing models
Extensions
Other networks of queues BCMP Networks multiple classes multiple servers, inﬁnite servers processor sharing discipline Whittle Networks G-Networks with negative customers ...

Queueing Systems Part 1: Basics of Queueing Other queueing models
Other sorts of queues

Fluid queues: no more individual customers, but a “ﬂuid” of work arriving with an instantaneous rate r (t) (variable) being served at an instantaneous rate C (t).
Example: an ON/OFF process with constant rates:

Oﬀ

Oﬀ

Oﬀ

rate On

On

On

Workload W (t)
8 7 6 5 4 3 2 1 0
t1

ti = end of processing of the ﬂuid arrived during the i-th "On" period

t2

t3 time t

Queueing Systems Part 2: Metrics associated with queuing
Part 2: Metrics associated with queueing

Queueing Systems Part 2: Metrics associated with queuing
Metrics associated with queuing
Table of contents: stability of queues throughputs and their diﬀerent kinds conservation laws for throughputs waiting times, response times occupancy: distribution and average, Little’s formula

Queueing Systems Part 2: Metrics associated with queuing
Metrics
General metrics apply to queues or network of queues capacity related to stability
throughputs débit d’arrivée, débit de sortie, débit oﬀert, débit eﬃcace, débit perdu
times time spent in the system, time spent waiting loss rates/probabilities in case of ﬁnite capacities, or impatiences
utilization of the server, of the waiting room

Queueing Systems Part 2: Metrics associated with queuing
Stability

Stability refers to the system “not exploding”.
Mathematically: from some sequences of random variables (see wn or rn below), or the processes {N(t); t ∈ R} {W (t); t ∈ R}: they have a proper limit when n or t goes to inﬁnity.
Principal stability result The G /G /1 queue is stable if and (almost) if

Eσ < Eτ

Consequences: the queue has a service capacity

1 Cmax = Eσ customers/s it is stable if and only if

λ=

1 Eτ

< Cmax .

Queueing Systems Part 2: Metrics associated with queuing Throughputs
Throughputs

The throughput is a number associated with a stream of “events” occurring at discrete times: t1, t2, . . . , tn, . . . .
Mathematically, it is deﬁned for stationary processes as:

θ

=

EN(0, T ) T

=

EN(0, 1) ,

where N(0, T ) is the (random) number of events in the interval [0, T ). Empirically, it is measured as:

θ ∼ N(0, T ) . T
Throughput is akin to a speed, a frequency. Measured in customers/s, events/s, etc. Sometimes called “rate”.

Queueing Systems Part 2: Metrics associated with queuing Throughputs
Many sort of throughputs
In a queue oﬀered throughput, arrival rate departure rate global of successful customers: goodput rejection rate, reneging rate, impatience rate ...

Queueing Systems Part 2: Metrics associated with queuing Throughputs
Conservation of throughputs

Conservation law: throughputs are conserved

λp λ1

λ1 + λ2

λ

λ

θ

S

λ2 λ(1 − p)
Laws of conservation of throughputs: merge, split and I/O

Input/Output law: for System S:
if S is stable, input throughput and output throughput coincide: θ = λ; otherwise, customers accumulate at rate λ − θ θ = max{λ, Cmax }.

Queueing Systems Part 2: Metrics associated with queuing Throughputs
Flow conservation in networks of queues

Application to networks of queues: traﬃc equations and stability conditions.
In both Jackson and Kelly networks, as long as no customers are lost and no accumulation occurs, it is possible to write traﬃc equations using the laws of conservation.

For Jackson Networks: let λˆi be the arrival rate to node i: and λ = (λˆ1, . . . , λˆN ).
The traﬃc equations write as:

λ = λ0 + λ R

N

λˆi = λi,0 +

λj rji .

j =1

The stability condition for the network is:

∀1 ≤ i ≤ N, λˆi < µi .

Queueing Systems Part 2: Metrics associated with queuing Throughputs
Traﬃc equations in Kelly networks

In a Kelly Network with routes (r1, . . . , rK ): the throughput of customers of class/route k entering node i is:

λˆik = λk × (numberof i in rk ).

the total arrival rate to node i:

λˆi =

λk × (nombre de i in rk ) .

ik

the stability condition:

∀1 ≤ i ≤ N, λˆi < µi .

Queueing Systems Part 2: Metrics associated with queuing Response times
Waiting times, Response times

Deﬁnitions:

response time rn = total time spent in the system, between arrival time and departure time

waiting time wn = total time spent in the waiting room (not being served)

Those are related by:

rn = wn + σn

Queueing Systems Part 2: Metrics associated with queuing Response times
General results: Little’s formula
The following relationship holds for general systems. Little’s formula The average response (sojourn) time R and the average number of customers N in a stable system where customers arrive at rate λ, are related by the formula:
λR = N

Queueing Systems Part 2: Metrics associated with queuing Response times
Waiting time: the FIFO case

wn: waiting time of customer number n before entering service σn: service duration
Lindley’s equation
Wn+1 = [Wn + σn − τn+1]+.

W (t)

τn+1

W (t)

τn+1

σn Wn Wn+1
an

σn

t

Wn

Wn+1

an+1

an

t an+1

Queueing Systems Part 2: Metrics associated with queuing Response times
Virtual waiting time, real waiting time
If an is the arrival time of customer n and if FIFO: Wn = W (an−) .
=⇒ W (t) is also called: virtual waiting time. Warning! Wn and W (t) do not necessarily have the same distribution!
PASTA Property (Poisson Arrivals See Time Averages) If arrivals are Poisson, the stationary distributions of Wn and W (t) do coincide.

Queueing Systems Part 2: Metrics associated with queuing Utilization
Utilization

Utilization of a resource is the fraction of the time some resource is used.
Let U(0, T ) be the total quantity of resource used in interval [0, T ). Then the utilization of the resource is:

ρ

=

limsupT →∞

U(0, T ) T

.

Consquence of Little’s formula:

Utilization in the G /G /1 queue The utilization of the server in a stable G /G /1 queue is:

ρ=

λ Cmax

= λ Eσ

Queueing Systems Part 2: Metrics associated with queuing Other metrics
Other metrics
Other metrics are sometimes of interest: jitter : a measure of the variation of response times {rn}
relaxation time : a measure of the time it takes for the system to becom stationary
busy periods : distribution, average, variance of the length of busy periods

Queueing Systems Part 3: Markov Chains
Part 3: Modeling queueing systems with Markov chains

Queueing Systems Part 3: Markov Chains
Modeling queueing systems with Markov chains
Table of contents: basic modeling of queues (in discrete time): system state, evolution equations crash course on discrete-time Markov chains deﬁnition, transition matrix, state probabilities transient and stationary distributions: path and matrix formulas, equilibrium equations classiﬁcation of states Markov Reward Processes and the evaluation of values

Queueing Systems Part 3: Markov Chains
Modeling queueing systems with Markov chains
Table of contents (ctd.) modeling example: the single-server queue with iid arrivals construction of the Markov chain equilibrium equations solution via generating functions variations on the model
→ to be developed in the Case Study after the pause.

Queueing Systems Part 3: Markov Chains Modeling queues
Back to the dynamics of queues

The evolution of queues can sometimes conveniently be represented with

equations. We have seen the recurrence on waiting times for FIFO

queues:

wn+1 = [wn + σn − τn+1]+ .

Consider a discrete-time queue, and Qn the number of customers in queue at slot n. The natural evolution equation is:

Qn+1 = Qn + An − Dn ,

with An the number of arrivals and Dn the number of departures. This depends on the scheduling policy and the amount of customers.
Such equations generate a stochastic process {Qn; n ∈ N}. Computing its properties is “solving the queueing problem”. When this process is a Markov process, this is easier.

Queueing Systems Part 3: Markov Chains Markov Chains in Discrete Time
Discrete Time Markov chains
Consider a sequence of random variables {X (n)} ⊂ E, where E is some discrete set. Deﬁnition of Discrete-Time Markov Chains {X (n), n ∈ N} is a homogeneous discrete time Markov chain if:
i/ (Markov property) ∀t ∈ N, et ∀ (j0, j1, . . . , jt , jt+1) ∈ Et+2:
P{X (t + 1) = jt+1|X (t) = jt , . . . , X (0) = j0} = P{X (t + 1) = jt+1|X (t) = jt } ;
ii/ (homogeneity) ∀t ∈ N, et (i, j) ∈ E × E,
P{X (t + 1) = j|X (t) = i } = Pi,j .
Pi,j , (i, j) ∈ E × E: transition probabilities P transition matrix.

Queueing Systems Part 3: Markov Chains Markov Chains in Discrete Time
Dynamics of probabilities

One looks for transition probabilities at n steps:

p(i, j; n) = P{X (n) = j | X (0) = i} , Let P(n) be the matrix of p(i, j; n). Then:

P(n) = Pn.

Let now, for n ∈ N and j ∈ E,

πn(j) = P{X (n) = j}.

Then:

πn(j) = π0(i ) p(i , j; n) .
i ∈E

Algebraic form: for any n ∈ N:

πn = π0 Pn.

Queueing Systems Part 3: Markov Chains Markov Chains in Discrete Time
The graph of a Markov Chain
To every probability transition matrix P = ((pij ))E×E , is associated a weighted (valued) directed graph G = (V , E , W ):
V =E E = {(i , j) ∈ V × V , pij > 0} W : E → R, (i , j) → pij .

Queueing Systems Part 3: Markov Chains Markov Chains in Discrete Time
Dynamics of probabilities (ctd.)

Another view of the formula P(n) = Pn: the path formula.
Let G be the graph of P. For all n ∈ N, (i, j) ∈ E × E, we have:

p(i, j; n) =

pi,i1 pi1,i2 . . . pin−1,j

(i1, . . . , in−1) ∈ E n−1

=

pi,i1 pi1,i2 . . . pin−1,j .

(i , i1, . . . , in−1, j) path in G

Queueing Systems Part 3: Markov Chains Markov Chains in Discrete Time
Example of Markov chain

Transition Matrix:

0.2

0.2

0.5

1

2

0.6

1

0.5

3
Graph, or transition diagram

 0.2 0.2 0.6  P =  0 0.5 0.5  .
100

Queueing Systems Part 3: Markov Chains Markov Chains in Discrete Time
Example of Markov chain (ctd.)

Probability vectors:

π0 = (1, 0, 0)

π1 = (0.2, 0.2, 0.6)

π2 = (0.64, 0.14, 0.22)

π3 = (0.348, 0.198, 0.454)

π4 = (0.5236, 0.1686, 0.3078)

...

... ...

π∞ = (5/11, 2/11, 4/11).

Is this behavior common to all Markov chains?

Queueing Systems Part 3: Markov Chains Equilibrium Equations
Equilibrium equations

We have:

πn+1 = πn P.

If limn πn = π exists, then:

π = πP.

These equilibrium equations are written: ∀i ∈ E,

π(i) =

π(j ) Pj,i .

j ∈E

They deﬁne the stationary probability. The computation of stationary probabilities is reduced to the solution of a linear system!

Queueing Systems Part 3: Markov Chains Equilibrium Equations
Example of Markov chain (ctd.)

In the example: Indeed,

 0.2 0.2 0.6  P =  0 0.5 0.5  .
100

 0.2 0.2 0.6  (5/11, 2/11, 4/11) .  0 0.5 0.5  = (5/11, 2/11, 4/11).
100

It is the only solution to πP = π that is a probability vector.

Queueing Systems Part 3: Markov Chains Equilibrium Equations
Classiﬁcation of states
The behavior of p(i, j, n) as n → ∞ depends primarily on the properties of the graph G = (V , E ) (without the weights).
Let V = C1 ∪ C2 ∪ . . . ∪ Cq be the partition in strongly connected components G = {V , E } the quotient graph induced by this partition: it is acyclic.
Then
Classiﬁcation of states
if Ck is a leaf in G , states of Ck are called recurrent othewise, states of Ck are called transient and p(i, j, n) → 0 as n → ∞, for all i and all j ∈ Ck .

Queueing Systems Part 3: Markov Chains Equilibrium Equations
Further concepts for Markov Chains
A Markov chain is said to be: irreducible if its graph has only one strongly connected component aperiodic if the greatest common divisor of all cycle lengths in its graph is 1.

Queueing Systems Part 3: Markov Chains Equilibrium Equations
Asymptotic behavior
The set E is ﬁnite. Let P be a ﬁnite stochastic matrix, irreducible and aperiodic. Let π be the left eigenvector of P for the eigenvalue 1, such that π.1 = 1. Then
lim Pn = 1.π .
n→∞
Consequently, for any vector π0, one has:
lim πn = π
n→∞
lim p(i, j, n) = π(j) ∀i, j ∈ E .
n→∞
The convergence occurs geometrically fast:
||πn − π|| = O(ρn)
for any ρ such that |λ2| < ρ < 1, where λ2 is the eigenvalue of P of largest modulus after 1.

Queueing Systems Part 3: Markov Chains Equilibrium Equations
Markov reward processes
In general, the Markov chain {X (n); n ∈ N} is not what is of interest in itself. In addition, there is a mechanism of accumulation of costs or rewards.
To each state of the Markov chain {X (n), n ∈ N} is associated a (possibly random) reward R(n) with the rules:
the distribution of R(n), conditioned on {X (n) = i}, is some Fi (·) the rewards at diﬀerent steps are conditionnally independent.
Markov Reward Process The process (X (n), R(n)) is a Markov Reward Process.

Queueing Systems Part 3: Markov Chains Equilibrium Equations
Statistics of Markov Reward Processes

We are interested in: the expected discounted reward: for each i ∈ E,

∞
V (i) = E βnR(n) X (0) = i
n=0
the reward rate or average reward:

ρ(i) =

1

lim T →∞ T

E

T −1
R(n) X (0) = i

n=0

Queueing Systems Part 3: Markov Chains Equilibrium Equations
Computation of Markov Reward statistics

Use the column vector notation: R = ((ER|X = i ))i∈E

V = ((V (i )))i∈E .

Discounted rewards The vector V = ((V (i)))i∈E is the solution to the linear system:
V = R + β PV .

Average rewards If the matrix P is irreducible, the quantity ρ(i) is independent on i and is given by:
ρ = π.R
where π is the stationary distribution of the chain.
Again linear algebra problems.

Queueing Systems Part 4: Numerical solution and simulation
Part 4: Numerical solution and simulation

Queueing Systems Part 4: Numerical solution and simulation
Numerical solution and simulation
Table of contents: Numerical methods: direct solution of linear systems, iterative solutions: power method, Jacobi-like methods Monte-Carlo Simulation: pseudo-random numbers, simulation of generic Markov Chains, simulation via evolution equations Application to sampling from complicated distributions

Queueing Systems Part 4: Numerical solution and simulation
Numerical computation of metrics
As observed above: the computation of stationary probabilities is reduced to the solution of a linear system
Also: many performance metrics (throughputs, average queue size, average waiting time, ...) can be deduced from the stationary distribution because they are some sort of Markov reward other performance metrics, such as hitting times, are also computed with linear systems.
Linear systems are easy! Problem solved? Some remaining issues:
the system is often very large it may even be inﬁnite!

Queueing Systems Part 4: Numerical solution and simulation
How to get distributions of a DTMC?
Two main approaches to obtain a stationary distribution from the matrix P:
1 numerical solution of the system π = πP 2 Monte-Carlo simulation of the Markov Chain + statistics

Queueing Systems Part 4: Numerical solution and simulation Numerical Solution
Numerical solutions

Solving the system: πP = P and π.1 = 1.
Direct Gaussian Elimination → adapted to small state spaces
Iterative methods: → adapted to medium state spaces
power method: πn+1 = πn.P relaxation method:

π(k+1)(i ) = π(k+1)(j )Pji + π(k)(j )Pji .

j <i

j ≥i

Jacobi-style methods: P = M + N =⇒ π = πN(I − M)−1 → typically faster convergence many others...

Queueing Systems Part 4: Numerical solution and simulation Monte-Carlo Simulation
Monte-Carlo simulation

Monte-Carlo simulation consists in generating trajectories of the Markov-Chain {Xn; n ∈ N}.
Then statistics are performed on the sample. Obvious example: the empirical distribution of one sample.

pˆi

=

1 N +1

N

1{X (n)=i} .

n=0

Other possibility, with many independent samples and some large N:

1K

pˆi = K

1{X (k)(N)=i} .

k =1

Main issues: computation time convergence to the stationary regime: when can one assume that X (n) is a sample from the stationary distribution?

Queueing Systems Part 4: Numerical solution and simulation Monte-Carlo Simulation
Pseudo-random numbers
Principle: given that Xn = i ∈ E, the distribution of Xn+1 is given by {Pij ; j ∈ E}. Sampling from a discrete distribution is the basic step. The following (naive) algorithm does it. It just needs a Unif([0,1]) pseudo-random numbers generator.
Algorithm: Function DiscreteSample
Data: A discrete distribution: array of n probabilities pi and values v[i] Result: A random value equal to v[k] with probability pk begin
U ← Unif([0, 1]) j ←1 while U > p[j] do
U ← U − p[j] j ←j+1
return v[j]

Queueing Systems Part 4: Numerical solution and simulation Monte-Carlo Simulation
Generic simulation algorithm
The basic algorithm returns a trajectory of predeﬁned length.
Data: A transition matrix P, in the form of |E| distributions pi , i ∈ E Data: An initial distribution π0 Data: A time horizon N ∈ N Result: A sequence of N + 1 states x[i], 0 ≤ i ≤ N begin
x[0] ← DiscreteSample(π0) for n from 1 to N do
nextDist ← px[n−1] x[n] ← DiscreteSample(nextDist) // insert here any processing on sample x[n] // insert here any processing on the sequence x[0 : N] return x[0 : N]

Queueing Systems Part 4: Numerical solution and simulation MCMC Sampling
Applications of Monte-Carlo simulation
It was claimed earlier that sampling from a discrete distribution is easy... but this is not always so. For instance: too many states... In that case, the MCMC (Markov chain Monte-Carlo) helps. Assume one wants to sample from distribution f (·).
construct a Markov Chain that has f a a stationary distribution simulate the Markov Chain for N steps return the state of the Markov Chain. The transition probabilities of the Markov chains, denoted with q(y |x) are called instrumental distributions.

Queueing Systems Part 4: Numerical solution and simulation MCMC Sampling
The (generic) Hastings-Metropolis algorithm

Data: A distribution function f (·)

Data: A family of instrumental distributions q(·|x)

Data: A time horizon T ∈ N Result: A sample of the distribution f (·)

begin x ← InitialSample()

for n from 1 to T do y = DiscreteSample(q(·|x))

r ← ρ(x, y ) // using (1)

u ← Unif([0, 1])

if u < r then x ← y // keep sample y

else x ←x

// reject sample y , keep x

return x

ρ(x, y ) = min

f (y ) f (x)

q(x q(y

|y |x

) )

,

1

.

(1)

Queueing Systems Part 4: Numerical solution and simulation MCMC Sampling
Tuning the Hastings-Metropolis algorithm
The instrumental distributions must be chosen such that: 1 it must be algorithmically easy to draw samples from the distribution q(·|x) (small requirement in memory, small computational time); 2 the function ρ(x, y ) must be easy to calculate; 3 the resulting Markov chain must be irreducible and aperiodic; 4 rejections do not happen too frequently; 5 convergence do the stationary distribution is fast.
Two solutions comply with requirements 1, 2 and 3: independent sampling: q(y |x) = q(y ) random walk sampling: q(x + 1|x) = q(x − 1|x) = 1/2 random walk + teleportation: mixture of both (see the PageRank algorithm)

Queueing Systems Part 4: Numerical solution and simulation MCMC Sampling
The (generic) Gibbs sampling algorithm
When the distribution has several dimensions, and each one-dimensional marginal is “easily” simulated, Gibbs’ algorithm can be used.
Data: A multidimensional distribution function f (x1, . . . , xp) Data: A time horizon T ∈ N Result: A sample of the distribution f (·) begin
(x1, . . . , xp) ← InitialSample() for n from 1 to T do
for k from 1 to p do xk ← DiscreteSample(f (x1, . . . , xk−1, xk+1, . . . , xp))
return (x1, . . . , xp)

Queueing Systems Part 4: Numerical solution and simulation MCMC Sampling
Gibbs sampling (ctd.)
Principle: each coordinate of the vector (x1, . . . , xp) is updated in sequence the updated coordinates are used (cf. relaxation) the new values are always accepted
The resulting process x(1), (2), . . . , x(T) is a Markov chain with stationary distribution f : if at somme time t the vector x(t) is distributed according to f , each sample of the following loop has the same distribution.

Queueing Systems Part 4: Numerical solution and simulation Sampling in discrete sets
Uniform sampling of discrete structures
A particular class of matrices: the bistochastic matrices 1P = 1 .
Let E be a set of objects from which we need uniform samples S = {σ1, σ2, . . . , σk } a set of bijections of E. α = (α1, . . . , αk ) a probability distribution over S

Queueing Systems Part 4: Numerical solution and simulation Sampling in discrete sets
Sampling algorithm by random walk
Data: A set S of bijections of E, and a distribution α on the set S Data: A time horizon N ∈ N Result: A sample of the uniform distribution on E begin
x ← InitialSample() for n from 1 to N do
p = DiscreteSample(α) x = σp(x) return x Principle: this realizes a Markov chain which has a bistochastic matrix. The uniform distribution is its stationary distribution.

