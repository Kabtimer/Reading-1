Ricco Rakotomalala http://eric.univ-lyon2.fr/~ricco/cours/cours_programmation_python.html

R.R. – Université Lyon 2

1

Scikit-learn ? Scikit-learn est une librairie pour Python spécialisée dans le machine learning (apprentissage automatique). Nous utilisons la version 0.19.0 dans ce tutoriel.

R.R. – Université Lyon 2

Machine Learning ? Une discipline de l’informatique (intégrée dans l’intelligence artificielle) destinée à modéliser les relations entre les données. Dans un autre domaine, on parlerait de modélisation statistique, ou de méthodes de data mining, ou encore d’analyse de données. On retrouve bien – quelle que soit l’appellation utilisée – les grands thèmes du traitement statistique des données [cf. Introduction à la Data Science]
2

Plan de présentation
Impossible de tout traiter dans un seul support. Nous choisissons l’axe de l’analyse prédictive en déroulant une étude de cas.

1. Schéma typique d’une démarche d’analyse prédictive 2. Stratégie et évaluation sur les petits échantillons 3. Scoring - Ciblage 4. Recherche des paramètres optimaux des algorithmes 5. Sélection de variables

R.R. – Université Lyon 2

3

Données – PIMA INDIAN DIABETES

Objectif : Prédire / expliquer l’occurrence du diabète (variable à prédire) à partir des caractéristiques des personnes (âge, IMC, etc.) (variables explicatives). Fichier texte « pima.txt » avec séparateur « tabulation », première ligne = noms des variables.

R.R. – Université Lyon 2

4

Schéma typique (standard) de l’analyse prédictive
ANALYSE PRÉDICTIVE

R.R. – Université Lyon 2

5

Analyse prédictive
Y : variable cible (diabète) X1, X2, … : variables explicatives f(.) une fonction qui essaie d’établir la relation Y = f(X1, X2, …) f(.) doit être « aussi précise que possible »…

Ensemble d’apprentissage

Construction de la fonction f(.) à partir des données d’apprentissage
Y = f(X1,X2,…) + 

Ensemble de données (dataset)
R.R. – Université Lyon 2

Ensemble de test

Application du modèle (prédiction) sur l’ensemble de test

(Y ,Yˆ)
Y : valeurs observées Y^ : valeurs prédites par f(.)

Mesures de performances par confrontation entre Y et Y^ : matrice de confusion + mesures

6

Importation des données

Pandas : Python Data Analysis Library. Très

pratique pour la manipulation des données, avec

#utilisation de la librairie Pandas

un type data.frame inspiré de R.

#spécialisée - entres autres - dans la manipulation des données

import pandas

pima

=

pandas.read_table("pima.txt",sep="\t",header=0)

header = 0, la première ligne (n°0) correspond aux noms de variables.

#dimensions print(pima.shape) # (768, 9) 768 lignes (obs.) et 9 colonnes (variables)

#liste des colonnes print(pima.columns) # Index(['pregnant', 'diastolic', 'triceps', 'bodymass', 'pedigree', 'age','plasma', 'serum', 'diabete'], dtype='object')

pregnant int64
#liste des colonnes et leurs types diastolic int64

print(pima.dtypes)

triceps int64 bodymass float64

pedigree float64

age

int64

plasma int64

serum int64

diabete object

dtype: object (chaîne de caractères)

R.R. – Université Lyon 2

7

Subdivision en échantillons d’apprentissage et de test

#transformation en matrice numpy - seul reconnu par scikit-learn data = pima.as_matrix()
#X matrice des var. explicatives X = data[:,0:8]
#y vecteur de la var. à prédire y = data[:,8]
#utilisation du module model_selection de scikit-learn (sklearn) from sklearn import model_selection
#subdivision des données – éch.test = 300 ; éch.app = 768 – éch.test = 468
X_app,X_test,y_app,y_test = model_selection.train_test_split(X,y,test_size = 300,random_state=0)
print(X_app.shape,X_test.shape,y_app.shape,y_test.shape)

(468,8) (300,8)

(468,) (300,)

R.R. – Université Lyon 2

8

Construction du modèle sur l’échantillon d’apprentissage

#à partir du module linear_model du package sklearn #importer la classe LogisticRegression from sklearn.linear_model import LogisticRegression

Nous utilisons la régression logistique, très populaire en France. D’autres approches supervisées sont disponibles dans scikit-learn.

#création d'une instance de la classe lr = LogisticRegression()

#exécution de l'instance sur les données d'apprentissage #c.à-d. construction du modèle prédictif modele = lr.fit(X_app,y_app)

On ne dispose pas des indicateurs usuels de la régression logistique

#les sorties sont très pauvres à la différence des logiciels de stat (tests de significativité,

#les coefficients…

écarts-type des

print(modele.coef_,modele.intercept_)

coefficients, etc.)

[[ 8.75111754e-02 -1.59515113e-02 1.70447729e-03 5.18540256e-02 5.34746050e-01 1.24326526e-02 2.40105095e-02 -2.91593120e-04]] [-5.13484535]

R.R. – Université Lyon 2

9

Commentaires sur les résultats de la régression logistique
Attention : La régression logistique de scikit-learn s’appuie sur un algorithme différent de celui des logiciels de statistique.

Coefficients du logiciel SAS

Coefficients du modèle élaboré sur la totalité des données (scikit-learn)

Variable Intercept pregnant diastolic triceps bodymass pedigree age plasma serum

Coefficient 8.4047 -0.1232 0.0133 -0.0006 -0.0897 -0.9452 -0.0149 -0.0352 0.0012

Variable Intercept pregnant diastolic triceps bodymass pedigree age plasma serum

Coefficient 5.8844 -0.1171 0.0169 -0.0008 -0.0597 -0.6776 -0.0072 -0.0284 0.0006

Les coefficients sont du même ordre mais différents. Ca ne veut pas dire que le modèle est moins performant en prédiction.

R.R. – Université Lyon 2

10

Prédiction et évaluation sur l’échantillon test
#prediction sur l'échantillon test y_pred = modele.predict(X_test)

#importation de metrics - utilisé pour les mesures de performances from sklearn import metrics

#matrice de confusion #confrontation entre Y obs. sur l’éch. test et la prédiction cm = metrics.confusion_matrix(y_test,y_pred) print(cm)

Matrice de confusion Ligne : observé Colonne : prédiction

#taux de succès acc = metrics.accuracy_score(y_test,y_pred) print(acc) # 0.793 = (184 + 54)/ (184 + 17 + 45 + 54)

#taux d'erreur err = 1.0 - acc print(err) # 0.206 = 1.0 – 0.793

#sensibilité (ou rappel) se = metrics.recall_score(y_test,y_pred,pos_label='positive') print(se) # 0.545 = 54 / (45+ 54)

R.R. – Université Lyon 2

11

Construction de sa propre mesure de performance (ex. Spécificité)

#écrire sa propre func. d'éval - ex. specificité def specificity(y,y_hat):
#matrice de confusion – un objet numpy.ndarray mc = metrics.confusion_matrix(y,y_hat) #’’negative’’ est sur l'indice 0 dans la matrice import numpy res = mc[0,0]/numpy.sum(mc[0,:]) #retour return res #

Remarque : utiliser les packages comme simples boîtes à outils est une chose, savoir programmer en Python en est une autre. C’est indispensable si l’on veut aller plus loin et exploiter au mieux le dispositif.
Matrice de confusion =

#la rendre utilisable - transformation en objet scorer specificite = metrics.make_scorer(specificity,greater_is_better=True)

#utilisation de l’objet scorer #remarque : modele est le modèle élaboré sur l’éch. d’apprentissage sp = specificite(modele,X_test,y_test) print(sp) # 0.915 = 184 / (184 + 17)

R.R. – Université Lyon 2

12

Stratégie et évaluation sur les petits échantillons
VALIDATION CROISÉE

R.R. – Université Lyon 2

13

Pourquoi la validation croisée

Problème : lorsque l’on traite un petit fichier (en

#importer la classe LogisticRegression

nombre d’obs.), le schéma apprentissage – test

from sklearn.linear_model import LogisticRegression

est pénalisant (apprentissage : on réduit

#création d'une instance de la classe lr = LogisticRegression()

l’information disponible pour créer le modèle ; test : un faible effectif produit des estimations des performances très instables).

#exécution de l'instance sur la totalité des données (X,y) modele_all = lr.fit(X,y)

Solution : (1) construire le modèle sur la totalité des données, (2) évaluer les performances à

l’aide des techniques de ré-échantillonnage (ex.

#affichage

validation croisée)

print(modele_all.coef_,modele_all.intercept_)

# [[ 1.17056955e-01 -1.69020125e-02 7.53362852e-04 5.96780492e-02 6.77559538e-01 7.21222074e-03 2.83668010e-02 -6.41169185e-04]] [-5.8844014]

# !!! Les coefficients sont différents de ceux estimés sur l’éch. d’apprentissage (on a plus d’obs. ici) !!!

#utilisation du module model_selection from sklearn import model_selection
#évaluation en validation croisée : 10 cross-validation succes = model_selection.cross_val_score(lr,X,y,cv=10,scoring='accuracy')
#détail des itérations print(succes)
#moyenne des taux de succès = estimation du taux de succès en CV print(succes.mean()) # 0.767
R.R. – Université Lyon 2

0.74025974 0.75324675 0.79220779 0.72727273 0.74025974 0.74025974 0.81818182 0.79220779 0.73684211 0.82894737
14

Dans un schéma apprentissage - test
SCORING

R.R. – Université Lyon 2

15

Scoring - Ciblage
Ex. de ciblage : faire la promotion d’un produit auprès d’un ensemble de clients Objectif : contacter le moins de personnes possible, obtenir le max. d’achats Démarche : attribuer un score aux individus, les trier de manière décroissante (score élevé = forte appétence au produit), estimer à l’aide de la courbe de gain le nombre d’achats en fonction d’une taille de cible choisie. Remarque : L’idée peut être transposée à d’autres domaines (ex. dépistage de maladie)

Ensemble d’apprentissage

Construction de la fonction f(.) à partir des données d’apprentissage

Y = f(X1,X2,…) + 

Ensemble de données (dataset)
R.R. – Université Lyon 2

Application du modèle (scoring) sur l’ensemble de test

Mesurer la performance avec la courbe de gain

Ensemble de test

(Y , score)
Y : valeurs observées score : propension à être positif attribué par f(.)

16

Construire la courbe de gain (1/3)

#classe Régression Logistique from sklearn.linear_model import LogisticRegression
#création d'une instance de la classe lr = LogisticRegression()

Probas. d’affectation aux classes Negative, Positive

#modélisation sur les données d'apprentissage modele = lr.fit(X_app,y_app)

#calcul des probas d'affectation sur ech. test probas = lr.predict_proba(X_test)

#score de 'presence' score = probas[:,1] # [0.86238322 0.21334963 0.15895063 …]
#transf. en 0/1 de Y_test pos = pandas.get_dummies(y_test).as_matrix()

Classe d’appartenance Negative, Positive

#on ne récupère que la 2è colonne (indice 1) pos = pos[:,1] # [ 1 0 0 1 0 0 1 1 …]

#nombre total de positif import numpy npos = numpy.sum(pos) # 99 – il y a 99 ind. ‘’positifs’’ dans l’échantillon test

R.R. – Université Lyon 2

17

Construction de la courbe de gain (2/3)

L’individu n°55 a le score le plus faible, suivi du

#index pour tri selon le score croissant

n°45, … , l’individu n°159 a le score le plus élevé.

index = numpy.argsort(score) # [ 55 45 265 261 … 11 255 159]

#inverser pour score décroissant – on s’intéresse à forte proba. en priorité index = index[::-1] # [ 159 255 11 … 261 265 45 55 ]

#tri des individus (des valeurs 0/1)

Le score est pas trop mal, il place bien les ‘positifs’

sort_pos = pos[index] # [ 1 1 1 1 1 0 1 1 …] en tête des données après le tri décroissant.

#somme cumulée cpos = numpy.cumsum(sort_pos) # [ 1 2 3 4 5 5 6 7 … 99]

#rappel rappel = cpos/npos # [ 1/99 2/99 3/99 4/99 5/99 5/99 6/99 7/99 … 99/99]

#nb. obs ech.test n = y_test.shape[0] # 300, il y a 300 ind. dans l’éch. test

#taille de cible – séquence de valeurs de 1 à 300 avec un pas de 1 taille = numpy.arange(start=1,stop=301,step=1) # [1 2 3 4 5 … 300]

#passer en proportion taille = taille / n # [ 1/300 2/300 3/300 … 300/300 ]

R.R. – Université Lyon 2

18

Construction de la courbe de gain (3/3)
#graphique avec matplotlib import matplotlib.pyplot as plt
#titre et en-têtes plt.title('Courbe de gain') plt.xlabel('Taille de cible') plt.ylabel('Rappel')

Objectif : Réaliser le graphique à partir des vecteurs ‘taille’ et ‘rappel’ – On parle de « courbe de gain » ou « courbe lift cumulée ».

#limites en abscisse et ordonnée plt.xlim(0,1) plt.ylim(0,1)

#astuce pour tracer la diagonale plt.scatter(taille,taille,marker='.',color='blue')

#insertion du couple (taille, rappel) plt.scatter(taille,rappel,marker='.',color='red')

#affichage plt.show()

R.R. – Université Lyon 2

19

Recherche des paramètres optimaux des algorithmes
GRID SEARCH

R.R. – Université Lyon 2

20

Dépendances des algorithmes d’apprentissage aux paramètres

#svm from sklearn import svm
#par défaut un noyau RBF et C = 1.0 mvs = svm.SVC()

Problème : De nombreux algorithmes de machine learning reposent sur des paramètres qui ne sont pas toujours évidents à déterminer pour obtenir les meilleurs performances sur un jeu de données à traiter. Ex. SVM.

#modélisation modele2 = mvs.fit(X_app,y_app)

#prédiction ech. test

y_pred2 = modele2.predict(X_test)

La méthode ne fait pas mieux que le classifieur

par défaut (prédire systématiquement ‘negative’,

#matrice de confusion

classe majoritaire). Matrice de confusion :

print(metrics.confusion_matrix(y_test,y_pred2))

#succès en test print(metrics.accuracy_score(y_test,y_pred2)) # 0.67

C’est la méthode (SVM) qui est inapte ou c’est le paramétrage qui est inadapté ?

R.R. – Université Lyon 2

21

Détermination des meilleurs valeurs des paramètres

#import de la classe from sklearn import model_selection

Stratégie : Grille de recherche. On indique les paramètres à faire varier,

#combinaisons de paramètres à évaluer parametres = [{'C':[0.1,1,10],'kernel':['rbf','linear']}]

scikit-learn les croise et mesure les performances en validation croisée.

#évaluation en validation croisée de 3 x 2 = 6 configurations #accuracy sera le critère à utiliser pour sélectionner la meilleure config #mvs est l’instance de la classe svm.SVC (cf. page précédente) grid = model_selection.GridSearchCV(estimator=mvs,param_grid=parametres,scoring='accuracy')

#lancer la recherche – attention, gourmand en calculs grille = grid.fit(X_app,y_app)

#résultat pour chaque combinaison print(pandas.DataFrame.from_dict(grille.cv_results_).loc[:,["params","mean_test_score"]])

#meilleur paramétrage print(grille.best_params_) # {‘C’ : 10, ‘kernel’ : ‘linear’}

#meilleur performance – estimée en interne par validation croisée print(grille.best_score_) # 0.7564

#prédiction avec le modèle « optimal » c.-à-d. {‘C’ : 10, ‘kernel’ : ‘linear’} y_pred3 = grille.predict(X_test)

#taux de succès en test print(metrics.accuracy_score(y_test,y_pred3)) # 0.7833, on se rapproche de la rég. logistique

R.R. – Université Lyon 2

22

Réduire le modèle aux variables explicatives les plus pertinentes
SÉLECTION DE VARIABLES

R.R. – Université Lyon 2

23

Sélection de variables (1/2)

Liste initiale des variables : pregnant, diastolic, triceps,

#importer la classe LogisticRegression

bodymass, pedigree, age, plasma, serum.

from sklearn.linear_model import LogisticRegression Objectif : la sélection de variables - la recherche de

#création d'une instance de la classe lr = LogisticRegression()

modèles parcimonieux - présente plusieurs avantages : interprétation, déploiement (moins de var. à renseigner), performances en généralisation

(ou du moins maintien des performances).

#algorithme de sélection de var.

Méthode : Nous implémentons la méthode RFE de

from sklearn.feature_selection import RFE

scikit-learn : elle élimine au fur et à mesure les

selecteur = RFE(estimator=lr)

coefficients les plus faibles en valeur absolue

(étrange : les variables ne sont pas toujours à la

#lancer la recherche sol = selecteur.fit(X_app,y_app)

même échelle ??? une standardisation des variables me paraît nécessaire), et s’arrête quand on arrive à la moitié ou à un nombre spécifié de

#nombre de var. sélectionnées

variables.

print(sol.n_features_) # 4 → 4 = 8 / 2 variables sélectionnées

#liste des variables sélectionnées print(sol.support_) # [True False False True True False True False ]

Variables sélectionnées : pregnant, bodymass, pedigree, plasma.

#ordre de suppression print(sol.ranking_) # [1 2 4 1 1 3 1 5] Serum a été retirée en premier, puis triceps, puis âge, puis
diastolic. Les variables restantes sont indexées 1.

R.R. – Université Lyon 2

24

Sélection de variables (2/2)

#réduction de la base d'app. aux var. sélectionnées #en utilisant le filtre booléen sol.support_ X_new_app = X_app[:,sol.support_] print(X_new_app.shape) # (468, 4) → 4 variables restantes

#construction du modèle sur les explicatives sélectionnées modele_sel = lr.fit(X_new_app,y_app)

#réduction de la base test aux mêmes variables X_new_test = X_test[:,sol.support_] print(X_new_test.shape) # (300, 4)

#prédiction du modèle réduit sur l’éch. test y_pred_sel = modele_sel.predict(X_new_test)
#évaluation print(metrics.accuracy_score(y_test,y_pred_sel)) # 0.787

Aussi bien (presque, 0.793) que le modèle initial, mais avec moitié moins de variables.

R.R. – Université Lyon 2

25

Références
De la documentation à profusion (n’achetez pas des livres sur Python)
Site du cours http://eric.univ-lyon2.fr/~ricco/cours/cours_programmation_python.html
Site de Python Welcome to Python - https://www.python.org/ Python 3.4.3 documentation - https://docs.python.org/3/index.html
Portail Python Page Python de Developpez.com
Quelques cours en ligne P. Fuchs, P. Poulain, « Cours de Python » sur Developpez.com G. Swinnen, « Apprendre à programmer avec Python » sur Developpez.com « Python », Cours interactif sur Codecademy
POLLS (KDnuggets)
Data Mining / Analytics Tools Used Python, 4ème en 2015 What languages you used for data mining / data science? Python, 3ème en 2014 (derrière R et SAS)

R.R. – Université Lyon 2

26

